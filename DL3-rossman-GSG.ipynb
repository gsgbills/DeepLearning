{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Structured and time series data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook contains an implementation of the 3rd place result in the Rossmann Kaggle competition as detailed in Guo/Berkhahn's [Entity Embeddings of Categorical Variables](https://arxiv.org/abs/1604.06737).\n",
    "\n",
    "The motivation behind exploring this architecture is it's relevance to real-world application. Most data used for decision making in industry is structured and/or time-series data. Here we explore the end-to-end process of using neural networks with practical structured data problems."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "PATH='data/rossmann/'\n",
    "\n",
    "\n",
    "from fastai.structured import *\n",
    "from fastai.column_data import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`np.set_printoptions(threshold=50, edgeitems=20)`\n",
    "\n",
    "threshold : int, optional - Total number of array elements which trigger summarization rather than full repr (default 1000).\n",
    "\n",
    "edgeitems : int, optional- Number of array items in summary at beginning and end of each dimension (default 3).edgeitems : int, optional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(threshold=50, edgeitems=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "scrolled": false
   },
   "source": [
    "## Create datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In addition to the provided data, we will be using external datasets put together by participants in the Kaggle competition. You can download all of them [here](http://files.fast.ai/part2/lesson14/rossmann.tgz).\n",
    "\n",
    "For completeness, the implementation used to put them together is included below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "def concat_csvs(dirname):\n",
    "    path = f'{PATH}{dirname}'\n",
    "    filenames=glob.glob(f\"{path}/*.csv\")\n",
    "\n",
    "    wrote_header = False\n",
    "    with open(f\"{path}.csv\",\"w\") as outputfile:\n",
    "        for filename in filenames:\n",
    "            name = filename.split(\".\")[0]\n",
    "            with open(filename) as f:\n",
    "                line = f.readline()\n",
    "                if not wrote_header:\n",
    "                    wrote_header = True\n",
    "                    outputfile.write(\"file,\"+line)\n",
    "                for line in f:\n",
    "                     outputfile.write(name + \",\" + line)\n",
    "                outputfile.write(\"\\n\")   #Notice this at end of file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB: Files must finish by \"\\n\", else some of the conversions fail..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Space:\n",
    "* train: Training set provided by competition\n",
    "* store: List of stores\n",
    "* store_states: mapping of store to the German state they are in\n",
    "* state_names: List of German state names\n",
    "* googletrend: trend of certain google keywords over time, found by users to correlate well w/ given data\n",
    "* weather: weather\n",
    "* test: testing set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_names = ['train', 'store', 'store_states', 'state_names', \n",
    "               'googletrend', 'weather', 'test']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`pandas` allows to manipulate tables/data frames in python as one would in a DB.\n",
    "using `pd.read_csv` to load the above (7) (fname).csv files as dataframes into the list `tables`.\n",
    "\n",
    "`low_memory` : Internally process the file in chunks, resulting in lower memory use while parsing, but possibly mixed type inference.          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "tables = [pd.read_csv(f'{PATH}{fname}.csv', low_memory=False)  \n",
    "          for fname in table_names]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing index in Kaggle table \n",
    "test table (v2 from Kaggle) is missing Index which we need for skipping validation set. Add it now. (Or later?)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = tables[6]\n",
    "t['Id'] = t.index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import HTML"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick look at the contents of each table:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `head()` to get a quick look at the contents of each table:\n",
    "* train: Contains store information on a daily basis, tracks things like sales, customers, whether that day was a holliday, etc.\n",
    "* store: general info about the store including competition, etc.\n",
    "* store_states: maps store to state it is in\n",
    "* state_names: Maps state abbreviations to names\n",
    "* googletrend: trend data for particular week/state\n",
    "* weather: weather conditions for each state\n",
    "* test: Same as training table, w/o sales and customers\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DF: train\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Date</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Customers</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>2015-07-31</td>\n",
       "      <td>5263</td>\n",
       "      <td>555</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store  DayOfWeek        Date  Sales  Customers  Open  Promo StateHoliday  \\\n",
       "0      1          5  2015-07-31   5263        555     1      1            0   \n",
       "\n",
       "   SchoolHoliday  \n",
       "0              1  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DF: store\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>StoreType</th>\n",
       "      <th>Assortment</th>\n",
       "      <th>CompetitionDistance</th>\n",
       "      <th>CompetitionOpenSinceMonth</th>\n",
       "      <th>CompetitionOpenSinceYear</th>\n",
       "      <th>Promo2</th>\n",
       "      <th>Promo2SinceWeek</th>\n",
       "      <th>Promo2SinceYear</th>\n",
       "      <th>PromoInterval</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>1270.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>2008.0</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store StoreType Assortment  CompetitionDistance  CompetitionOpenSinceMonth  \\\n",
       "0      1         c          a               1270.0                        9.0   \n",
       "\n",
       "   CompetitionOpenSinceYear  Promo2  Promo2SinceWeek  Promo2SinceYear  \\\n",
       "0                    2008.0       0              NaN              NaN   \n",
       "\n",
       "  PromoInterval  \n",
       "0           NaN  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DF: store_states\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>HE</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Store State\n",
       "0      1    HE"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DF: state_names\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>StateName</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BadenWuerttemberg</td>\n",
       "      <td>BW</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           StateName State\n",
       "0  BadenWuerttemberg    BW"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DF: googletrend\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>week</th>\n",
       "      <th>trend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rossmann_DE_SN</td>\n",
       "      <td>2012-12-02 - 2012-12-08</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             file                     week  trend\n",
       "0  Rossmann_DE_SN  2012-12-02 - 2012-12-08     96"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DF: weather\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>Date</th>\n",
       "      <th>Max_TemperatureC</th>\n",
       "      <th>Mean_TemperatureC</th>\n",
       "      <th>Min_TemperatureC</th>\n",
       "      <th>Dew_PointC</th>\n",
       "      <th>MeanDew_PointC</th>\n",
       "      <th>Min_DewpointC</th>\n",
       "      <th>Max_Humidity</th>\n",
       "      <th>Mean_Humidity</th>\n",
       "      <th>...</th>\n",
       "      <th>Max_VisibilityKm</th>\n",
       "      <th>Mean_VisibilityKm</th>\n",
       "      <th>Min_VisibilitykM</th>\n",
       "      <th>Max_Wind_SpeedKm_h</th>\n",
       "      <th>Mean_Wind_SpeedKm_h</th>\n",
       "      <th>Max_Gust_SpeedKm_h</th>\n",
       "      <th>Precipitationmm</th>\n",
       "      <th>CloudCover</th>\n",
       "      <th>Events</th>\n",
       "      <th>WindDirDegrees</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NordrheinWestfalen</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>94</td>\n",
       "      <td>87</td>\n",
       "      <td>...</td>\n",
       "      <td>31.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>39</td>\n",
       "      <td>26</td>\n",
       "      <td>58.0</td>\n",
       "      <td>5.08</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Rain</td>\n",
       "      <td>215</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 file        Date  Max_TemperatureC  Mean_TemperatureC  \\\n",
       "0  NordrheinWestfalen  2013-01-01                 8                  4   \n",
       "\n",
       "   Min_TemperatureC  Dew_PointC  MeanDew_PointC  Min_DewpointC  Max_Humidity  \\\n",
       "0                 2           7               5              1            94   \n",
       "\n",
       "   Mean_Humidity       ...        Max_VisibilityKm  Mean_VisibilityKm  \\\n",
       "0             87       ...                    31.0               12.0   \n",
       "\n",
       "   Min_VisibilitykM  Max_Wind_SpeedKm_h  Mean_Wind_SpeedKm_h  \\\n",
       "0               4.0                  39                   26   \n",
       "\n",
       "   Max_Gust_SpeedKm_h  Precipitationmm  CloudCover  Events  WindDirDegrees  \n",
       "0                58.0             5.08         6.0    Rain             215  \n",
       "\n",
       "[1 rows x 24 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "DF: test\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Date</th>\n",
       "      <th>Open</th>\n",
       "      <th>Promo</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2015-09-17</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id  Store  DayOfWeek        Date  Open  Promo StateHoliday  SchoolHoliday\n",
       "0   1      1          4  2015-09-17   1.0      1            0              0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "i = 0\n",
    "for t in tables: \n",
    "    print(\"\\nDF:\", table_names[i]); i += 1 \n",
    "    display(t.head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is very representative of a typical industry dataset.\n",
    "\n",
    "The following returns summarized aggregate information to each table accross each field."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### summary of each DF using `display(DataFrameSummary(t).summary())`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# for t in tables: display(DataFrameSummary(t).summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Cleaning / Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As a structured data problem, we have to go through all the cleaning and feature engineering, even though we're using an ANN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set= 1017209 Test set = 41088\n"
     ]
    }
   ],
   "source": [
    "train, store, store_states, state_names, googletrend, weather, test = tables\n",
    "print(\"Training set=\", len(train), \"Test set =\", len(test)) #, len(store), len(store_states), len(state_names), len(googletrend), len(weather)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Turn State Holidays to Boolean\n",
    "We turn state Holidays to booleans, to make them more convenient for modeling. We can do calculations on pandas fields using notation very similar (often identical) to numpy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.StateHoliday = train.StateHoliday!='0'\n",
    "test.StateHoliday = test.StateHoliday!='0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join Tables with `join_df`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`join_df` is a function for joining tables on specific fields. By default, we'll be doing a left outer join of `right` on the `left` argument using the given fields for each table.\n",
    "\n",
    "Pandas does joins using the `merge` method. The `suffixes` argument describes the naming convention for duplicate fields. We've elected to leave the duplicate field names on the left untouched, and append a \"\\_y\" to those on the right."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def join_df(left, right, left_on, right_on=None, suffix='_y'):\n",
    "    if right_on is None: right_on = left_on\n",
    "    return left.merge(right, how='left', left_on=left_on, right_on=right_on, \n",
    "                      suffixes=(\"\", suffix))   # if the 2 columns have the same then suffix is nothing \"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Join weather/state names."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>Date</th>\n",
       "      <th>Max_TemperatureC</th>\n",
       "      <th>Mean_TemperatureC</th>\n",
       "      <th>Min_TemperatureC</th>\n",
       "      <th>Dew_PointC</th>\n",
       "      <th>MeanDew_PointC</th>\n",
       "      <th>Min_DewpointC</th>\n",
       "      <th>Max_Humidity</th>\n",
       "      <th>Mean_Humidity</th>\n",
       "      <th>...</th>\n",
       "      <th>Min_VisibilitykM</th>\n",
       "      <th>Max_Wind_SpeedKm_h</th>\n",
       "      <th>Mean_Wind_SpeedKm_h</th>\n",
       "      <th>Max_Gust_SpeedKm_h</th>\n",
       "      <th>Precipitationmm</th>\n",
       "      <th>CloudCover</th>\n",
       "      <th>Events</th>\n",
       "      <th>WindDirDegrees</th>\n",
       "      <th>StateName</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NordrheinWestfalen</td>\n",
       "      <td>2013-01-01</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>94</td>\n",
       "      <td>87</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>39</td>\n",
       "      <td>26</td>\n",
       "      <td>58.0</td>\n",
       "      <td>5.08</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Rain</td>\n",
       "      <td>215</td>\n",
       "      <td>NordrheinWestfalen</td>\n",
       "      <td>NW</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 file        Date  Max_TemperatureC  Mean_TemperatureC  \\\n",
       "0  NordrheinWestfalen  2013-01-01                 8                  4   \n",
       "\n",
       "   Min_TemperatureC  Dew_PointC  MeanDew_PointC  Min_DewpointC  Max_Humidity  \\\n",
       "0                 2           7               5              1            94   \n",
       "\n",
       "   Mean_Humidity  ...    Min_VisibilitykM  Max_Wind_SpeedKm_h  \\\n",
       "0             87  ...                 4.0                  39   \n",
       "\n",
       "   Mean_Wind_SpeedKm_h  Max_Gust_SpeedKm_h  Precipitationmm  CloudCover  \\\n",
       "0                   26                58.0             5.08         6.0   \n",
       "\n",
       "   Events  WindDirDegrees           StateName  State  \n",
       "0    Rain             215  NordrheinWestfalen     NW  \n",
       "\n",
       "[1 rows x 26 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather = join_df(weather, state_names, \"file\", \"StateName\")\n",
    "weather.head(1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In pandas you can add new columns to a `dataframe` by simply defining it. We'll do this for googletrends by extracting dates and state names from the given data and adding those columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>week</th>\n",
       "      <th>trend</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rossmann_DE_SN</td>\n",
       "      <td>2012-12-02 - 2012-12-08</td>\n",
       "      <td>96</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             file                     week  trend\n",
       "0  Rossmann_DE_SN  2012-12-02 - 2012-12-08     96"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "googletrend.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>file</th>\n",
       "      <th>week</th>\n",
       "      <th>trend</th>\n",
       "      <th>Date</th>\n",
       "      <th>State</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Rossmann_DE_SN</td>\n",
       "      <td>2012-12-02 - 2012-12-08</td>\n",
       "      <td>96</td>\n",
       "      <td>2012-12-02</td>\n",
       "      <td>SN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             file                     week  trend        Date State\n",
       "0  Rossmann_DE_SN  2012-12-02 - 2012-12-08     96  2012-12-02    SN"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Add Date and State columns to this DF\n",
    "googletrend['Date'] = googletrend.week.str.split(' - ', expand=True)[0]\n",
    "googletrend['State'] = googletrend.file.str.split('_', expand=True)[2]\n",
    "googletrend.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Review Pandas indexing\n",
    "We're also going to replace all instances of state name 'NI' to match the usage in the rest of the data: 'HB,NI'. This is a good opportunity to highlight pandas indexing. We can use `.loc[rows, cols]` to select a list of rows and a list of columns from the dataframe. In this case, we're selecting rows w/ statename 'NI' by using a boolean list googletrend.State=='NI' and selecting \"State\"."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "googletrend.loc[googletrend.State=='NI', \"State\"] = 'HB,NI'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using `add_datepart()` to extract particular date fields (from a complete datetime) for constructing categoricals.\n",
    "\n",
    "You should *always* consider this feature extraction step when working with date-time. Without expanding your date-time into these additional fields, you can't capture any trend/cyclical behavior as a function of time at any of these granularities. We'll add to every table with a date field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "add_datepart(weather, \"Date\", drop=False)\n",
    "add_datepart(googletrend, \"Date\", drop=False)\n",
    "add_datepart(train, \"Date\", drop=False)\n",
    "add_datepart(test, \"Date\", drop=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The Googletrend data has a special category for the whole of the US (Germany?) - we'll pull that out so we can use it explicitly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "trend_de = googletrend[googletrend.file == 'Rossmann_DE']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now outer join all of our data into a single dataframe. \n",
    "\n",
    "Recall that in outer joins, everytime a value in the joining field on the left table does not have a corresponding value on the right table, the corresponding row in the new table has Null values for all right table fields. \n",
    "One way to check that all records are consistent and complete is to check for Null values post-join, as we do here."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### *Aside*: Why note just do an inner join?\n",
    "If you are assuming that all records are complete and match on the field you desire, an inner join will do the same thing as an outer join. However, if you are wrong or a mistake is made, an outer join followed by a null-check will catch it. (Comparing before/after # of rows for inner join is equivalent, but requires keeping track of before/after row #'s. Outer join is easier.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Create a DF for the Stores\n",
    "store = join_df(store, store_states, \"Store\")\n",
    "len(store[store.State.isnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined = join_df(train, store, \"Store\")\n",
    "joined_test = join_df(test, store, \"Store\")\n",
    "len(joined[joined.StoreType.isnull()]),len(joined_test[joined_test.StoreType.isnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined = join_df(joined, googletrend, [\"State\",\"Year\", \"Week\"])\n",
    "joined_test = join_df(joined_test, googletrend, [\"State\",\"Year\", \"Week\"])\n",
    "len(joined[joined.trend.isnull()]),len(joined_test[joined_test.trend.isnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Use MERGE for the trend_de ... WHY?\n",
    "joined = joined.merge(trend_de, 'left', [\"Year\", \"Week\"], suffixes=('', '_DE'))\n",
    "joined_test = joined_test.merge(trend_de, 'left', [\"Year\", \"Week\"], suffixes=('', '_DE'))\n",
    "len(joined[joined.trend_DE.isnull()]),len(joined_test[joined_test.trend_DE.isnull()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 0)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined = join_df(joined, weather, [\"State\",\"Date\"])\n",
    "joined_test = join_df(joined_test, weather, [\"State\",\"Date\"])\n",
    "len(joined[joined.Mean_TemperatureC.isnull()]),len(joined_test[joined_test.Mean_TemperatureC.isnull()])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Drop the _y columns in both DFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in (joined, joined_test):\n",
    "    for c in df.columns:\n",
    "        if c.endswith('_y'):\n",
    "            if c in df.columns: df.drop(c, inplace=True, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fill in missing values to avoid complications with `NA`'s. \n",
    "\n",
    "`NA` (Not Available) is how Pandas indicates missing values; Many models have problems when missing values are present, so it's always important to think about how to deal with them. In these cases, we are picking an arbitrary *signal value* that doesn't otherwise appear in the data.  For example, for Year, the fill for NA is 1900, while for Month and Week we choose 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in (joined,joined_test):\n",
    "    df['CompetitionOpenSinceYear'] = df.CompetitionOpenSinceYear.fillna(1900).astype(np.int32)\n",
    "    df['CompetitionOpenSinceMonth'] = df.CompetitionOpenSinceMonth.fillna(1).astype(np.int32)\n",
    "    df['Promo2SinceYear'] = df.Promo2SinceYear.fillna(1900).astype(np.int32)\n",
    "    df['Promo2SinceWeek'] = df.Promo2SinceWeek.fillna(1).astype(np.int32)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract features `CompetitionOpenSince` and `CompetitionDaysOpen`. \n",
    "Note the use of `apply()` in mapping a function across dataframe values.  What we really want to know is how long has this store been open (in days) for this particular record."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in (joined,joined_test):\n",
    "    df[\"CompetitionOpenSince\"] = pd.to_datetime(dict(year=df.CompetitionOpenSinceYear, \n",
    "                                                     month=df.CompetitionOpenSinceMonth, day=15))\n",
    "    df[\"CompetitionDaysOpen\"] = df.Date.subtract(df.CompetitionOpenSince).dt.days"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### replace erroneous / outlying data \n",
    "eg negative days open when competition opened after the store,  etc.\n",
    "This is based on the 3rd place winner process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in (joined,joined_test):\n",
    "    df.loc[df.CompetitionDaysOpen<0, \"CompetitionDaysOpen\"] = 0\n",
    "    df.loc[df.CompetitionOpenSinceYear<1990, \"CompetitionDaysOpen\"] = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limit the number of unique categories by adding fields"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We add \"CompetitionMonthsOpen\" field\n",
    "limiting the maximum to 2 years (24 months)to limit number of unique categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in (joined,joined_test):\n",
    "    df[\"CompetitionMonthsOpen\"] = df[\"CompetitionDaysOpen\"]//30\n",
    "    df.loc[df.CompetitionMonthsOpen>24, \"CompetitionMonthsOpen\"] = 24\n",
    "#joined.CompetitionMonthsOpen.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Same process for Promo dates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice below that the `.apply lambda` is very slow as it repeatedly invokes a Python function to a column. \n",
    "JH used this because he was unable to find a function that would (vectorized) compute (pandas or numpy) for year and week number into a date...\n",
    "`lambda` is creating a function just for this single use...\n",
    "Alternatively, we could have written create_promo2since and pass it by name:\n",
    "\n",
    "def create_promo2since(x):\n",
    "    return Week(x.Promo2SinceYear, x.Promo2SinceWeek).monday() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in (joined,joined_test):\n",
    "    df[\"Promo2Since\"] = pd.to_datetime(df.apply(lambda x: Week(\n",
    "        x.Promo2SinceYear, x.Promo2SinceWeek).monday(), axis=1).astype(pd.datetime))\n",
    "    df[\"Promo2Days\"] = df.Date.subtract(df[\"Promo2Since\"]).dt.days\n",
    "    df.loc[df.Promo2Days<0, \"Promo2Days\"] = 0\n",
    "    df.loc[df.Promo2SinceYear<1990, \"Promo2Days\"] = 0\n",
    "    df[\"Promo2Weeks\"] = df[\"Promo2Days\"]//7\n",
    "    df.loc[df.Promo2Weeks<0, \"Promo2Weeks\"] = 0\n",
    "    df.loc[df.Promo2Weeks>25, \"Promo2Weeks\"] = 25\n",
    "    df.Promo2Weeks.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Save data -\n",
    "joined is the training set, joined_test is the test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "import feather    # fast saving/loading of dataframes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of training set= 1017209 Size of test set= 41088\n"
     ]
    }
   ],
   "source": [
    "joined.to_feather(f'{PATH}joined')\n",
    "joined_test.to_feather(f'{PATH}joined_test')\n",
    "print(\"Size of training set=\", len(joined), \"Size of test set=\", len(joined_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Durations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is common when working with time series data to extract data that explains relationships across rows as opposed to columns, e.g.:\n",
    "* Running averages\n",
    "* Time until next event\n",
    "* Time since last event\n",
    "\n",
    "This is often difficult to do with most table manipulation frameworks, since they are designed to work with relationships across columns. As such, we've created a class to handle this type of data.\n",
    "\n",
    "We'll define a function `get_elapsed` for cumulative counting across a sorted dataframe. Given a particular field `fld` to monitor, this function will start tracking time since the last occurrence of that field. When the field is seen again, the counter is set to zero.  Hence, for a given store and a given event (eg StateHoliday) we will be able to know how long before the last one and how long until the next one. So we create 2 new columns for each such event.  We don't know of a library for this, so JH implemented `get_elapsed` below.\n",
    "\n",
    "Upon initialization, this will result in datetime NA's until the field is encountered. This is reset every time a new store is seen. We'll see how to use this shortly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_elapsed(sdf, fld, pre):   # GSG: Added sdf as sorted df parameter\n",
    "    day1 = np.timedelta64(1, 'D')\n",
    "    last_date = np.datetime64()  # arbitrary last date?\n",
    "    last_store = 0\n",
    "    res = []\n",
    "\n",
    "    for s,v,d in zip(sdf.Store.values, sdf[fld].values, sdf.Date.values):\n",
    "        if s != last_store:  # when it is a new store, we need to reset.\n",
    "            last_date = np.datetime64()\n",
    "            last_store = s\n",
    "        if v: last_date = d   # if it was a school holiday keep track of it\n",
    "        ra = ((d-last_date).astype('timedelta64[D]') / day1).astype(int)\n",
    "        if ra < 0: ra = 0  # GSG: Added check to avoid negative durations\n",
    "        res.append(ra)       #.astype(int))\n",
    "        #res.append(((d-last_date).astype('timedelta64[D]') / day1).astype(int))\n",
    "    sdf[pre+fld] = res\n",
    "    return sdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Above notice the use of zip. Alternative way would have been to write:\n",
    "\n",
    "for row in df.iterrows():\n",
    "\n",
    "but this would iterate on a DF, which is **very slow**,  ie 300 times slower.\n",
    "It is much faster to iterate over np.arrays.\n",
    "zip means loop thru each of the list one at a time, and grab them.\n",
    "above it is a loop over every store, every school holiday, and every date.\n",
    "Very common pattern."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll be applying this (get_elapsed) to a subset of columns:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "columns = [\"Date\", \"Store\", \"Promo\", \"StateHoliday\", \"SchoolHoliday\"]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below JH used the same variable, df, instead of 2 different variables....\n",
    "That prevented the running of the notebook from begining to end, as it was \n",
    "requiring running all the following twice, once for train and once for test. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = train[columns]   #DF for the above train columns to df_train\n",
    "df_test = test[columns]      #DF for the test set "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's walk through an example.\n",
    "\n",
    "Say we're looking at School Holiday. We'll first sort by Store, then Date, and then call `add_elapsed('SchoolHoliday', 'After')`:\n",
    "This will apply to each row with School Holiday:\n",
    "* A applied to every row of the dataframe in order of store and date\n",
    "* Will add to the dataframe the days since seeing a School Holiday\n",
    "* If we sort in the other direction, this will count the days until another holiday."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_before_after_count (df1, fld):\n",
    "    df1 = df1.sort_values(['Store', 'Date'])  #Sort by Store, then Date\n",
    "    df1 = get_elapsed(df1, fld, 'After')\n",
    "    df1 = df1.sort_values(['Store', 'Date'], ascending=[True, False])\n",
    "    df1 = get_elapsed(df1, fld, 'Before')\n",
    "    return df1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute Before and After for SchoolHoliday, StateHoliday, and Promo, for both train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "columnsBaA = ['SchoolHoliday', 'StateHoliday', 'Promo']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in columnsBaA:\n",
    "    df_train = add_before_after_count(df_train, col)\n",
    "    df_test = add_before_after_count(df_test, col)\n",
    "#df_train.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set the active index to Date."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.set_index(\"Date\")\n",
    "df_test = df_test.set_index(\"Date\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Then set null values from elapsed field calculations to 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dfx in [df_train, df_test]:\n",
    "    for o in ['Before', 'After']:\n",
    "        for p in columnsBaA:\n",
    "            a = o+p\n",
    "            dfx[a] = dfx[a].fillna(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Demonstrate window functions in pandas to calculate rolling quantities.\n",
    "Here we're sorting by date (`sort_index()`) and counting the number of events of interest (`sum()`) defined in `columns` in the following week (`rolling()`), grouped by Store (`groupby()`). We do the same in the opposite direction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df_train.head(1)\n",
    "#df_test.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "bwd = df_train[['Store']+columnsBaA].sort_index().groupby(\"Store\").rolling(7, min_periods=1).sum()\n",
    "fwd = df_train[['Store']+columnsBaA].sort_index(ascending=False).groupby(\"Store\").rolling(7, min_periods=1).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dfx in [bwd, fwd]:\n",
    "    dfx.drop('Store',1,inplace=True)  #Drop the Store indiced grouped together\n",
    "    dfx.reset_index(inplace=True)\n",
    "#fwd.drop('Store',1,inplace=True)\n",
    "#fwd.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.reset_index(inplace=True)\n",
    "#df_train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train = df_train.merge(bwd, 'left', ['Date', 'Store'], suffixes=['', '_bw'])\n",
    "df_train = df_train.merge(fwd, 'left', ['Date', 'Store'], suffixes=['', '_fw'])\n",
    "df_train.drop(columnsBaA,1,inplace=True)\n",
    "#df_train.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "bwd = df_test[['Store']+columnsBaA].sort_index().groupby(\"Store\").rolling(7, min_periods=1).sum()\n",
    "fwd = df_test[['Store']+columnsBaA].sort_index(ascending=False).groupby(\"Store\").rolling(7, min_periods=1).sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the Store indices grouped together in the window function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "bwd.drop('Store',1,inplace=True)  #Drop the Store indiced grouped together\n",
    "bwd.reset_index(inplace=True)\n",
    "fwd.drop('Store',1,inplace=True)\n",
    "fwd.reset_index(inplace=True)\n",
    "df_test.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Store</th>\n",
       "      <th>AfterSchoolHoliday</th>\n",
       "      <th>BeforeSchoolHoliday</th>\n",
       "      <th>AfterStateHoliday</th>\n",
       "      <th>BeforeStateHoliday</th>\n",
       "      <th>AfterPromo</th>\n",
       "      <th>BeforePromo</th>\n",
       "      <th>SchoolHoliday_bw</th>\n",
       "      <th>StateHoliday_bw</th>\n",
       "      <th>Promo_bw</th>\n",
       "      <th>SchoolHoliday_fw</th>\n",
       "      <th>StateHoliday_fw</th>\n",
       "      <th>Promo_fw</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2015-09-17</td>\n",
       "      <td>1</td>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Date  Store  AfterSchoolHoliday  BeforeSchoolHoliday  \\\n",
       "0 2015-09-17      1                  13                    0   \n",
       "\n",
       "   AfterStateHoliday  BeforeStateHoliday  AfterPromo  BeforePromo  \\\n",
       "0                  0                   0           0            0   \n",
       "\n",
       "   SchoolHoliday_bw  StateHoliday_bw  Promo_bw  SchoolHoliday_fw  \\\n",
       "0               0.0              0.0       4.0               0.0   \n",
       "\n",
       "   StateHoliday_fw  Promo_fw  \n",
       "0              0.0       1.0  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test = df_test.merge(bwd, 'left', ['Date', 'Store'], suffixes=['', '_bw'])\n",
    "df_test = df_test.merge(fwd, 'left', ['Date', 'Store'], suffixes=['', '_fw'])\n",
    "df_test.drop(columnsBaA,1,inplace=True)\n",
    "df_test.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "#display(DataFrameSummary(df_train).summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### drop the Store indices grouped together in the window function.\n",
    "Often in pandas, there is an option to do this in place. This is time and memory efficient when working with large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "#bwd.drop('Store',1,inplace=True)\n",
    "#bwd.reset_index(inplace=True)\n",
    "#bwd.shape\n",
    "#fwd.drop('Store',1,inplace=True)\n",
    "#fwd.reset_index(inplace=True)\n",
    "\n",
    "#for df in [df_train, df_test]:\n",
    "#    df.reset_index(inplace=True)\n",
    "#df_train.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now we'll merge these values onto the df."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = df.merge(bwd, 'left', ['Date', 'Store'], suffixes=['', '_bw'])\n",
    "#df = df.merge(fwd, 'left', ['Date', 'Store'], suffixes=['', '_fw'])\n",
    "\n",
    "#df.drop(columnsBaA,1,inplace=True)\n",
    "#df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back-up large tables\n",
    "It's usually a good idea to back up large tables of extracted / wrangled features before you join them onto another one, that way you can go back to it easily if you need to make changes to it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_train.to_feather(f'{PATH}df_train')\n",
    "df_train = pd.read_feather(f'{PATH}df_train')  #wrong argument? , index_col=0)\n",
    "df_test.to_feather(f'{PATH}df_test')\n",
    "df_test = pd.read_feather(f'{PATH}df_test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "for dfx in [df_train, df_test]:\n",
    "    dfx[\"Date\"] = pd.to_datetime(dfx.Date)\n",
    "\n",
    "#print(df_train.columns, \"\\n\\n\", df_test.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1017209, 80), (1017209, 14), (41088, 79), (41088, 14), (41088, 79))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined.shape, df_train.shape,  joined_test.shape, df_test.shape, df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined = join_df(joined, df_train, ['Store', 'Date'])\n",
    "joined_test = join_df(joined_test, df_test, ['Store', 'Date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove? Instances were the store was closed or had 0 sales.\n",
    "\n",
    "The authors also removed all instances where the store had zero sale / was closed. We speculate that this may have cost them a higher standing in the competition. One reason this may be the case is that a little exploratory data analysis reveals that there are often periods where stores are closed, typically for refurbishment. Before and after these periods, there are naturally spikes in sales that one might expect. By ommitting this data from their training, the authors gave up the ability to leverage information about these periods to predict this otherwise volatile behavior."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GSG: Testing with avoiding the 0 sales\n",
    "#joined = joined[joined.Sales!=0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We'll back this up as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined.reset_index(inplace=True)\n",
    "joined_test.reset_index(inplace=True)\n",
    "joined.to_feather(f'{PATH}joined')\n",
    "joined_test.to_feather(f'{PATH}joined_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now have our final set of engineered features.\n",
    "\n",
    "While these steps were explicitly outlined in the paper, these are all fairly typical feature engineering steps for dealing with time series data and are practical in any similar setting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# Create features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined = pd.read_feather(f'{PATH}joined')\n",
    "joined_test = pd.read_feather(f'{PATH}joined_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below `T.` is Tranverse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#joined.head().T.head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert to input compatible for ANN\n",
    "Now that we've engineered all our features, we need to convert to input compatible with an Artificial Neural Network.\n",
    "\n",
    "This includes converting categorical variables into contiguous integers or one-hot encodings, normalizing continuous features to standard normal, etc.\n",
    "If they are floating point, likely to be continous as it will be hard to have enugh categories.\n",
    "If it is like age, we could decide if to treat them as categorical or continuos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_vars = ['Store', 'DayOfWeek', 'Year', 'Month', 'Day', 'StateHoliday', 'CompetitionMonthsOpen',\n",
    "    'Promo2Weeks', 'StoreType', 'Assortment', 'PromoInterval', 'CompetitionOpenSinceYear', 'Promo2SinceYear',\n",
    "    'State', 'Week', 'Events', 'Promo_fw', 'Promo_bw', 'StateHoliday_fw', 'StateHoliday_bw',\n",
    "    'SchoolHoliday_fw', 'SchoolHoliday_bw']\n",
    "\n",
    "contin_vars = ['CompetitionDistance', 'Max_TemperatureC', 'Mean_TemperatureC', 'Min_TemperatureC',\n",
    "   'Max_Humidity', 'Mean_Humidity', 'Min_Humidity', 'Max_Wind_SpeedKm_h', \n",
    "   'Mean_Wind_SpeedKm_h', 'CloudCover', 'trend', 'trend_DE',\n",
    "   'AfterStateHoliday', 'BeforeStateHoliday', 'Promo', 'SchoolHoliday']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "#joined_test.head().T.head(90)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert the types of categorical and continuos\n",
    "for v in cat_vars: \n",
    "    joined[v] = joined[v].astype('category').cat.as_ordered()\n",
    "    # for joined_test it will be done below by \"apply_cats\"\n",
    "for v in contin_vars:\n",
    "    joined[v] = joined[v].astype('float32') #Because pytorch expects all vars as float32\n",
    "    joined_test[v] = joined_test[v].astype('float32')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "dep = 'Sales'\n",
    "joined = joined[cat_vars+contin_vars+[dep, 'Date']].copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that the test set from Kaggle does not include an 'Id' field."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "#joined.head(1)\n",
    "#joined_test.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_test['Id'] = joined_test.index + 1    #V2 of test was missing the Id field"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_test[dep] = 0   # We zero the sales for the test set\n",
    "joined_test = joined_test[cat_vars+contin_vars+[dep, 'Date', 'Id']].copy()\n",
    "\n",
    "#joined_test.head(1) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Use `apply_cats(df, trn)` \n",
    "to change any columns of strings in df into categorical variables using trn as\n",
    "    a template for the category codes.\n",
    "    This is to guarantee that both DFs have the same set of categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "apply_cats(joined_test, joined)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We're going to run on a sample, `joined_samp`\n",
    "The idea is to do all the work first on the sample, and once we are satisfied, then go below and use the full dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = len(joined)\n",
    "idxs = get_cv_idxs(n, val_pct=150000/n)  #select random set\n",
    "joined_samp = joined.iloc[idxs].set_index(\"Date\")\n",
    "samp_size = len(joined_samp); samp_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### To run on the full dataset, use this instead:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "samp_size = n\n",
    "joined_samp = joined.set_index(\"Date\")\n",
    "\n",
    "#print(\"Sample size=\", len(joined_samp), \"Shape=\", joined_samp.shape)\n",
    "#joined_samp.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can now process our data..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- `proc_df` takes dataframe, pulls variable ('Sales') puts it in y, and returns df without it.\n",
    "- Because `do_scale=True` it will substract the mean and divide by standard deviation....(ie it does scaling to 0-1). \n",
    "- We save `mapper` (has the mean and std deviation of the continuos column for each continuos variable). So we later apply the same for the test set so they have the same meaning.\n",
    "- Also handles missing values, fills with median"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, y, nas, mapper = proc_df(joined_samp, 'Sales', do_scale=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GSG added: Avoid 0s returned by proc_df as we will take logs later\n",
    "y[y==0] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We take the log because the Kaggle competition defines that the evaluation metric is RMSPE. So we are penalized by the **ratio** between our answer and the correct answer.  By using the log we get an equivalent metric.  There is no RSMPE function in pytorch. \n",
    "Majority of regression competition use the log as the evaluation metric because we care more about ratios than about differences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 8.56846,  8.71012,  9.0257 ,  9.54646,  8.48094,  8.63959,  9.63848,  9.04688,  9.05544,  8.87975,\n",
       "        9.25503,  9.10041,  9.08489,  8.7863 ,  9.12598,  9.23318,  9.03955,  9.21742,  9.01603,  9.16879,\n",
       "       ...,  0.     ,  8.69299,  0.     ,  0.     ,  0.     ,  0.     ,  0.     ,  0.     ,  0.     ,\n",
       "        0.     ,  0.     ,  0.     ,  0.     ,  0.     ,  0.     ,  0.     ,  0.     ,  0.     ,  0.     ,  0.     ])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "yl = np.log(y); yl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>CompetitionMonthsOpen</th>\n",
       "      <th>Promo2Weeks</th>\n",
       "      <th>StoreType</th>\n",
       "      <th>Assortment</th>\n",
       "      <th>...</th>\n",
       "      <th>Mean_Wind_SpeedKm_h</th>\n",
       "      <th>CloudCover</th>\n",
       "      <th>trend</th>\n",
       "      <th>trend_DE</th>\n",
       "      <th>AfterStateHoliday</th>\n",
       "      <th>BeforeStateHoliday</th>\n",
       "      <th>Promo</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "      <th>CompetitionDistance_na</th>\n",
       "      <th>CloudCover_na</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-07-31</th>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>7</td>\n",
       "      <td>31</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.147662</td>\n",
       "      <td>-2.812232</td>\n",
       "      <td>1.744363</td>\n",
       "      <td>1.743047</td>\n",
       "      <td>0.644376</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.273237</td>\n",
       "      <td>2.144211</td>\n",
       "      <td>-0.05103</td>\n",
       "      <td>-0.292796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Store  DayOfWeek  Year  Month  Day  StateHoliday  \\\n",
       "Date                                                           \n",
       "2015-07-31      1          5     3      7   31             1   \n",
       "\n",
       "            CompetitionMonthsOpen  Promo2Weeks  StoreType  Assortment  \\\n",
       "Date                                                                    \n",
       "2015-07-31                     25            1          3           1   \n",
       "\n",
       "                ...        Mean_Wind_SpeedKm_h  CloudCover     trend  \\\n",
       "Date            ...                                                    \n",
       "2015-07-31      ...                  -0.147662   -2.812232  1.744363   \n",
       "\n",
       "            trend_DE  AfterStateHoliday  BeforeStateHoliday     Promo  \\\n",
       "Date                                                                    \n",
       "2015-07-31  1.743047           0.644376                 0.0  1.273237   \n",
       "\n",
       "            SchoolHoliday  CompetitionDistance_na  CloudCover_na  \n",
       "Date                                                              \n",
       "2015-07-31       2.144211                -0.05103      -0.292796  \n",
       "\n",
       "[1 rows x 40 columns]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(1)  #take a look, now df is all numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>CompetitionMonthsOpen</th>\n",
       "      <th>Promo2Weeks</th>\n",
       "      <th>StoreType</th>\n",
       "      <th>Assortment</th>\n",
       "      <th>...</th>\n",
       "      <th>CloudCover</th>\n",
       "      <th>trend</th>\n",
       "      <th>trend_DE</th>\n",
       "      <th>AfterStateHoliday</th>\n",
       "      <th>BeforeStateHoliday</th>\n",
       "      <th>Promo</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "      <th>Sales</th>\n",
       "      <th>Date</th>\n",
       "      <th>Id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>2015</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>False</td>\n",
       "      <td>24</td>\n",
       "      <td>0</td>\n",
       "      <td>c</td>\n",
       "      <td>a</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>2015-09-17</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 41 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  Store DayOfWeek  Year Month Day StateHoliday CompetitionMonthsOpen  \\\n",
       "0     1         4  2015     9  17        False                    24   \n",
       "\n",
       "  Promo2Weeks StoreType Assortment ... CloudCover trend trend_DE  \\\n",
       "0           0         c          a ...        6.0  69.0     67.0   \n",
       "\n",
       "  AfterStateHoliday BeforeStateHoliday Promo SchoolHoliday Sales       Date Id  \n",
       "0               0.0                0.0   1.0           0.0     0 2015-09-17  1  \n",
       "\n",
       "[1 rows x 41 columns]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_test.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_test = joined_test.set_index(\"Date\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_test, _, nas, mapper = proc_df(joined_test, 'Sales', do_scale=True, skip_flds=['Id'],\n",
    "                                  mapper=mapper, na_dict=nas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Store</th>\n",
       "      <th>DayOfWeek</th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Day</th>\n",
       "      <th>StateHoliday</th>\n",
       "      <th>CompetitionMonthsOpen</th>\n",
       "      <th>Promo2Weeks</th>\n",
       "      <th>StoreType</th>\n",
       "      <th>Assortment</th>\n",
       "      <th>...</th>\n",
       "      <th>Mean_Wind_SpeedKm_h</th>\n",
       "      <th>CloudCover</th>\n",
       "      <th>trend</th>\n",
       "      <th>trend_DE</th>\n",
       "      <th>AfterStateHoliday</th>\n",
       "      <th>BeforeStateHoliday</th>\n",
       "      <th>Promo</th>\n",
       "      <th>SchoolHoliday</th>\n",
       "      <th>CompetitionDistance_na</th>\n",
       "      <th>CloudCover_na</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2015-09-17</th>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>9</td>\n",
       "      <td>17</td>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0.361056</td>\n",
       "      <td>0.272087</td>\n",
       "      <td>0.333411</td>\n",
       "      <td>0.079555</td>\n",
       "      <td>-1.183596</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.273237</td>\n",
       "      <td>-0.466372</td>\n",
       "      <td>-0.05103</td>\n",
       "      <td>-0.292796</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 40 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Store  DayOfWeek  Year  Month  Day  StateHoliday  \\\n",
       "Date                                                           \n",
       "2015-09-17      1          4     3      9   17             1   \n",
       "\n",
       "            CompetitionMonthsOpen  Promo2Weeks  StoreType  Assortment  \\\n",
       "Date                                                                    \n",
       "2015-09-17                     25            1          3           1   \n",
       "\n",
       "                ...        Mean_Wind_SpeedKm_h  CloudCover     trend  \\\n",
       "Date            ...                                                    \n",
       "2015-09-17      ...                   0.361056    0.272087  0.333411   \n",
       "\n",
       "            trend_DE  AfterStateHoliday  BeforeStateHoliday     Promo  \\\n",
       "Date                                                                    \n",
       "2015-09-17  0.079555          -1.183596                 0.0  1.273237   \n",
       "\n",
       "            SchoolHoliday  CompetitionDistance_na  CloudCover_na  \n",
       "Date                                                              \n",
       "2015-09-17      -0.466372                -0.05103      -0.292796  \n",
       "\n",
       "[1 rows x 40 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NOTE: In time series data, cross-validation is not random.**\n",
    "Instead, our holdout data is generally the most recent data, as it would be in real application. This issue is discussed in detail in [this post](http://www.fast.ai/2017/11/13/validation-sets/).\n",
    "\n",
    "One approach is to take the last 25% (or 10%) of rows (sorted by date) as our validation set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio = 0.75\n",
    "#train_ratio = 0.9\n",
    "train_size = int(samp_size * train_ratio)\n",
    "val_idx = list(range(train_size, len(df)))\n",
    "#val_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An even better option for picking a validation set is using the exact same length of time period as the test set uses - this is implemented below, where\n",
    "`numpy.flatnonzero(a)` Return indices that are non-zero in the flattened version of a.\n",
    "\n",
    "So now we create a validation set which is on the most recent period (1 Aug - 19Sept 2014)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([334555, 334556, 334557, 334558, 334559, 334560, 334561, 334562, 334563, 334564, 334565, 334566, 334567,\n",
       "       334568, 334569, 334570, 334571, 334572, 334573, 334574, ..., 379415, 379416, 379417, 379418, 379419,\n",
       "       379420, 379421, 379422, 379423, 379424, 379425, 379426, 379427, 379428, 379429, 379430, 379431, 379432,\n",
       "       379433, 379434])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_idx = np.flatnonzero(\n",
    "    (df.index<=datetime.datetime(2014,9,17)) & (df.index>=datetime.datetime(2014,8,1)))\n",
    "val_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "#val_idx=[0]   #Reset val_idx to use the full training set\n",
    "#val_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Deep Learning\n",
    "We're ready to put together our DL models."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Define the metric and related parameters\n",
    "`Root-Mean-Squared Percent Error` (RMSPE) is the metric Kaggle used for this competition."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inv_y(a): return np.exp(a)\n",
    "\n",
    "def exp_rmspe(y_pred, targ):\n",
    "    targ = inv_y(targ)\n",
    "    pct_var = (targ - inv_y(y_pred))/targ\n",
    "    return math.sqrt((pct_var**2).mean())\n",
    "\n",
    "max_log_y = np.max(yl)\n",
    "y_range = (0, max_log_y*1.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create ModelData object\n",
    "\n",
    "Very similar to the image recognition process\n",
    "- find training dataset\n",
    "- find test set\n",
    "- set a learner\n",
    "- fit and go\n",
    "But since we are not doing images, but structured data: `ColumnarModelData`\n",
    "\n",
    "- PATH - where to store everything that you save later\n",
    "- val_idx - which we will put in the validation set\n",
    "- df - dataframe\n",
    "- yl - target (dependent variable)\n",
    "- cat_flds - which things we want to treat as categorical. At this time everything is a number\n",
    "\n",
    "We can create a ModelData object directly from the data frame, passing it the test dataframe (df_test).\n",
    "We must tell it which variables to treat as categorical (`cat_flds`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = ColumnarModelData.from_data_frame(PATH, val_idx, df, yl.astype(np.float32), \n",
    "                                       cat_flds=cat_vars, \n",
    "                                       bs=64, #bs=128,\n",
    "                                       test_df=df_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some categorical variables have a lot more levels than others. Store, in particular, has over a thousand!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_sz = [(c, len(joined_samp[c].cat.categories)+1) for c in cat_vars]\n",
    "#cat_sz"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Embeddings\n",
    "We use the *cardinality* of each variable (that is, its number of unique values) to decide how large to make its *embeddings*. Each level will be associated with a vector with length defined as below.  (We define the dimensionality of the embeddings).   In NLP models it was found empiracally that you need about 600, because human languages are complex. But for some categories there is very little need for so many, eg for a StateHoliday.\n",
    "JH rule of thumb is to look at how many discrite values the category has, and make the dimensionality of the embedding half of that, but not more than 50 (heuristic). `(c, min(50, (c+1)//2))`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "emb_szs = [(c, min(50, (c+1)//2)) for _,c in cat_sz] #Heuristic for size of embedding\n",
    "#emb_szs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#??md.get_learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get_learner and find Learning rate\n",
    "0.04 is the dropout at the start, \n",
    "[1000, 500] are how many activation to start\n",
    "[0.001,0.01] how much dropout in the later layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = md.get_learner(emb_szs, len(df.columns)-len(cat_vars), 0.04, 1, [1000,500], [0.001,0.01], y_range=y_range)\n",
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a4cb9babde964cb3ae6a62226e1293ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 51%|█████     | 7708/15193 [01:40<01:37, 76.81it/s, loss=0.833]"
     ]
    }
   ],
   "source": [
    "m.lr_find()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYIAAAEOCAYAAACEiBAqAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3Xl4VOX5xvHvk4U9BIEgqwKCIrKI\noqiggogirq1Wa6t1p7Y/l1pbBZe6K621tVo3al1q3cVaKyAqiqIiEDZBQED2PexbQrb398cMQ5ZJ\nMgmZeWcy9+e6cuWcM2d5kpPMPWd7X3POISIiySvFdwEiIuKXgkBEJMkpCEREkpyCQEQkySkIRESS\nnIJARCTJKQhERJKcgkBEJMkpCEREkpyCQEQkyaX5LiASLVu2dB07dvRdhohIQpkxY8Ym51xWVfMl\nRBB07NiR7Oxs32WIiCQUM1sRyXw6NSQikuQUBCIiSU5BICKS5BQEIiJJTkEgIpLkFAQiIkmuzgfB\n0pxd7Mkv9F2GiEjcqtNBsCe/kNMe+5xTH53kuxQRkbhVp4PgqyWbAcjZuddzJSIi8atOB0Fmw/TQ\n8LRlWzxWIiISv+p0EOQXFoeGd+/VdQIRkXDqdBCUvEj80LgFHisREYlfdToIhr8yIzS8ZOMuj5WI\niMSvOh0EIiJStaQKgr2FRb5LEBGJO0kVBB/P3+C7BBGRuFOngyDFSo8XFjk/hYiIxLGE6KGspr65\nYzDb9xSwdU8BFz83hfyi4qoXEhFJMnX6iKBVRgO6HpzBIc0bAXDbO996rkhEJP7U6SDYp0WTer5L\nEBGJW0kRBOmp+3/M/MJi8gp095CIyD5JEQQA9YJhcPhd4+l294eeqxERiR9RCwIze8HMNprZvBLT\nmpvZx2a2OPj9oGhtv6zCYl0oFhEJJ5pHBC8BQ8tMGwFMdM51BSYGx2OiuMydo8VlJ4iIJKmoBYFz\n7gugbNvP5wMvB4dfBi6I1vbLeu26fqXGN+1WHwUiIhD7awQHO+fWAQS/t4rVhru0alJqfN6a7bHa\ntIhIXIvbi8VmNtzMss0sOycn54DX1yqjQalxtUYqIhIQ6yDYYGZtAILfN1Y0o3NutHOur3Oub1ZW\nVq1s/NNbT+X1604ASt9SKiKSzGL9bvg+cEVw+Argv7HceOesJvRsnwnAff+bH8tNi4jErWjePvo6\nMAU4wsxWm9k1wChgiJktBoYEx2OqUXpqrDcpIhLXotbonHPu0gpeGhytbUYiJcVIMejfpaXPMkRE\n4kZSnijv1b6Z7xJEROJGUgZB4/qp7MlXe0MiIpCkQdAwPY1123J9lyEiEheSMgg+WbCBtdvzWLh+\nh+9SRES8S8og2Gfku3N9lyAi4l1SBsEHNw4A4NxebT1XIiLiX1IGQbtmDQG4/wM9VCYikpRBkNFg\n/+MTq7fu8ViJiIh/SRkEaSXaGRrwx888ViIi4l9SBgFAz3aZvksQEYkLSRsEI4d1812CiEhciFpb\nQ/HupMNaktEgjayM+r5LERHxKmmPCADOP7ot2/YU+C5DRMSrpA6CjAbp7MwrwDl1ZC8iySupg6Bx\nvVQKihwXPzeF7OVbfJcjIuJFUgfBxwsCPWVOX76Vi56d4rkaERE/kjoIurdp6rsEERHvkjoIbjm9\na6nxJRt3eqpERMSfpA6Clk1K3zq6YrOamxCR5JPUQZCSYhxxcAbHdTwIQL2WiUhSSuogAJhwyyn8\n4xd9AdiwI89zNSIisZf0QQCB5wkAVm3RqSERST4KAiA1xQB4ecoKz5WIiMSegqCMeWu2+y5BRCSm\nFARlvD5tpe8SRERiSkEQ9Oq1/QBYsG6H50pERGJLQRB0WFYTAGau3Oa5EhGR2PISBGZ2i5l9Z2bz\nzOx1M2vgo46SDm6qfglEJDnFPAjMrB1wE9DXOdcDSAV+Gus6yjIzzHxXISISe75ODaUBDc0sDWgE\nrPVURymZDQPPE+wt1BPGIpI8Yh4Ezrk1wJ+BlcA6YLtz7qNY1xFOWkrg1/HGtFWeKxERiR0fp4YO\nAs4HOgFtgcZmdlmY+YabWbaZZefk5MSktutP7QxA22YNY7I9EZF44OPU0OnAMudcjnOuAHgXOKns\nTM650c65vs65vllZWTEp7ITOLQB47vMfYrI9EZF44CMIVgInmFkjMzNgMLDAQx3l7LtGkL1iq+dK\nRERix8c1gqnAO8BMYG6whtGxriOcDs0bhYZ35BV4rEREJHa83DXknLvHOdfNOdfDOXe5c26vjzoq\n89RnS3yXICISE3qyuIwXrgz0TfDc50s9VyIiEhsKgjJS9FSZiCQZBUEZA49oBaCnjEUkaSgIwmhS\nPw3n4Julm32XIiISdQqCMPY1QDdDt5GKSBJQEIQxOtiZfYP0VM+ViIhEn4IgjM4tG1M/LYUfcnb5\nLkVEJOoUBGGYGXsLi3lt6kpmr1JHNSJStykIqjBVF4xFpI5TEFTg1wMPA+CR8QuZv1b9GItI3aUg\nqMBtQ7uFhoc9MdljJSIi0aUgEBFJcgqCSky89VTfJYiIRJ2CoBKHZTXxXYKISNQpCKpww6AuACzb\ntNtzJSIi0aEgqEK9tMCvaNCfJ/ktREQkShQEVTj/6La+SxARiSoFQRUObdE4NFxc7DxWIiISHQqC\nCFx5UkcAxs1b57cQEZEoUBBEYECXlgDc8NosxsxY7bkaEZHapSCIQNtmDUPDt749h/Xb8zxWIyJS\nuxQEEWjbrEGp8RWbdSupiNQdCoIIZDZMB6BD88CRwbsz1/gsR0SkVikIImBmfDNyMB/ceDIAb2av\n8lyRiEjtSfNdQKJondmg6plERBKQjghqaEdege8SRERqhYKgms7u1QaApz/7wXMlIiK1Q0FQTSPP\nCnRY8+znCgIRqRu8BIGZNTOzd8xsoZktMLMTfdRRE1kZ9X2XICJSq3wdEfwN+NA51w3oDSzwVEe1\n1U9LpXNWoP0hNU0tInVBzIPAzJoCpwD/BHDO5TvntsW6jgOxNCcQAJMX53iuRETkwPk4IugM5AAv\nmtksM3vezBpXtVA8ef26EwBokJ7quRIRkQMXURCY2c1m1tQC/mlmM83sjBpuMw04BnjGOdcH2A2M\nCLPN4WaWbWbZOTnx9cm7zyHNALjtnW89VyIicuAiPSK42jm3AzgDyAKuAkbVcJurgdXOuanB8XcI\nBEMpzrnRzrm+zrm+WVlZNdxUdJQ8Eti8a6/HSkREDlykQWDB78OAF51zc0pMqxbn3HpglZkdEZw0\nGJhfk3XFg2Mf/MR3CSIiByTSIJhhZh8RCIIJZpYBFB/Adm8EXjWzb4GjgYcPYF1eZN91uu8SRERq\nRaRtDV1D4A17qXNuj5k1J3B6qEacc7OBvjVdPh60bLL/eYKNO/NolaG2iEQkMUV6RHAi8L1zbpuZ\nXQbcBWyPXlmJ4Y8X9gRg5eY9nisREam5SIPgGWCPmfUGbgNWAP+KWlUJ4thDmwOwaquCQEQSV6RB\nUOicc8D5wN+cc38DMqJXVmJof1Cgo5pVW3I9VyIiUnORBsFOMxsJXA6MNbNUID16ZSWGfbeR/uXj\nReQVFHmuRkSkZiINgkuAvQSeJ1gPtAMejVpVCWjCd+t9lyAiUiMRBUHwzf9VINPMzgHynHNJf40A\n4H83DADg5jdme65ERKRmIm1i4mJgGvAT4GJgqpldFM3CEsURrQOXSjq2aOS5EhGRmon0OYI7geOc\ncxsBzCwL+IRA8xBJrV5aCj3bZTJ3zXa27M6neeN6vksSEamWSK8RpOwLgaDN1Vi2zpu7JvBIxeDH\nJvktRESkBiJ9M//QzCaY2ZVmdiUwFhgXvbISy75+jDMbJv2NVCKSgCI6NeSc+72ZXQj0J9DY3Gjn\n3H+iWlkCeepnx7Azbxrb9uT7LkVEpNoivUaAc24MMCaKtSS0jPppfLEoR+0OiUjCqfTUkJntNLMd\nYb52mtmOWBWZCGau3ArA8Q9N9FyJiEj1VBoEzrkM51zTMF8ZzrmmsSoyETx+ydG+SxARqRHd+VNL\n+nVuwdX9OwGwbrvaHhKRxKEgqEX9OgdaIz3zr194rkREJHIKglp0WrdWAOzIK/RciYhI5BQEtSg9\ndf+v84KnvqLjiLFqlVRE4p6CoJZdfsKhAMxetQ2ALxdv8lmOiEiVFAS17N7zjio1viOvwFMlIiKR\nURDUstQUKzX+27fmeKpERCQyCoIoWD7qbJY+PCw0Pi/YKJ2ISDxSEERJSopxTrAxuhe+XOa5GhGR\niikIoujvPzsGCISCiEi8UhBE2cFN6/POjNU453yXIiISloIgyk46rCUAG3fu9VyJiEh4CoIou/CY\n9gD8kLPLcyUiIuEpCKLskOaBTu3/O2ut50pERMLzFgRmlmpms8zsA181xEKH5g0BeDN7FUs26qhA\nROKPzyOCm4EFHrcfE2b77xg6/S+f89s3Z3usRkSkPC9BYGbtgbOB531sP9b29VMA8O6sNbqDSETi\niq8jgseB24BiT9uPqT+c273U+Ph56z1VIiJSXsyDwMzOATY652ZUMd9wM8s2s+ycnJwYVRc9Pzw8\njOGndAZgzVb1YCYi8cPHEUF/4DwzWw68AZxmZv8uO5NzbrRzrq9zrm9WVlasa6x1qSnGrWccDsBD\n4+r8pRERSSAxDwLn3EjnXHvnXEfgp8CnzrnLYl2HD/XTUn2XICJSjp4j8GROsOMaERHfvAaBc26S\nc+4cnzXE2l1nHwnAmJmrPVciIhKgI4IYu2ZA4FbSf01Z4bkSEZEABUGMlXzA7LiHPvFYiYhIgILA\ng4m3ngpAjlokFZE4oCDw4LCsJqHhhet3eKxERERB4M2fLuoFoIboRMQ7BYEn5/VuC8ANr83yXImI\nJDsFgScN0vc/XDblh80eKxGRZKcg8Gj05ccCsHLLbs+ViEgyUxB41L9LoD/jLxZt8lyJiCQzBYFH\njeunAbB2u1ojFRF/FASeDe7Wilkrt1FcrM5qRMQPBYFn+y4ad75jHLe+NYdpy7Z4rkhEko2CwLMR\nZ3ULDY+ZuZqLn5visRoRSUYKAs86NG/EncOOLDXtsY++91SNiCQjBUEcuO6Uzrx6bb/Q+JOfLvFY\njYgkGwVBnOjfpSXLR50dGv/PLPVXICKxoSCIM29ffyIAt7w5h8++3+i5GhFJBgqCOHPMIQeFhq96\ncTp78gs9ViMiyUBBEGdSU4wfHh4WGr/yxekeqxGRZKAgiEOpKcbCB4YCMG3ZFrbuzvdckYjUZQqC\nONUgPZUWjesB0OeBj9m9V6eIRCQ6FARx7PITDw0NH3XPBI+ViEhdpiCIYzcP7spdZ+9/2KzjiLG8\nOX2lx4pEpC5SEMQxM+PakzvTvU3T0LTbx8z1WJGI1EUKggQw9qYBHNV2fxjszCvwWI2I1DUKggRg\nZoy96WT+8Yu+ACzaoA7vRaT2KAgSSO/2mQD8b85az5WISF0S8yAwsw5m9pmZLTCz78zs5ljXkKha\nNW0AwEtfL6egqNhzNSJSV/g4IigEbnXOHQmcAPyfmXX3UEdC63rneABen7aSOau2ea5GRBJZzIPA\nObfOOTczOLwTWAC0i3UdiWrsTQNCw7/69wxGvjuX85/6ymNFIpLovF4jMLOOQB9gqs86EslRbTN5\n/JKjARg/b31o+pgZarZaRGrGWxCYWRNgDPAb59yOMK8PN7NsM8vOycmJfYFx7MyjWpebduvbc9Qm\nkYjUiJcgMLN0AiHwqnPu3XDzOOdGO+f6Ouf6ZmVlxbbAONewXip/uqgX95zbvVRnNn0e+NhjVSKS\nqHzcNWTAP4EFzrm/xHr7dcXFfTtwVf9OAHzy21ND05fm6BkDEakeH0cE/YHLgdPMbHbwa1hVC0nF\nurRqwvBTOgNw2mOfs2TjTs8ViUgi8XHX0JfOOXPO9XLOHR38GhfrOuqaO4btb5zu9L98wdSlmz1W\nIyKJxJxzvmuoUt++fV12drbvMuJeXkER3e7+sNS0BukpLHzgLE8ViYhPZjbDOde3qvnUxEQd0iA9\ntdTFY4C8gmIue34qW3RHkYhUQEcEddSMFVu58Jmvy02fdudgWmU08FCRiMRapEcECoI6ruOIsRW+\ntuyRYQRu4hKRukinhgSApQ8P47v7zqR10/JHAYMf+7zctLyCIlZt2UMifEAQkdqhI4Iksm1PPkff\nX/qhs26tM2jVtAHPXnYMjeql0fXOcRQUBf4mnry0D7kFRfzk2PY6chBJQDo1JGEVFwf298l/+ow1\n23JLvXbp8Yfw+rTyfSJ/cOMAerTLjEl9IlJ7dGpIwkpJMVJSjK9GnFbutXAhAHDu378kr6CI5ycv\nZePOPN6duZqlObvYnhvoMnPttlzWbMstdzpJbR+JJAYdESSxgqJinpn0A30Oacbl/5wWmj7//jPZ\nuqeA/qM+DU1rUj+NXXsLq1xn9l2nk5tfxFOfLeGN6asA6Nkuk/dv6K/TSyIxplNDUi2bdu3ll6/M\n4PFLjqZD80YATF6cw5eLN/HcF0sjXk+jeqnsyS8qN33ybYNC6xWR2NCpIamWlk3qM+ZXJ5V6sz65\naxYjhx3JmUcdHJrWo11TGqanVriecCEAgWsSuyM4ogDYW1jEoxMWhq5niEh0pfkuQOLfbUO7MeG7\nDbw5/AT6dW5BQVExH8/fwNCjWmNG6JTPHf+Zy2tTA9cZmjeuxx/O6c7p3Q+mxz0TADjqngkseegs\n0lIr//xx/EMT2Z5bwPRlW3nr+hOj+8OJiI4IpGqHZTVh+aiz6de5BQDpqSkM69mGlBQrdd7/D+cE\nup4+9tCDmHn3EC7o044m9dM4u2eb0Dxd7hzPmX/9Iux2tu7O54mJi0MXoact36KmMURiQNcIJCbu\n/M9cXp1a+q6kr0acRnqKMW35Ftof1IgLKul7efFDZ5FexZFEZX7I2cXgxz5nxFndOOLgDAZ1a1Xj\ndYkkCl0slrhz2fNT+XLJpojm/fiWUxgS5shh8m2DaNusIQbkFRaxI7eQ1pmBp6Ynfb+RzIbp9Dnk\nIABy84t46evlnNu7DZ8t3Mjd//0utJ6Zdw+heeN6B/5DicQxBYHEndz8ItZtz+XN6asqvRNp0YNn\nUS8thcPvGk9+YXGV6z27VxvWbstl1sptACwfdTbTl2/hJ89OqXLZKSNPo01mw8h/CJEEoiCQuFay\n74RDmjfi39f045MFGxjUrRWdWjYuNW9lDeeFc1X/jrz41fKI51/2yDAeHLuAoT1ac1zH5tXalkg0\nOecO6PkbBYHEPecc89bsoGf7ypuv2LW3kPlrdzDi3W9ZmrM7NL1Hu6bMW7Mj4u3dfU53rjqpI+Pm\nreOG12aFpo88qxuPjF8IUK4/BxFfOo4Yy0+P68CoC3vVeB0KAkkaH85bz6tTV/DyVcfT+Y79vZ6e\n1aM1j/6kN03qh79Let6a7Zzz5Jelpk27czAHNapX6YXpcXPXccwhB4WuTQA8OXExM1Zu5fFLjqZZ\nI117kMot3rCTNs0ahv3b/Oi79bzyzQomLw5cTzuQDyd6oEySxtAerXnlmn6kpBgLHxgamv7MZcdW\nGAIAR7VtWm7a8Q9NpOud4ytcZu22XH796kxuH/MtEHj4bfQXP/DYx4uY9H0OR9//Mau27DmAnya8\nomJHQVHV10sq4pwr1xbU7r2FPDJ+AXkF4R8ClOgoLnYM+esX9LhnQtjm3oe/MiMUAgA5O/dGvSYd\nEUhSc86xdU8BBUXF9Ht4Ymj67UO78auBh4XGb3x9Fumpxrsz14Sm/fOKvlzzcvm/y4z6acy978yw\n2/tu7XaOalu9llydc3QaGTjS+f2ZR/B/g7rUePnhp3RmxNBuvDNjNbcFwwzgu/vOpHEwNPMKiigq\ndqHxkgqKig/oNl6BTxdu4OqX9v/dlPzEf+wDH7O5xLMzh2U15qWrjq9x8yw6NSRSTU9OXMxjHy8K\njf+oTzuuGdCp3Omjinx5+yAG/PGz0Pi8+86kxz0TuKp/R0aedSSH37X/SOO3Qw6nR7umZDZM59hD\nK75AvXjDTiYu3Mio4DUMCLxxLNqwk7XbcjmhcwsaVNLkB4Q/BRbO8lFnl7owX/INasnGnZz+l8Dt\nvI9e1Iuf9O0Qdh3/nb2Gm9+YHVjmobP47PscrvtXNt3bNGXczSdXWUNl9uQX8utXZ3LHsCM5/OCM\ncq9PXpxDfmExJx7Wgp15hRxcojOm4mJX6rThs5cdy4CuLSs9YtzHOceH89YzddkWrj/1MA5qnE69\n1BT25Bext7CYhumpNKxX+T4oacyM1dz69pxS087t3ZYnL+0T+v1fO6ATdwUf0DwQCgKRGvr589/w\n1ZLNFb7esUUjlm/ef/pnWM/W3D60G4e2aMy/v1nBXe/Nq9b2vn9wKPXTUvliUQ5rtuXy6ITvK32i\n+usRp3FSiZZh3/rliRzfqTn/mrKcDs0bMfDwrNCdJl8t2cTPn58aUR0XHN2W92avDY3//swjOK93\nW7JXbOGWN/e/cXVo3pDJt5VvxnzjjjyOL3FUVbYBwul3nk5WRv2Iagnn80U5XPHCNFIMJvzmFLoG\nw2D99jxyC4oY9OdJpeb/3RmHc2X/TjSpn8Zb01eVOgIqac4fziCzUToAhUXF7M4vIrNhYLygqLjS\nU4X7VHQef/zcddRLS2HwkYH2ukqG8h3DuvHwuP0B/9p1/fjZP6ZWur7qUhCIHIBnJv3AHz/c/0/a\nrFE6M+4aghHo0yFn516Gv5LNL048lB/1aV9q2YkLNoQ9ZQRQPy2FvWGejXjt2n78rIo37Ld+eSIX\nPxf+2Yij2jblu7Wl76D6/PcDOfXRSaHxpQ8P4/4P5vPS18vp36UFT/3sGJo1qsc7M1bzuzKfUKNl\n1t1DOKiKB/mKix0fzV/PkO6tSTGYu2Y7PdtlcvMbs3l/zv6gymyYzuw/DAmd9qrIt/eeQa97P6p0\nnuWjzqagqJjjHvqEbXsKQqfKIr11+emfH8OwEk2pAGzetZdjH/wEgHppKdxzbnde/WYl89ftCG2z\n930fhZpU2ee3Qw7npsFdI9puVRQEIgdo1sqtTFm6mV8PrN45eYA5q7ZxfpkmMxrVS+W7+87kljdn\nl/rkHYlPbz2VQ5o3oksEn07DqeoTZsk3vHE3ncywJyaXm2fm3UP4IWdXlQ/qzbx7CIMfm8TWPQVh\nX58y8jR25hVy1YvTeeWa4+mc1SRsLUe2aUrnlo0ZO3ddpdsr6cfHtCt1Haesz38/kOzlW8udmvnp\ncR1C/WeE89p1/TihUws+XbiRa/8V/r3o4r7teSt7NQCTfjeQGSvKb2ef//5ff3p3aAbAjBVbuPCZ\n/b/TP5zTnasHdKqwlupQEIh4lptfRP20FP755TIeGreAufeeQUaDwCmHrbvzuX3Mt9wy5HDO+tv+\nN90PbhxAo3qpHNqiMakp5R8kKigqZs/eIqYs3cSgbq1Yuy2v1CmRC49pz5iZq0st8+FvTqZb6/J3\nSJW0dlsuY79dxzUDOpGSYlzxwjQ+X5RTap59YfLrV2cwbu76Cte1b74P562jTWZDendoxvbcAnrf\nF/5TefZdp/PUZ0v4zeDD6X1/5Z/cIXBh+9WpK0qdVtlnwf1DaVgvlfzCYh4Zv6DUg4XXndyJO8/u\njnOO8fPWM6BrSxZv2MWFz3xd6fYqOl9fVOzYtbeQC576imWbdodZsmJlg7mwqJib35jN2LnrWPrw\nMFLC7PuaUBCIJIj8wuLQheSanBt2zvGbN2fzq4GHhd7wN+7M4+bXZ/PABT3o0qpJFWuo2L5TZE9c\n2ofzercNu20zY29hET//x1RGXdirwu1t31MQ0Rt9ZZ697BiG9gicgnn8k0U8/sliIPB0eLgncK99\nOZtPFmygWaN0pt4xmPpp5S/qXvTM12Sv2ArAoCOy+MWJHbnqpelAZG1S7d5byN3vzePdWeGPRBY/\ndBZFxY6ZK7Zy5YvTmTLyNFo0qfm1kupQEIgkkMKiYlLLNOtdF+3IK2D2ym384oVp/KzfIaH+K0ra\nd/E2N7+oWnfjhOOcY/XW3Cpvv9x3OqqmF2l35hXQM3gdYu69Z3DNy9nUT0vhhSuP83q7bVwHgZkN\nBf4GpALPO+dGVTa/gkCkbtq6O59b357DDad14cdPf82wnq15+ufHxryOvIIitu7JP6AGCIuLHQXF\nxWGPOnyJ2yAws1RgETAEWA1MBy51zs2vaBkFgYhI9cVzExPHA0ucc0udc/nAG8D5HuoQERH8BEE7\noOR9WquD00RExAMfQRDuali581NmNtzMss0sOycnJ8wiIiJSG3wEwWqgZEMl7YFyT9c450Y75/o6\n5/pmZWXFrDgRkWTjIwimA13NrJOZ1QN+CrzvoQ4REQGqbnqvljnnCs3sBmACgdtHX3DOfVfFYiIi\nEiUxDwIA59w4oPKWokREJCbUw4SISJJLiCYmzCwHWFFiUiawvcxs4aa1BDYRe+FqicV6Ip2/qvkq\ne72i1yLZJ8m2PyJdxtf+gOTbJ77+R3ztj0Odc1XfbbOvL9NE+gJGRzgtO17qi8V6Ip2/qvkqe72i\n1yLZJ8m2PyJdxtf+SMZ94ut/JN73R6KeGvpfhNN8qa1aqrueSOevar7KXq/otXjeJ772R6TLJNv+\ngOT7H4nr/ZEQp4ZqysyyXQTtbEhsaH/EH+2T+OJrfyTqEUGkRvsuQErR/og/2ifxxcv+qNNHBCIi\nUrW6fkQgIiJVUBCIiCQ5BYGISJJL2iAws4FmNtnMnjWzgb7rETCzxmY2w8zO8V1LsjOzI4P/G++Y\n2a981yNgZheY2T/M7L9mdkZtrjshg8DMXjCzjWY2r8z0oWb2vZktMbMRVazGAbuABgSaxpYaqqX9\nAXA78FZ0qkwetbE/nHMLnHPXAxcDur30ANXSPnnPOXcdcCVwSa3Wl4h3DZnZKQTexP/lnOsRnBa2\nL2QCLZw+UmYVVwObnHPFZnYw8Bfn3M9jVX9dU0v7oxeBx+sbENg3H8Sm+rqnNvaHc26jmZ0HjAD+\n7px7LVb110W1tU+Cyz0GvOqcm1lb9XlpffRAOee+MLOOZSaH+kIGMLM3gPOdc48AlZ1q2ArUj0ad\nyaI29oeZDQIaA92BXDMb55wrjmrhdVRt/X84594H3jezsYCC4ADU0v+IAaOA8bUZApCgQVCBcH0h\n96toZjP7MXAm0Az4e3RLS0qnS3YmAAAF1klEQVTV2h/OuTsBzOxKgkdrUa0u+VT3/2Mg8GMCH5LU\nZHx0VGufADcCpwOZZtbFOfdsbRVSl4Igor6QQy849y7wbvTKSXrV2h+hGZx7qfZLEar//zEJmBSt\nYgSo/j55AngiGoUk5MXiCkTUF7LEjPZHfNH+iD9xs0/qUhCoL+T4ov0RX7Q/4k/c7JOEDAIzex2Y\nAhxhZqvN7BrnXCGwry/kBcBbTn0hx4T2R3zR/og/8b5PEvL2URERqT0JeUQgIiK1R0EgIpLkFAQi\nIklOQSAikuQUBCIiSU5BICKS5BQEUuvMbFcMtnFehE1b1+Y2B5rZSTVYro+ZPR8cvtLM4qJtKzPr\nWLZZ5DDzZJnZh7GqSfxQEEjcCjbTG5Zz7n3n3KgobLOy9rcGAtUOAuAO4MkaFeSZcy4HWGdm/X3X\nItGjIJCoMrPfm9l0M/vWzO4rMf29YG9k35nZ8BLTd5nZ/WY2FTjRzJab2X1mNtPM5ppZt+B8oU/W\nZvaSmT1hZl+b2VIzuyg4PcXMng5u4wMzG7fvtTI1TjKzh83sc+BmMzvXzKaa2Swz+8TMDg42IXw9\ncIuZzTazk4OflscEf77p4d4szSwD6OWcmxPmtUPNbGLwdzPRzA4JTj/MzL4JrvP+cEdYFujNbayZ\nzTGzeWZ2SXD6ccHfwxwzm2ZmGcFP/pODv8OZ4Y5qzCzVzB4tsa9+WeLl9wD111GXOef0pa9a/QJ2\nBb+fAYwm0MpiCvABcErwtebB7w2BeUCL4LgDLi6xruXAjcHhXwPPB4evJNBhCsBLwNvBbXQn0MY7\nwEUEmlBOAVoT6HviojD1TgKeLjF+EPufur8WeCw4fC/wuxLzvQYMCA4fAiwIs+5BwJgS4yXr/h9w\nRXD4auC94PAHwKXB4ev3/T7LrPdC4B8lxjOBesBS4LjgtKYEWhhuBDQITusKZAeHOwLzgsPDgbuC\nw/WBbKBTcLwdMNf335W+ovdVl5qhlvhzRvBrVnC8CYE3oi+Am8zsR8HpHYLTNwNFwJgy69nXXPgM\nAm3kh/OeC/RhMN8Cvc4BDADeDk5fb2afVVLrmyWG2wNvmlkbAm+uyypY5nSge6C/EACamlmGc25n\niXnaADkVLH9iiZ/nFeBPJaZfEBx+DfhzmGXnAn82sz8CHzjnJptZT2Cdc246gHNuBwSOHoC/m9nR\nBH6/h4dZ3xlArxJHTJkE9skyYCPQtoKfQeoABYFEkwGPOOeeKzUx0OnJ6cCJzrk9ZjaJQBeVAHnO\nuaIy69kb/F5ExX+ze0sMW5nvkdhdYvhJAt2Xvh+s9d4Klkkh8DPkVrLeXPb/bFWJuOEv59wiMzsW\nGAY8YmYfETiFE24dtwAbgN7BmvPCzGMEjrwmhHmtAYGfQ+ooXSOQaJoAXG1mTQDMrJ2ZtSLwaXNr\nMAS6ASdEaftfAhcGrxUcTOBibyQygTXB4StKTN8JZJQY/4hA65EABD9xl7UA6FLBdr4m0PQwBM7B\nfxkc/obAqR9KvF6KmbUF9jjn/k3giOEYYCHQ1syOC86TEbz4nUngSKEYuJxAn7hlTQB+ZWbpwWUP\nDx5JQOAIotK7iySxKQgkapxzHxE4tTHFzOYC7xB4I/0QSDOzb4EHCLzxRcMYAp1/zAOeA6YC2yNY\n7l7gbTObDGwqMf1/wI/2XSwGbgL6Bi+uzidwPr8U59xCAl0LZpR9Lbj8VcHfw+XAzcHpvwF+a2bT\nCJxaCldzT2Camc0G7gQedM7lA5cAT5rZHOBjAp/mnwauMLNvCLyp7w6zvueB+cDM4C2lz7H/6GsQ\nMDbMMlJHqBlqqdPMrIlzbpeZtQCmAf2dc+tjXMMtwE7n3PMRzt8IyHXOOTP7KYELx+dHtcjK6/mC\nQKfqW33VINGlawRS131gZs0IXPR9INYhEPQM8JNqzH8sgYu7BmwjcEeRF2aWReB6iUKgDtMRgYhI\nktM1AhGRJKcgEBFJcgoCEZEkpyAQEUlyCgIRkSSnIBARSXL/D3mKZTz9hvvfAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f26d4a60518>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "m.sched.plot(30) #100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = md.get_learner(emb_szs, len(df.columns)-len(cat_vars), 0.04, 1, [1000,500], [0.001,0.01], y_range=y_range)\n",
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d73810c577a64e3a910d1ba0b711bb00",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  5%|▍         | 702/15193 [00:09<03:07, 77.25it/s, loss=0.503] \n",
      "  5%|▍         | 719/15193 [00:09<03:07, 77.40it/s, loss=0.531]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-4:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/german/anaconda3/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/german/anaconda3/lib/python3.6/site-packages/tqdm/_tqdm.py\", line 144, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"/home/german/anaconda3/lib/python3.6/_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   exp_rmspe                        \n",
      "    0      0.138396   0.262989   165.02122 \n",
      "    1      0.127265   0.268385   159.086876                       \n",
      "    2      0.071071   0.251457   153.722943                       \n",
      "    3      0.079969   0.286809   170.750593                       \n",
      "\n",
      "CPU times: user 13min 43s, sys: 1min 2s, total: 14min 45s\n",
      "Wall time: 13min 14s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([ 0.28681]), 170.7505932963295]"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time m.fit(lr, 4, metrics=[exp_rmspe])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80737bf063984f61ae423454df2b96cf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   exp_rmspe                        \n",
      "    0      0.129908   0.259613   152.273757\n",
      "    1      0.057797   0.26258    158.51999                        \n",
      "    2      0.068189   0.257991   149.226535                       \n",
      "    3      0.051243   0.263498   163.426719                       \n",
      "    4      0.063855   0.271352   166.181679                       \n",
      "\n",
      "CPU times: user 17min 16s, sys: 1min 19s, total: 18min 35s\n",
      "Wall time: 16min 42s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([ 0.27135]), 166.18167927421905]"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time m.fit(lr, 5, metrics=[exp_rmspe], cycle_len=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d6c60f4b638945399cef65622bf4c906",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   exp_rmspe                        \n",
      "    0      0.080181   0.263242   143.500412\n",
      "    1      0.069481   0.26353    167.87209                        \n",
      "    2      0.026753   0.255213   165.762702                       \n",
      "    3      0.042425   0.259249   161.654453                       \n",
      "    4      0.130556   0.267726   175.679363                       \n",
      "    5      0.059325   0.240523   155.852028                       \n",
      "    6      0.052931   0.247094   153.811485                       \n",
      "    7      0.035474   0.244434   154.63188                        \n",
      "    8      0.074629   0.244809   162.972233                       \n",
      "    9      0.072618   0.277004   167.360017                       \n",
      "    10     0.03513    0.251461   158.746426                       \n",
      "    11     0.04639    0.254883   151.896704                       \n",
      "    12     0.046894   0.259423   157.824838                       \n",
      "    13     0.052072   0.283941   160.822069                       \n",
      "    14     0.071888   0.271861   160.449102                       \n",
      "    15     0.037806   0.269049   156.937334                       \n",
      "\n",
      "CPU times: user 55min 31s, sys: 4min 10s, total: 59min 41s\n",
      "Wall time: 53min 38s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([ 0.26905]), 156.93733382238131]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time m.fit(lr, 4, metrics=[exp_rmspe], cycle_len=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## All"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = md.get_learner(emb_szs, len(df.columns)-len(cat_vars),\n",
    "                   0.04, 1, [1000,500], [0.001,0.01], y_range=y_range)\n",
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fc823d4ec6c146fc9064b13533171490",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   exp_rmspe                        \n",
      "    0      0.234306   0.270629   158.721049\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([ 0.27063]), 158.72104863877888]"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(lr, 1, metrics=[exp_rmspe])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "854524669ff84d24879995af03952a7d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   exp_rmspe                        \n",
      "    0      0.069192   0.273726   149.120181\n",
      "    1      0.114563   0.270484   151.180549                       \n",
      "    2      0.105632   0.270051   145.917317                       \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([ 0.27005]), 145.91731712973112]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(lr, 3, metrics=[exp_rmspe])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "68d0fbe4cd8349109ecd95bcb032abaf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   exp_rmspe                        \n",
      "    0      0.075973   0.239576   130.563887\n",
      "    1      0.067593   0.256751   130.264231                       \n",
      "    2      0.052421   0.274901   140.921123                       \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([ 0.2749]), 140.92112338340246]"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.fit(lr, 3, metrics=[exp_rmspe], cycle_len=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = md.get_learner(emb_szs, len(df.columns)-len(cat_vars),0.04, 1, [1000,500], [0.001,0.01], y_range=y_range)\n",
    "lr = 1e-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb8f610b5d2d45c4b6091bdbb3b18d5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   exp_rmspe                        \n",
      "    0      0.164063   0.265729   157.833708\n",
      "    1      0.238327   0.272893   165.037305                       \n",
      "    2      0.113807   0.26575    161.98482                        \n",
      "    3      0.074931   0.252112   161.475302                       \n",
      "\n",
      "CPU times: user 13min 38s, sys: 1min 4s, total: 14min 43s\n",
      "Wall time: 13min 12s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([ 0.25211]), 161.47530176024821]"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time m.fit(lr, 4, metrics=[exp_rmspe])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "166a1d55380f46e88ed9de30c43c9991",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   exp_rmspe                        \n",
      "    0      0.081754   0.253845   155.381808\n",
      "    1      0.066245   0.236513   143.967133                       \n",
      "    2      0.121782   0.230671   141.855501                       \n",
      "    3      0.043868   0.235618   143.619884                       \n",
      "\n",
      "CPU times: user 13min 49s, sys: 1min 2s, total: 14min 52s\n",
      "Wall time: 13min 21s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([ 0.23562]), 143.61988433357672]"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time m.fit(lr, 4, metrics=[exp_rmspe], cycle_len=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "m.save('val0')\n",
    "m.load('val0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "x,y=m.predict_with_targs()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "289.05920944073034"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "exp_rmspe(x,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_test=m.predict(True)  #True to state this is the test set.  predict returns the logs of the predictions\n",
    "\n",
    "pred_test = np.exp(pred_test)  #now get the actuals\n",
    "#pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_test['Sales']=pred_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#joined_test['Sales']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<a href='data/rossmann/tmp/sub.csv' target='_blank'>data/rossmann/tmp/sub.csv</a><br>"
      ],
      "text/plain": [
       "/home/german/fastai/courses/dl1/data/rossmann/tmp/sub.csv"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csv_fn=f'{PATH}tmp/sub.csv'\n",
    "\n",
    "joined_test[['Id','Sales']].to_csv(csv_fn, index=False)\n",
    "\n",
    "FileLink(csv_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RandomForest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "((val,trn), (y_val,y_trn)) = split_by_idx(val_idx, df.values, yl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = RandomForestRegressor(n_estimators=40, max_features=0.99, min_samples_leaf=2,\n",
    "                          n_jobs=-1, oob_score=True)\n",
    "m.fit(trn, y_trn);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.9973536825684356,\n",
       " 0.97633665016753624,\n",
       " 0.99134121749090809,\n",
       " 306.4106112946695)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = m.predict(val)\n",
    "m.score(trn, y_trn), m.score(val, y_val), m.oob_score_, exp_rmspe(preds, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[    1.     ,     5.     ,     3.     ,     7.     ,    31.     ,     1.     ,    25.     ,\n",
       "            1.     ,     3.     ,     1.     ,     0.     ,    16.     ,     1.     ,     5.     ,\n",
       "           31.     ,     1.     ,     2.     ,     6.     ,     1.     ,     1.     ,     2.     ,\n",
       "            6.     ,    -0.53874,     1.02445,     0.81863,     0.32505,     0.61112,    -1.51079,\n",
       "           -1.62656,     0.14844,    -0.14766,    -2.81223,     1.74436,     1.74305,     0.64438,\n",
       "            0.     ,     1.27324,     2.14421,    -0.05103,    -0.2928 ],\n",
       "       [    2.     ,     5.     ,     3.     ,     7.     ,    31.     ,     1.     ,    25.     ,\n",
       "           26.     ,     1.     ,     1.     ,     2.     ,    15.     ,     3.     ,    12.     ,\n",
       "           31.     ,     1.     ,     2.     ,     6.     ,     1.     ,     1.     ,     2.     ,\n",
       "            6.     ,    -0.62957,     0.5519 ,     0.40421,     0.17024,     0.87028,    -0.90502,\n",
       "           -1.2699 ,    -0.97008,    -0.14766,    -0.96164,     1.30344,     1.74305,     0.96507,\n",
       "            0.     ,     1.27324,     2.14421,    -0.05103,    -0.2928 ],\n",
       "       [    3.     ,     5.     ,     3.     ,     7.     ,    31.     ,     1.     ,    25.     ,\n",
       "           26.     ,     1.     ,     1.     ,     2.     ,    14.     ,     4.     ,     7.     ,\n",
       "           31.     ,     1.     ,     2.     ,     6.     ,     1.     ,     1.     ,     2.     ,\n",
       "            6.     ,     1.12989,     0.78817,     0.40421,     0.01544,     0.87028,    -0.98074,\n",
       "           -1.32085,    -0.97008,    -1.1651 ,    -2.19537,     1.83255,     1.74305,     0.64438,\n",
       "            0.     ,     1.27324,     2.14421,    -0.05103,    -0.2928 ],\n",
       "       [    4.     ,     5.     ,     3.     ,     7.     ,    31.     ,     1.     ,    25.     ,\n",
       "            1.     ,     3.     ,     3.     ,     0.     ,    17.     ,     1.     ,     1.     ,\n",
       "           31.     ,     0.     ,     2.     ,     6.     ,     1.     ,     1.     ,     2.     ,\n",
       "            6.     ,    -0.62308,     0.5519 ,     0.54235,     0.47985,     0.09281,    -0.98074,\n",
       "           -1.01514,     0.03659,     0.7002 ,     0.27209,     0.77433,     1.74305,     0.96507,\n",
       "            0.     ,     1.27324,     2.14421,    -0.05103,    -0.2928 ],\n",
       "       [    5.     ,     5.     ,     3.     ,     7.     ,    31.     ,     1.     ,     4.     ,\n",
       "            1.     ,     1.     ,     1.     ,     0.     ,    23.     ,     1.     ,    10.     ,\n",
       "           31.     ,     0.     ,     2.     ,     6.     ,     1.     ,     1.     ,     2.     ,\n",
       "            6.     ,     3.1774 ,     0.67004,     0.68049,     0.63466,    -1.46214,    -1.43507,\n",
       "           -1.21895,    -0.97008,    -0.14766,    -0.96164,     1.47981,     1.74305,     0.64438,\n",
       "            0.     ,     1.27324,     2.14421,    -0.05103,    -0.2928 ],\n",
       "       [    6.     ,     5.     ,     3.     ,     7.     ,    31.     ,     1.     ,    20.     ,\n",
       "            1.     ,     1.     ,     1.     ,     0.     ,    21.     ,     1.     ,    10.     ,\n",
       "           31.     ,     0.     ,     2.     ,     6.     ,     1.     ,     1.     ,     2.     ,\n",
       "            6.     ,    -0.66331,     0.67004,     0.68049,     0.63466,    -1.46214,    -1.43507,\n",
       "           -1.21895,    -0.97008,    -0.14766,    -0.96164,     1.47981,     1.74305,     0.64438,\n",
       "            0.     ,     1.27324,     2.14421,    -0.05103,    -0.2928 ],\n",
       "       [    7.     ,     5.     ,     3.     ,     7.     ,    31.     ,     1.     ,    25.     ,\n",
       "            1.     ,     1.     ,     3.     ,     0.     ,    21.     ,     1.     ,     9.     ,\n",
       "           31.     ,    11.     ,     2.     ,     6.     ,     1.     ,     1.     ,     2.     ,\n",
       "            6.     ,     2.41056,     0.43376,     0.54235,     0.32505,    -0.68467,    -0.98074,\n",
       "           -0.86228,     0.37214,     0.19148,     0.27209,     1.03889,     1.74305,     0.96507,\n",
       "            0.     ,     1.27324,     2.14421,    -0.05103,    -0.2928 ],\n",
       "       [    8.     ,     5.     ,     3.     ,     7.     ,    31.     ,     1.     ,    10.     ,\n",
       "            1.     ,     1.     ,     1.     ,     0.     ,    22.     ,     1.     ,     9.     ,\n",
       "           31.     ,    11.     ,     2.     ,     6.     ,     1.     ,     1.     ,     2.     ,\n",
       "            6.     ,     0.27222,     0.43376,     0.54235,     0.32505,    -0.68467,    -0.98074,\n",
       "           -0.86228,     0.37214,     0.19148,     0.27209,     1.03889,     1.74305,     0.96507,\n",
       "            0.     ,     1.27324,     2.14421,    -0.05103,    -0.2928 ],\n",
       "       [    9.     ,     5.     ,     3.     ,     7.     ,    31.     ,     1.     ,    25.     ,\n",
       "            1.     ,     1.     ,     3.     ,     0.     ,     8.     ,     1.     ,     7.     ,\n",
       "           31.     ,     1.     ,     2.     ,     6.     ,     1.     ,     1.     ,     2.     ,\n",
       "            6.     ,    -0.44013,     0.78817,     0.40421,     0.01544,     0.87028,    -0.98074,\n",
       "           -1.32085,    -0.97008,    -1.1651 ,    -2.19537,     1.83255,     1.74305,     0.64438,\n",
       "            0.     ,     1.27324,     2.14421,    -0.05103,    -0.2928 ],\n",
       "       [   10.     ,     5.     ,     3.     ,     7.     ,    31.     ,     1.     ,    25.     ,\n",
       "            1.     ,     1.     ,     1.     ,     0.     ,    17.     ,     1.     ,     4.     ,\n",
       "           31.     ,     0.     ,     2.     ,     6.     ,     1.     ,     1.     ,     2.     ,\n",
       "            8.     ,    -0.29351,     0.43376,     0.40421,     0.32505,     0.09281,    -0.52642,\n",
       "           -1.01514,    -0.18712,     0.19148,    -0.34478,     1.30344,     1.74305,     0.96507,\n",
       "            0.     ,     1.27324,     2.14421,    -0.05103,    -0.2928 ],\n",
       "       [   11.     ,     5.     ,     3.     ,     7.     ,    31.     ,     1.     ,    25.     ,\n",
       "           26.     ,     1.     ,     3.     ,     2.     ,    19.     ,     5.     ,     9.     ,\n",
       "           31.     ,    11.     ,     2.     ,     6.     ,     1.     ,     1.     ,     2.     ,\n",
       "            6.     ,    -0.57897,     0.43376,     0.54235,     0.32505,    -0.68467,    -0.98074,\n",
       "           -0.86228,     0.37214,     0.19148,     0.27209,     1.03889,     1.74305,     0.96507,\n",
       "            0.     ,     1.27324,     2.14421,    -0.05103,    -0.2928 ],\n",
       "       [   12.     ,     5.     ,     3.     ,     7.     ,    31.     ,     1.     ,     1.     ,\n",
       "           26.     ,     1.     ,     3.     ,     2.     ,     1.     ,     3.     ,     9.     ,\n",
       "           31.     ,    11.     ,     2.     ,     6.     ,     1.     ,     1.     ,     2.     ,\n",
       "            6.     ,    -0.56469,     0.43376,     0.54235,     0.32505,    -0.68467,    -0.98074,\n",
       "           -0.86228,     0.37214,     0.19148,     0.27209,     1.03889,     1.74305,     0.96507,\n",
       "            0.     ,     1.27324,     2.14421,    -0.05103,    -0.2928 ],\n",
       "       [   13.     ,     5.     ,     3.     ,     7.     ,    31.     ,     1.     ,     1.     ,\n",
       "           26.     ,     4.     ,     1.     ,     1.     ,     1.     ,     2.     ,     3.     ,\n",
       "           31.     ,     0.     ,     2.     ,     6.     ,     1.     ,     1.     ,     1.     ,\n",
       "            1.     ,    -0.66331,     1.02445,     0.95677,     0.63466,    -0.81424,    -1.81367,\n",
       "           -1.16799,    -0.41082,    -0.99552,     0.27209,     1.83255,     1.74305,     0.64438,\n",
       "            0.     ,     1.27324,    -0.46637,    -0.05103,     3.41535],\n",
       "       [   14.     ,     5.     ,     3.     ,     7.     ,    31.     ,     1.     ,    17.     ,\n",
       "           26.     ,     1.     ,     1.     ,     2.     ,    22.     ,     4.     ,     7.     ,\n",
       "           31.     ,     1.     ,     2.     ,     6.     ,     1.     ,     1.     ,     2.     ,\n",
       "            6.     ,    -0.53485,     0.78817,     0.40421,     0.01544,     0.87028,    -0.98074,\n",
       "           -1.32085,    -0.97008,    -1.1651 ,    -2.19537,     1.83255,     1.74305,     0.64438,\n",
       "            0.     ,     1.27324,     2.14421,    -0.05103,    -0.2928 ],\n",
       "       [   15.     ,     5.     ,     3.     ,     7.     ,    31.     ,     1.     ,    25.     ,\n",
       "           26.     ,     4.     ,     3.     ,     2.     ,    18.     ,     4.     ,     9.     ,\n",
       "           31.     ,    11.     ,     2.     ,     6.     ,     1.     ,     1.     ,     2.     ,\n",
       "            6.     ,    -0.17024,     0.43376,     0.54235,     0.32505,    -0.68467,    -0.98074,\n",
       "           -0.86228,     0.37214,     0.19148,     0.27209,     1.03889,     1.74305,     0.96507,\n",
       "            0.     ,     1.27324,     2.14421,    -0.05103,    -0.2928 ],\n",
       "       [   16.     ,     5.     ,     3.     ,     7.     ,    31.     ,     1.     ,     1.     ,\n",
       "            1.     ,     1.     ,     3.     ,     0.     ,     1.     ,     1.     ,     2.     ,\n",
       "           31.     ,     0.     ,     2.     ,     6.     ,     1.     ,     1.     ,     2.     ,\n",
       "            3.     ,    -0.27923,     1.02445,     0.68049,     0.17024,    -0.81424,    -1.73795,\n",
       "           -1.52466,    -0.74638,    -0.31723,    -2.19537,     2.27347,     1.74305,     0.64438,\n",
       "            0.     ,     1.27324,     2.14421,    -0.05103,    -0.2928 ],\n",
       "       [   17.     ,     5.     ,     3.     ,     7.     ,    31.     ,     1.     ,    25.     ,\n",
       "           26.     ,     1.     ,     1.     ,     2.     ,    13.     ,     3.     ,    12.     ,\n",
       "           31.     ,     1.     ,     2.     ,     6.     ,     1.     ,     1.     ,     2.     ,\n",
       "            6.     ,    -0.69704,     0.5519 ,     0.40421,     0.17024,     0.87028,    -0.90502,\n",
       "           -1.2699 ,    -0.97008,    -0.14766,    -0.96164,     1.30344,     1.74305,     0.96507,\n",
       "            0.     ,     1.27324,     2.14421,    -0.05103,    -0.2928 ],\n",
       "       [   18.     ,     5.     ,     3.     ,     7.     ,    31.     ,     1.     ,    25.     ,\n",
       "           26.     ,     4.     ,     3.     ,     2.     ,    18.     ,     5.     ,    12.     ,\n",
       "           31.     ,     1.     ,     2.     ,     6.     ,     1.     ,     1.     ,     2.     ,\n",
       "            6.     ,     1.09226,     0.5519 ,     0.40421,     0.17024,     0.87028,    -0.90502,\n",
       "           -1.2699 ,    -0.97008,    -0.14766,    -0.96164,     1.30344,     1.74305,     0.96507,\n",
       "            0.     ,     1.27324,     2.14421,    -0.05103,    -0.2928 ],\n",
       "       [   19.     ,     5.     ,     3.     ,     7.     ,    31.     ,     1.     ,     1.     ,\n",
       "           26.     ,     1.     ,     3.     ,     3.     ,     1.     ,     4.     ,     7.     ,\n",
       "           31.     ,     1.     ,     2.     ,     6.     ,     1.     ,     1.     ,     2.     ,\n",
       "            6.     ,    -0.28313,     0.78817,     0.40421,     0.01544,     0.87028,    -0.98074,\n",
       "           -1.32085,    -0.97008,    -1.1651 ,    -2.19537,     1.83255,     1.74305,     0.64438,\n",
       "            0.     ,     1.27324,     2.14421,    -0.05103,    -0.2928 ],\n",
       "       [   20.     ,     5.     ,     3.     ,     7.     ,    31.     ,     1.     ,    25.     ,\n",
       "           26.     ,     4.     ,     1.     ,     2.     ,    17.     ,     7.     ,     3.     ,\n",
       "           31.     ,     0.     ,     2.     ,     6.     ,     1.     ,     1.     ,     1.     ,\n",
       "            1.     ,    -0.39991,     1.02445,     0.95677,     0.63466,    -0.81424,    -1.81367,\n",
       "           -1.16799,    -0.41082,    -0.99552,     0.27209,     1.83255,     1.74305,     0.64438,\n",
       "            0.     ,     1.27324,    -0.46637,    -0.05103,     3.41535],\n",
       "       ..., \n",
       "       [ 1096.     ,     2.     ,     1.     ,     1.     ,     1.     ,     2.     ,     1.     ,\n",
       "            1.     ,     1.     ,     3.     ,     3.     ,     1.     ,     7.     ,     7.     ,\n",
       "            1.     ,    11.     ,     2.     ,     1.     ,     2.     ,     2.     ,     5.     ,\n",
       "            2.     ,    -0.55691,    -0.7476 ,    -0.83904,    -0.60378,     0.09281,     0.98799,\n",
       "            0.76818,     1.82621,     2.39592,     0.27209,    -0.1957 ,    -0.44029,    -1.1836 ,\n",
       "            0.     ,    -0.7854 ,     2.14421,    -0.05103,    -0.2928 ],\n",
       "       [ 1097.     ,     2.     ,     1.     ,     1.     ,     1.     ,     2.     ,    25.     ,\n",
       "            1.     ,     2.     ,     2.     ,     0.     ,    10.     ,     1.     ,     8.     ,\n",
       "            1.     ,    11.     ,     2.     ,     1.     ,     2.     ,     2.     ,     5.     ,\n",
       "            2.     ,    -0.61011,    -0.7476 ,    -0.56276,    -0.29417,    -0.16635,     0.07935,\n",
       "            0.46247,     0.37214,     1.20892,     1.50581,    -2.57668,    -0.44029,    -1.1836 ,\n",
       "            0.     ,    -0.7854 ,     2.14421,    -0.05103,    -0.2928 ],\n",
       "       [ 1098.     ,     2.     ,     1.     ,     1.     ,     1.     ,     2.     ,    25.     ,\n",
       "            1.     ,     1.     ,     1.     ,     0.     ,    12.     ,     1.     ,    10.     ,\n",
       "            1.     ,    11.     ,     2.     ,     1.     ,     2.     ,     2.     ,     3.     ,\n",
       "            2.     ,    -0.46608,    -0.86574,    -0.7009 ,    -0.44898,    -1.59172,    -0.4507 ,\n",
       "           -0.19991,     0.37214,     1.20892,     0.88895,     0.50978,    -0.44029,    -1.1836 ,\n",
       "            0.     ,    -0.7854 ,     2.14421,    -0.05103,    -0.2928 ],\n",
       "       [ 1099.     ,     2.     ,     1.     ,     1.     ,     1.     ,     2.     ,     1.     ,\n",
       "            1.     ,     1.     ,     3.     ,     2.     ,    21.     ,     6.     ,     9.     ,\n",
       "            1.     ,    11.     ,     2.     ,     1.     ,     2.     ,     2.     ,     5.     ,\n",
       "            2.     ,    -0.67758,    -0.7476 ,    -0.42462,     0.01544,     0.87028,     1.59376,\n",
       "            2.19483,     0.03659,     0.7002 ,     0.27209,     0.59796,    -0.44029,    -1.1836 ,\n",
       "            0.     ,    -0.7854 ,     2.14421,    -0.05103,    -0.2928 ],\n",
       "       [ 1100.     ,     2.     ,     1.     ,     1.     ,     1.     ,     2.     ,     1.     ,\n",
       "           26.     ,     1.     ,     1.     ,     2.     ,     1.     ,     4.     ,     7.     ,\n",
       "            1.     ,    11.     ,     2.     ,     1.     ,     2.     ,     2.     ,     5.     ,\n",
       "            2.     ,    -0.63346,    -0.7476 ,    -0.83904,    -0.60378,     0.09281,     0.98799,\n",
       "            0.76818,     1.82621,     2.39592,     0.27209,    -0.1957 ,    -0.44029,    -1.1836 ,\n",
       "            0.     ,    -0.7854 ,     2.14421,    -0.05103,    -0.2928 ],\n",
       "       [ 1101.     ,     2.     ,     1.     ,     1.     ,     1.     ,     2.     ,     4.     ,\n",
       "            1.     ,     4.     ,     3.     ,     0.     ,    20.     ,     1.     ,     9.     ,\n",
       "            1.     ,    11.     ,     2.     ,     1.     ,     2.     ,     2.     ,     5.     ,\n",
       "            2.     ,    -0.17673,    -0.7476 ,    -0.42462,     0.01544,     0.87028,     1.59376,\n",
       "            2.19483,     0.03659,     0.7002 ,     0.27209,     0.59796,    -0.44029,    -1.1836 ,\n",
       "            0.     ,    -0.7854 ,     2.14421,    -0.05103,    -0.2928 ],\n",
       "       [ 1102.     ,     2.     ,     1.     ,     1.     ,     1.     ,     2.     ,     2.     ,\n",
       "            1.     ,     1.     ,     1.     ,     2.     ,    20.     ,     7.     ,     3.     ,\n",
       "            1.     ,     2.     ,     2.     ,     1.     ,     3.     ,     2.     ,     5.     ,\n",
       "            2.     ,    -0.59324,    -0.86574,    -1.25345,    -1.68742,     0.87028,     1.06371,\n",
       "            0.56437,     0.03659,    -0.99552,     0.27209,    -0.81299,    -0.44029,    -1.1836 ,\n",
       "            0.     ,    -0.7854 ,     2.14421,    -0.05103,    -0.2928 ],\n",
       "       [ 1103.     ,     2.     ,     1.     ,     1.     ,     1.     ,     2.     ,    25.     ,\n",
       "            1.     ,     4.     ,     3.     ,     1.     ,    14.     ,     6.     ,     5.     ,\n",
       "            1.     ,    11.     ,     2.     ,     1.     ,     2.     ,     2.     ,     8.     ,\n",
       "            2.     ,    -0.52966,    -0.7476 ,    -0.56276,    -0.44898,    -0.03677,     0.45795,\n",
       "            0.46247,     0.03659,     0.36106,     0.27209,     0.68615,    -0.44029,    -1.1836 ,\n",
       "            0.     ,    -0.7854 ,     2.14421,    -0.05103,    -0.2928 ],\n",
       "       [ 1104.     ,     2.     ,     1.     ,     1.     ,     1.     ,     2.     ,    11.     ,\n",
       "           26.     ,     4.     ,     1.     ,     2.     ,    20.     ,     4.     ,     3.     ,\n",
       "            1.     ,     2.     ,     2.     ,     1.     ,     3.     ,     2.     ,     5.     ,\n",
       "            2.     ,    -0.66979,    -0.86574,    -1.25345,    -1.68742,     0.87028,     1.06371,\n",
       "            0.56437,     0.03659,    -0.99552,     0.27209,    -0.81299,    -0.44029,    -1.1836 ,\n",
       "            0.     ,    -0.7854 ,     2.14421,    -0.05103,    -0.2928 ],\n",
       "       [ 1105.     ,     2.     ,     1.     ,     1.     ,     1.     ,     2.     ,    25.     ,\n",
       "            1.     ,     3.     ,     3.     ,     1.     ,    16.     ,     6.     ,     7.     ,\n",
       "            1.     ,    11.     ,     2.     ,     1.     ,     2.     ,     2.     ,     5.     ,\n",
       "            2.     ,    -0.66071,    -0.7476 ,    -0.83904,    -0.60378,     0.09281,     0.98799,\n",
       "            0.76818,     1.82621,     2.39592,     0.27209,    -0.1957 ,    -0.44029,    -1.1836 ,\n",
       "            0.     ,    -0.7854 ,     2.14421,    -0.05103,    -0.2928 ],\n",
       "       [ 1106.     ,     2.     ,     1.     ,     1.     ,     1.     ,     2.     ,    16.     ,\n",
       "            1.     ,     1.     ,     3.     ,     2.     ,    19.     ,     6.     ,     9.     ,\n",
       "            1.     ,    11.     ,     2.     ,     1.     ,     2.     ,     2.     ,     5.     ,\n",
       "            2.     ,    -0.01194,    -0.7476 ,    -0.42462,     0.01544,     0.87028,     1.59376,\n",
       "            2.19483,     0.03659,     0.7002 ,     0.27209,     0.59796,    -0.44029,    -1.1836 ,\n",
       "            0.     ,    -0.7854 ,     2.14421,    -0.05103,    -0.2928 ],\n",
       "       [ 1107.     ,     2.     ,     1.     ,     1.     ,     1.     ,     2.     ,     7.     ,\n",
       "           26.     ,     1.     ,     1.     ,     2.     ,    20.     ,     3.     ,     3.     ,\n",
       "            1.     ,     2.     ,     2.     ,     1.     ,     3.     ,     2.     ,     5.     ,\n",
       "            2.     ,    -0.52187,    -0.86574,    -1.25345,    -1.68742,     0.87028,     1.06371,\n",
       "            0.56437,     0.03659,    -0.99552,     0.27209,    -0.81299,    -0.44029,    -1.1836 ,\n",
       "            0.     ,    -0.7854 ,     2.14421,    -0.05103,    -0.2928 ],\n",
       "       [ 1108.     ,     2.     ,     1.     ,     1.     ,     1.     ,     2.     ,    25.     ,\n",
       "            1.     ,     1.     ,     1.     ,     0.     ,    12.     ,     1.     ,    10.     ,\n",
       "            1.     ,    11.     ,     2.     ,     1.     ,     2.     ,     2.     ,     3.     ,\n",
       "            2.     ,    -0.63346,    -0.86574,    -0.7009 ,    -0.44898,    -1.59172,    -0.4507 ,\n",
       "           -0.19991,     0.37214,     1.20892,     0.88895,     0.50978,    -0.44029,    -1.1836 ,\n",
       "            0.     ,    -0.7854 ,     2.14421,    -0.05103,    -0.2928 ],\n",
       "       [ 1109.     ,     2.     ,     1.     ,     1.     ,     1.     ,     2.     ,    21.     ,\n",
       "           26.     ,     3.     ,     1.     ,     2.     ,    19.     ,     5.     ,     3.     ,\n",
       "            1.     ,     2.     ,     2.     ,     1.     ,     3.     ,     2.     ,     5.     ,\n",
       "            2.     ,    -0.25069,    -0.86574,    -1.25345,    -1.68742,     0.87028,     1.06371,\n",
       "            0.56437,     0.03659,    -0.99552,     0.27209,    -0.81299,    -0.44029,    -1.1836 ,\n",
       "            0.     ,    -0.7854 ,     2.14421,    -0.05103,    -0.2928 ],\n",
       "       [ 1110.     ,     2.     ,     1.     ,     1.     ,     1.     ,     2.     ,    25.     ,\n",
       "            1.     ,     3.     ,     3.     ,     0.     ,    18.     ,     1.     ,     1.     ,\n",
       "            1.     ,    11.     ,     2.     ,     1.     ,     2.     ,     2.     ,     5.     ,\n",
       "            2.     ,    -0.58675,    -0.7476 ,    -0.42462,    -0.13937,     0.87028,     0.30651,\n",
       "            0.61532,     0.37214,     1.03935,     0.27209,     0.4216 ,    -0.44029,    -1.1836 ,\n",
       "            0.     ,    -0.7854 ,     2.14421,    -0.05103,    -0.2928 ],\n",
       "       [ 1111.     ,     2.     ,     1.     ,     1.     ,     1.     ,     2.     ,     1.     ,\n",
       "            1.     ,     1.     ,     1.     ,     2.     ,    22.     ,     6.     ,     7.     ,\n",
       "            1.     ,    11.     ,     2.     ,     1.     ,     2.     ,     2.     ,     5.     ,\n",
       "            2.     ,    -0.457  ,    -0.7476 ,    -0.83904,    -0.60378,     0.09281,     0.98799,\n",
       "            0.76818,     1.82621,     2.39592,     0.27209,    -0.1957 ,    -0.44029,    -1.1836 ,\n",
       "            0.     ,    -0.7854 ,     2.14421,    -0.05103,    -0.2928 ],\n",
       "       [ 1112.     ,     2.     ,     1.     ,     1.     ,     1.     ,     2.     ,    25.     ,\n",
       "            1.     ,     3.     ,     3.     ,     0.     ,    14.     ,     1.     ,     7.     ,\n",
       "            1.     ,    11.     ,     2.     ,     1.     ,     2.     ,     2.     ,     5.     ,\n",
       "            2.     ,    -0.45959,    -0.7476 ,    -0.83904,    -0.60378,     0.09281,     0.98799,\n",
       "            0.76818,     1.82621,     2.39592,     0.27209,    -0.1957 ,    -0.44029,    -1.1836 ,\n",
       "            0.     ,    -0.7854 ,     2.14421,    -0.05103,    -0.2928 ],\n",
       "       [ 1113.     ,     2.     ,     1.     ,     1.     ,     1.     ,     2.     ,     1.     ,\n",
       "            1.     ,     1.     ,     3.     ,     0.     ,     1.     ,     1.     ,     9.     ,\n",
       "            1.     ,    11.     ,     2.     ,     1.     ,     2.     ,     2.     ,     5.     ,\n",
       "            2.     ,     0.49799,    -0.7476 ,    -0.42462,     0.01544,     0.87028,     1.59376,\n",
       "            2.19483,     0.03659,     0.7002 ,     0.27209,     0.59796,    -0.44029,    -1.1836 ,\n",
       "            0.     ,    -0.7854 ,     2.14421,    -0.05103,    -0.2928 ],\n",
       "       [ 1114.     ,     2.     ,     1.     ,     1.     ,     1.     ,     2.     ,     1.     ,\n",
       "            1.     ,     1.     ,     3.     ,     0.     ,     1.     ,     1.     ,     6.     ,\n",
       "            1.     ,    11.     ,     2.     ,     1.     ,     2.     ,     2.     ,     5.     ,\n",
       "            2.     ,    -0.59064,    -0.7476 ,    -0.56276,    -0.29417,     0.87028,     1.3666 ,\n",
       "            1.02294,     1.93806,     1.88721,     0.27209,    -0.1957 ,    -0.44029,    -1.1836 ,\n",
       "            0.     ,    -0.7854 ,     2.14421,    -0.05103,    -0.2928 ],\n",
       "       [ 1115.     ,     2.     ,     1.     ,     1.     ,     1.     ,     2.     ,     1.     ,\n",
       "           26.     ,     4.     ,     3.     ,     3.     ,     1.     ,     5.     ,     5.     ,\n",
       "            1.     ,    11.     ,     2.     ,     1.     ,     2.     ,     2.     ,     8.     ,\n",
       "            2.     ,    -0.00935,    -0.7476 ,    -0.56276,    -0.44898,    -0.03677,     0.45795,\n",
       "            0.46247,     0.03659,     0.36106,     0.27209,     0.68615,    -0.44029,    -1.1836 ,\n",
       "            0.     ,    -0.7854 ,     2.14421,    -0.05103,    -0.2928 ]])"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.exp(preds)\n",
    "trn\n",
    "#forest_test = np.\n",
    "#forest_test['Sales']=np.exp(preds)\n",
    "#forest_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "#train.StateHoliday = train.StateHoliday != \"0\""
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "toc": {
   "nav_menu": {
    "height": "173px",
    "width": "251px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
