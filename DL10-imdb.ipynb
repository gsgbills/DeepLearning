{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## IMDb\n",
    "<div class=\"alert alert-block alert-info\">NB: This notebook is based on [Fastai Notebook Lesson 10](https://github.com/fastai/fastai/blob/master/courses/dl2/imdb.ipynb) \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Sun May 13 08:24:54 2018'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import time\n",
    "t0 = time.clock()\n",
    "time.ctime(time.time())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`fastai.text` replaces the torchtext library, and supersedes the fastai.nlp library, but retains many of the key functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.text import *\n",
    "import html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `fastai.text` module introduces several custom tokens.\n",
    "\n",
    "We need to download the [IMDB large movie reviews](http://ai.stanford.edu/~amaas/data/sentiment/)\n",
    "Direct link : [Link](http://ai.stanford.edu/~amaas/data/sentiment/aclImdb_v1.tar.gz) \n",
    "and untar it into the PATH location. \n",
    "```\n",
    "curl -OL http://files.fast.ai/data/aclImdb.tgz\n",
    "tar -xzf aclImdb.tgz\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH=Path('data/aclImdb/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Standardize format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get the Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLAS_PATH=Path('data/imdb_clas/')\n",
    "CLAS_PATH.mkdir(exist_ok=True)\n",
    "\n",
    "LM_PATH=Path('data/imdb_lm/')\n",
    "LM_PATH.mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The imdb dataset has 3 classes: positive, negative and unsupervised (sentiment is unknown). \n",
    "- 75k training reviews(12.5k pos, 12.5k neg, 50k unsup)\n",
    "- 25k validation reviews(12.5k pos, 12.5k neg & no unsup)\n",
    "See README file in the imdb corpus for further information about the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "CLASSES = ['neg', 'pos', 'unsup']\n",
    "\n",
    "def get_texts(path):\n",
    "    texts,labels = [],[]\n",
    "    for idx,label in enumerate(CLASSES):\n",
    "        for fname in (path/label).glob('*.*'):\n",
    "            texts.append(fname.open('r').read())\n",
    "            labels.append(idx)\n",
    "    return np.array(texts),np.array(labels)\n",
    "\n",
    "trn_texts,trn_labels = get_texts(PATH/'train')\n",
    "val_texts,val_labels = get_texts(PATH/'test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75000, 25000)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(trn_texts),len(val_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shuffle the training and validation data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use `np.random.permutation()` to create a set of randomly permuted indexes in the corresponding range, \n",
    "which are then used to *shuffle* the text reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(42)\n",
    "trn_idx = np.random.permutation(len(trn_texts))\n",
    "val_idx = np.random.permutation(len(val_texts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([23481, 13606, 13639, ..., 22410,  9907, 24798]),\n",
       " array([26837,  2592, 18359, ..., 54886,   860, 15795]))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "val_idx, trn_idx  # randomly permutated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Shuffle the training and validation sets (texts and labels) with the right indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_texts = trn_texts[trn_idx]\n",
    "trn_labels = trn_labels[trn_idx]\n",
    "\n",
    "val_texts = val_texts[val_idx]\n",
    "val_labels = val_labels[val_idx]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Format using new \"standard\"\n",
    "Fastai adopts a recent (LeCun paper) \"standard\" format for NLP datasets: label followed by text columns. \n",
    "For IMDB, there is only one text column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names = ['labels','text']\n",
    "\n",
    "df_trn = pd.DataFrame({'text':trn_texts, 'labels':trn_labels}, columns=col_names)\n",
    "df_val = pd.DataFrame({'text':val_texts, 'labels':val_labels}, columns=col_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that for clasification we remove label $2$ 'unsup' as they are not useful for training.\n",
    "Hovewer, for the LM they will be useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn[df_trn['labels']!=2].to_csv(CLAS_PATH/'train.csv', header=False, index=False)\n",
    "df_val.to_csv(CLAS_PATH/'test.csv', header=False, index=False)\n",
    "\n",
    "(CLAS_PATH/'classes.txt').open('w').writelines(f'{o}\\n' for o in CLASSES)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create data for Language Model (LM)\n",
    "The LM's learns the **structure** of English, \n",
    "by trying to predict the next word given a set of previous words(ngrams).\n",
    "Since the LM does not classify reviews, the labels are ignored.\n",
    "The LM can benefit from all the textual data, so we include the unsup/unclassified movie reviews.\n",
    "\n",
    "First concat all the train (pos/neg/unsup = **75k**) and test (pos/neg=**25k**) reviews into a big chunk of **100k** reviews. \n",
    "```\n",
    "np.concatenate([trn_texts,val_texts])\n",
    "```\n",
    "Then use sklearn splitter to divide up the 100k texts into 90% training and 10% validation sets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(90000, 10000)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trn_texts,val_texts = sklearn.model_selection.train_test_split(\n",
    "    np.concatenate([trn_texts,val_texts]), test_size=0.1)\n",
    "\n",
    "len(trn_texts), len(val_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn = pd.DataFrame({'text':trn_texts, 'labels':[0]*len(trn_texts)}, columns=col_names)\n",
    "df_val = pd.DataFrame({'text':val_texts, 'labels':[0]*len(val_texts)}, columns=col_names)\n",
    "\n",
    "df_trn.to_csv(LM_PATH/'train.csv', header=False, index=False)\n",
    "df_val.to_csv(LM_PATH/'test.csv', header=False, index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing - Language model tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section, we start cleaning up the messy text. There are 2 main activities we need to perform:\n",
    "\n",
    "1. Clean up extra spaces, tab chars, new ln chars and other characters and replace them with standard ones\n",
    "2. Tokenize the data. \n",
    "\n",
    "fastai now adds `Tokenizer()`, a faster, parallel/multicore version of the [spaCy tokenizer](http://spacy.io), \n",
    "which uses all the CPU cores. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before passing it to spaCy, there are a few things that need to be fixed....\n",
    "Many kinds of different things on different text datasets, which we would like to \"clean-up\"\n",
    "`fixup(x)` includes some fixes that JH found useful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "re1 = re.compile(r'  +')\n",
    "\n",
    "def fixup(x):\n",
    "    x = x.replace('#39;', \"'\").replace('amp;', '&').replace('#146;', \"'\").replace(\n",
    "        'nbsp;', ' ').replace('#36;', '$').replace('\\\\n', \"\\n\").replace('quot;', \"'\").replace(\n",
    "        '<br />', \"\\n\").replace('\\\\\"', '\"').replace('<unk>','u_n').replace(' @.@ ','.').replace(\n",
    "        ' @-@ ','-').replace('\\\\', ' \\\\ ')\n",
    "    return re1.sub(' ', html.unescape(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tokenization is splitting the text into separate tokens, each token assigned a unique index, \n",
    "which our models can use.  \n",
    "Tokens are \"kind-of\" words, but not exactly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#These strings do not appear often.\n",
    "BOS = 'xbos'  # beginning-of-sentence tag\n",
    "FLD = 'xfld'  # data field tag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The above tokens are very useful. For example, now we have a new one, forget about the old, etc.\n",
    "\n",
    "Tokenizing is slow, so fastai will use multi-processing using `proc_all_mp`.\n",
    "`partition_by_cores(texts)` divides the texts into pieces for the number of cores in the computer.\n",
    "Few things in python leverages multi-threading...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_texts(df, n_lbls=1):\n",
    "    labels = df.iloc[:,range(n_lbls)].values.astype(np.int64)\n",
    "    texts = f'\\n{BOS} {FLD} 1 ' + df[n_lbls].astype(str)\n",
    "    for i in range(n_lbls+1, len(df.columns)): texts += f' {FLD} {i-n_lbls} ' + df[i].astype(str)\n",
    "    texts = texts.apply(fixup).values.astype(str)\n",
    "\n",
    "    tok = Tokenizer().proc_all_mp(partition_by_cores(texts))\n",
    "    return tok, list(labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_all(df, n_lbls):\n",
    "    tok, labels = [], []\n",
    "    for i, r in enumerate(df):\n",
    "        print(i)\n",
    "        tok_, labels_ = get_texts(r, n_lbls)\n",
    "        tok += tok_;\n",
    "        labels += labels_\n",
    "    return tok, labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use pandas, which can be very inneficient... like python, in storage, they use a lot of RAM.\n",
    "Thus, few people in NLP work on large corpuses, as tools make it difficult.\n",
    "JH has used the code below with corpuses of over 1B words.\n",
    "We use an appropriate chunksize as the tokenization process is memory intensive.\n",
    "With `chunksize` pandas does not return a full dataset, but returns an iterator that we can use.\n",
    "Above, in `get_all` we use `enumerate(df)` which uses the iterator to go thru the chunks of data of size `chunksize`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunksize=24000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn = pd.read_csv(LM_PATH/'train.csv', header=None, chunksize=chunksize)\n",
    "df_val = pd.read_csv(LM_PATH/'test.csv', header=None, chunksize=chunksize)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now tokenize, this will take time, so `get_all()` prints the current i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "2\n",
      "3\n",
      "0\n"
     ]
    }
   ],
   "source": [
    "tok_trn, trn_labels = get_all(df_trn, 1)\n",
    "tok_val, val_labels = get_all(df_val, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "(LM_PATH/'tmp').mkdir(exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n xbos xfld 1 i have just seen this movie , on tv . saturday , drinking tea , and using the remote control hoping for a miracle in channel 12 of montevideo , uruguay . and it appears ! ! ... this is a very nice movie , you can laugh , think , cry and find references to events , characters , behaviors of many people at their time . and seeing on 2005 , after how comics and cartoons have evolved it is a pleasure . it was a pity that i could not enjoy billy cristal \\'s voice cause it was in spanish . it contains many jokes , references to particular historical situations . it portraits quite well the life of athletes and how maybe they give all their life such in gymnastics . i really enjoy this \" before born \" joke about her .'"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(tok_trn[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(LM_PATH/'tmp'/'tok_trn.npy', tok_trn)\n",
    "np.save(LM_PATH/'tmp'/'tok_val.npy', tok_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_trn = np.load(LM_PATH/'tmp'/'tok_trn.npy')\n",
    "tok_val = np.load(LM_PATH/'tmp'/'tok_val.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the most frequently used tokens in the vocalubalary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('the', 1208506),\n",
       " ('.', 993054),\n",
       " (',', 986089),\n",
       " ('and', 588243),\n",
       " ('a', 583522),\n",
       " ('of', 524941),\n",
       " ('to', 485834),\n",
       " ('is', 394273),\n",
       " ('it', 341863),\n",
       " ('in', 337992),\n",
       " ('i', 308495),\n",
       " ('this', 270551),\n",
       " ('that', 261509),\n",
       " ('\"', 237372),\n",
       " (\"'s\", 221370),\n",
       " ('-', 188030),\n",
       " ('was', 180707),\n",
       " ('\\n\\n', 179108),\n",
       " ('as', 166065),\n",
       " ('with', 159368),\n",
       " ('for', 158837),\n",
       " ('movie', 157400),\n",
       " ('but', 150598),\n",
       " ('film', 144190),\n",
       " ('you', 124110)]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freq = Counter(p for o in tok_trn for p in o)\n",
    "freq.most_common(25)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The *vocab* is the **unique set of all tokens** in our dataset. \n",
    "The vocab provides a way to replace each word in our datasets with a unique integer (index).\n",
    "In a large corpus of data one might find rare words which are only used a few times. \n",
    "We discard such rare words as it would be hard to learn meaningful patterns out of them.\n",
    "\n",
    "We limit our vocabulary to 60K words, and we set a minimum frequency of word occurence to 2 times. \n",
    "NLP practicioners observed that a maximum vocab of 60K usually yields good results for classification tasks. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_vocab = 60000\n",
    "min_freq = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we get the `max_vocab` (60000) most frequent ones, only picking those that appear more than `min_freq`.\n",
    "Then add 2 more tokens, a token for `_unk_` and a token for `_pad_`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "itos = [o for o,c in freq.most_common(max_vocab) if c>min_freq]\n",
    "itos.insert(1, '_pad_')\n",
    "itos.insert(0, '_unk_')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a *reverse mapping* called `stoi` to lookup the index of a given token. \n",
    "`stoi` has the same number of elements as `itos`. \n",
    "We use a high performance container called \n",
    "[collections.defaultdict](https://docs.python.org/2/library/collections.html#collections.defaultdict) \n",
    "to store our stoi mapping.\n",
    "\n",
    "If we find something not in the dictionary `enumerate(itos)`, we replace it with `\\_unk_` (token 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60002"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stoi = collections.defaultdict(lambda:0, {v:k for k,v in enumerate(itos)})\n",
    "len(itos)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we call `stoi` for every word on every sentence in the training and validation sets, to get the numericalaized versions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_lm = np.array([[stoi[o] for o in p] for p in tok_trn])\n",
    "val_lm = np.array([[stoi[o] for o in p] for p in tok_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'40 41 42 39 12 36 56 130 13 23 4 28 264 3 2386 4 2522 3964 4 5 800 1 2700 1141 1377 22 6 5097 11 1234 1771 7 32109 4 25539 3 5 10 748 49 49 92 13 9 6 69 358 23 4 26 77 447 4 122 4 1531 5 185 1988 8 713 4 120 4 12747 7 127 99 44 78 74 3 5 335 28 3203 4 118 108 3815 5 2193 36 8627 10 9 6 1757 3 10 18 6 2320 14 12 95 32 389 1407 41984 16 581 1165 10 18 11 1917 3 10 1424 127 653 4 1988 8 898 1296 1128 3 10 12748 204 89 1 135 7 14066 5 108 299 45 220 43 78 135 159 11 21328 3 12 83 389 13 15 179 1370 15 997 58 55 3'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(str(o) for o in trn_lm[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets save the vocabularies for training and validation, to be able to later interpret them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(LM_PATH/'tmp'/'trn_ids.npy', trn_lm)\n",
    "np.save(LM_PATH/'tmp'/'val_ids.npy', val_lm)\n",
    "pickle.dump(itos, open(LM_PATH/'tmp'/'itos.pkl', 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_lm = np.load(LM_PATH/'tmp'/'trn_ids.npy')\n",
    "val_lm = np.load(LM_PATH/'tmp'/'val_ids.npy')\n",
    "itos = pickle.load(open(LM_PATH/'tmp'/'itos.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60002, 90000)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vs=len(itos)\n",
    "vs,len(trn_lm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## wikitext103 conversion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets build an English language model for the IMDB corpus, using *transfer learning*, a recent idea for NLP.\n",
    "We use a `pre-trained` LM that has been trained on a large generic corpus (_like wikipedia articles_),\n",
    "transfer it's knowledge to a target LM, and then the weights can be fine-tuned.\n",
    "\n",
    "Our source LM is the wikitext103 LM \n",
    "[Dataset by Stephen Merity @ Salesforce Research.](https://www.salesforce.com/products/einstein/ai-research/the-wikitext-dependency-language-modeling-dataset/)\n",
    "The language model for wikitext103 (AWD LSTM) has been pre-trained (by JH?) and the weights can be downloaded \n",
    "[here](http://files.fast.ai/models/wt103/). Our target LM is the IMDB LM. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! wget -nH -r -np -P {PATH} http://files.fast.ai/models/wt103/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The pre-trained LM weights have an embedding size of 400, 1150 hidden units and just 3 layers. \n",
    "We need to match these values  with the target `IMDB LM` so that the weights can be loaded up."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "em_sz,nh,nl = 400,1150,3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "PRE_PATH = PATH/'models'/'wt103'\n",
    "PRE_LM_PATH = PRE_PATH/'fwd_wt103.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/german/DeepLearning'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgts = torch.load(PRE_LM_PATH, map_location=lambda storage, loc: storage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We calculate `row_m`, the mean of the layer0 encoder weights. \n",
    "This mean (the average embedding weight) is used to assign weights to unknown tokens (as default initialization) when we transfer to target IMDB LM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "enc_wgts = to_np(wgts['0.encoder.weight'])\n",
    "row_m = enc_wgts.mean(0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NB:** The LM for wikitext103 was done with a different vocabulary, indexes. \n",
    "Fortunately, we do have access to that vocabulary in `itos_wt103.pkl`\n",
    "So, before we try to transfer the knowledge from wikitext to the IMDB LM, we match up the vocab words and their indexes. \n",
    "We use the defaultdict container once again, to assign mean weights to unknown IMDB tokens that do not exist in wikitext103.\n",
    "`itos2` and `stoi2` are for wikitext103.\n",
    "Here we use $-1$ to indicate unknown word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "itos2 = pickle.load((PRE_PATH/'itos_wt103.pkl').open('rb'))\n",
    "stoi2 = collections.defaultdict(lambda:-1, {v:k for k,v in enumerate(itos2)})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To convert, first we create a np zeros array.\n",
    "Then we go thru all our vocabulary (`itos`), and look up the word in the 2nd dataset \n",
    "```\n",
    "r = stoi2[w]\n",
    "```\n",
    "Then if the word was not found (not $-1$), then we use the corresponding `enc_wgts`, else the special `row_m`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_w = np.zeros((vs, em_sz), dtype=np.float32)\n",
    "for i,w in enumerate(itos):\n",
    "    r = stoi2[w]\n",
    "    new_w[i] = enc_wgts[r] if r>=0 else row_m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We now overwrite the weights into the wgts odict.\n",
    "The decoder module, which we will explore in detail is also loaded with the same weights due to an idea called weight tying."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "wgts['0.encoder.weight'] = T(new_w)\n",
    "wgts['0.encoder_with_dropout.embed.weight'] = T(np.copy(new_w))\n",
    "wgts['1.decoder.weight'] = T(np.copy(new_w))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have the weights prepared, we are ready to create and start training our new IMDB language pytorch model!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Language model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use a Language Model, which gives much better results than embeddings. For years most NLP researchers are attached to embeddings, which is a fixed model. We knew on CV that this does not work (it was hyper-columns). Fine-tuning the entire model works much better.\n",
    "\n",
    "The model will have a backbone (the IMDB LM pre-trained with wikitext) and a custom head (a linear classifier). \n",
    "\n",
    "### Backbone\n",
    "In this section we will focus on the backbone LM and the next section will talk about the classifier custom head."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd=1e-7\n",
    "bptt=70\n",
    "bs=42   #52\n",
    "opt_fn = partial(optim.Adam, betas=(0.8, 0.99))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NB: the total length of the training LM is `t= len(np.concatenate(trn_lm))`, (here $\\approx 25M$). \n",
    "If we use a batch size of, e.g., bs=64, then we will be creating 64 batches of  size $t \\div bs$, (here $\\approx 390K$)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25012685, 390823)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = len(np.concatenate(trn_lm))\n",
    "t, t//64"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The LM is stateful. \n",
    "The **goal** of the LM is to learn to **predict a word/token** given a preceeding set of words(tokens). \n",
    "\n",
    "We take all the movie reviews (90k training set and 10k validation set) and concatenate them to form long strings of tokens. \n",
    "We use text.py `LanguageModelLoader` class, that\n",
    "takes a concatenated string of tokens and returns a data loader for `bptt`-sized mini batches. \n",
    "So we have bs=64 columns by `len(np.concatenate(trn_lm)) // bs` rows.\n",
    "And we grab, at each time, `bptt` rows.\n",
    "\n",
    "Since we are predicting words using ngrams, we want our next batch to line up with the end-points of the previous mini-batch's items. \n",
    "batch-size is constant, but the fastai library expands and contracts bptt each mini-batch using a clever stochastic implementation of a batch. \n",
    "(original credits attributed to [Smerity](https://twitter.com/jeremyphoward/status/980227258395770882))\n",
    "\n",
    "**NB:** The `LanguageModelLoader` can not shuffle the data, as we would normally do, \n",
    "because a language model needs to learn sequentially, the context of the sentence matters a lot. \n",
    "Since we can't do that, lets try to change the size...\n",
    "But if we always grab `bptt` sized, then we always will get the same data in all epochs...\n",
    "Hence, fastai uses Merity's trick, to adjust the *length*. \n",
    "In 95% of the cases it uses `bptt` as defined, but in 5% it divides `bptt` by 2.\n",
    "Then it makes the sequence length a normally distributed random number, with a mean of `bptt`, and a std of 5.\n",
    "So the sequence length is `bptt`-ish, every time we get a size of slightly different batches.\n",
    "\n",
    "```\n",
    "bptt = self.bptt if np.random.random() < 0.95 else self.bptt / 2.\n",
    "seq_len = max(5, int(np.random.normal(bptt, 5)))\n",
    "```\n",
    "\n",
    "`bptt` (*also known traditionally in NLP LM as ngrams*) in fastai LMs is approximated to a std. deviation around 70, by perturbing the sequence length on a per-batch basis. \n",
    "This is akin to shuffling our data in computer vision, only that in NLP we cannot shuffle inputs and we have to maintain statefulness. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_dl = LanguageModelLoader(np.concatenate(trn_lm), bs, bptt)\n",
    "val_dl = LanguageModelLoader(np.concatenate(val_lm), bs, bptt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In `text.py` we have a special modeldata object class for LMs called `LanguageModelData` \n",
    "to which we can pass the training and validation loaders and get in return the model itself."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See `LanguageModelData()` in text.py, to review how this class is defined. [1:10].\n",
    "fastai uses `to_gpu()` as a more flexible approach to choose where to put the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = LanguageModelData(PATH, 1, vs, trn_dl, val_dl, bs=bs, bptt=bptt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NB:** Droputs are important!. JH setup the dropouts for the model, with values chosen after experimentation.  \n",
    "We may need to update them for custom LMs.\n",
    "For example, we can change the weighting factor `dwfactor` (=0.7 here) based on the amount of data available. \n",
    "JH claims that all what is needed is to change `dwfactor`.\n",
    "The more data that is available, the less dropout that is needed, hence a lower `dwfactor`.\n",
    "For small datasets, we can reduce overfitting by choosing a higher dropout factor. \n",
    "**No other dropout value requires tuning**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "dwfactor = 0.7\n",
    "drops = np.array([0.25, 0.1, 0.2, 0.02, 0.15])*dwfactor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Review of dropout types in Stephen Merity's [Regularizing and Optimizing LSTM Language Models](https://arxiv.org/abs/1708.02182)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first tune the last embedding layer so that the missing tokens initialized with mean weights get tuned properly. So we freeze everything except the last layer.\n",
    "\n",
    "We also keep track of the *accuracy* metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner= md.get_model(opt_fn, em_sz, nh, nl, \n",
    "    dropouti=drops[0], dropout=drops[1], wdrop=drops[2], dropoute=drops[3], dropouth=drops[4])\n",
    "\n",
    "learner.metrics = [accuracy]\n",
    "learner.freeze_to(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.model.load_state_dict(wgts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We set learning rates and fit our IMDB LM. We first run one epoch to tune the last layer which contains the embedding weights. This should help the missing tokens in the *wikitext103* learn better weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=1e-3\n",
    "lrs = lr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NB:** Use of `use_clr(a,b)`  This is based on Leslie Smith paper [Cyclical Learning Rates for Training Neural Networks](https://arxiv.org/abs/1506.01186).\n",
    "Here the `lr` value represents the maximum value that the learning rate may take.\n",
    "`a`, is the scale between the minimum and your maximum, i.e., by how much the learning rate is divided to get the minimum value. \n",
    "`b` is the split of the cycle between increasing and decreasing: \n",
    "For example, with a=20, b=5:  use_clr(20,5), given lr=0.01, begins at $0.01 / 20 = 0.0005$,\n",
    "with 1/5 of growth and 4/5 of descent.  Leslie recommends using this for a single cycle only."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6ff064725d9143e5a55d25714618382a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                     \n",
      "    0      4.692012   4.448833   0.257947  \n",
      "\n",
      "CPU times: user 20min 24s, sys: 8min 40s, total: 29min 5s\n",
      "Wall time: 28min 52s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([4.44883]), 0.25794688757426354]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time learner.fit(lrs/2, 1, wds=wd, use_clr=(32,2), cycle_len=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NB** we track `accuracy`, i.e., the rate it predicts the target word correctly. \n",
    "`accuracy` is a good metric to check, but it is **not** part of our loss function as it can get \"bumpy\". \n",
    "We only minimize Cross-Entropy Loss in the LM.\n",
    "There are lots of problems with comparing based on CEL... basically because if penalizes models that are not so sure, ie lack confidence...  Accuracy tells us how good we are doing in our predictions, and is more stable.\n",
    "That is why we track both.\n",
    "**TODO: How does this relate to MIT work on confidence?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save('lm_last_ft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.load('lm_last_ft')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.unfreeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8f03766b2b5247a19c9d4276e4180249",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                     \n",
      "    0      4.81424    4.635004   0.244239  \n",
      "\n"
     ]
    }
   ],
   "source": [
    "learner.lr_find(start_lr=lrs/10, end_lr=lrs*10, linear=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4dea910d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "70272b08f98647928b483b7143c036f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=15), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                     \n",
      "    0      4.384418   4.171102   0.285469  \n",
      "    1      4.264403   4.103605   0.291715                     \n",
      "    2      4.191735   4.057564   0.296622                     \n",
      "    3      4.17492    4.030737   0.299519                     \n",
      "    4      4.159534   4.011856   0.301418                     \n",
      "    5      4.087927   3.998196   0.303012                     \n",
      "    6      4.066455   3.986265   0.30448                      \n",
      "    7      4.097224   3.975422   0.305758                     \n",
      "    8      4.018887   3.969066   0.306902                     \n",
      "    9      4.020799   3.96008    0.307912                     \n",
      "    10     3.994351   3.95426    0.308849                     \n",
      "    11     3.973335   3.947343   0.309582                     \n",
      "    12     3.954658   3.941512   0.310499                     \n",
      "    13     3.983358   3.934531   0.311326                     \n",
      "    14     3.959226   3.93117    0.311791                     \n",
      "\n",
      "CPU times: user 5h 48min 29s, sys: 2h 25min 3s, total: 8h 13min 32s\n",
      "Wall time: 8h 10min 48s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([3.93117]), 0.31179063867782536]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time learner.fit(lrs, 1, wds=wd, use_clr=(20,10), cycle_len=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After training for a while (15 cycles) we get a CEL of $\\approx 3.9.$.\n",
    "The **Perplexity** metric of the LM is the exponent of the CEL.  Lower perplexity is better.\n",
    "In 2017, perplexity state-of-the-art was above 100, now we reach $\\approx 50$.\n",
    "NLP is rapidly advancing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "51.00583306460888"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "math.exp(3.9)   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We save the trained model weights `lm1`.\n",
    "Separately, we save the encoder `lm1_enc` part of the LM model.\n",
    "That is, we save the `RNN_encoder()` part, but we do not save the `LinearDecoder()`. We don't care about the LM generator any more.\n",
    "The `lm1_enc` will be the backbone in the classification task model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "learner.save('lm1')\n",
    "\n",
    "learner.save_encoder('lm1_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4e0914f588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learner.sched.plot_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier tokens"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The classifier model is basically a linear layer custom head on top of the LM backbone. Setting up the classifier data is similar to the LM data setup except that we cannot use the unsup movie reviews this time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_trn = pd.read_csv(CLAS_PATH/'train.csv', header=None, chunksize=chunksize)\n",
    "df_val = pd.read_csv(CLAS_PATH/'test.csv', header=None, chunksize=chunksize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "1\n",
      "0\n",
      "1\n"
     ]
    }
   ],
   "source": [
    "tok_trn, trn_labels = get_all(df_trn, 1)\n",
    "tok_val, val_labels = get_all(df_val, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "(CLAS_PATH/'tmp').mkdir(exist_ok=True)\n",
    "\n",
    "np.save(CLAS_PATH/'tmp'/'tok_trn.npy', tok_trn)\n",
    "np.save(CLAS_PATH/'tmp'/'tok_val.npy', tok_val)\n",
    "\n",
    "np.save(CLAS_PATH/'tmp'/'trn_labels.npy', trn_labels)\n",
    "np.save(CLAS_PATH/'tmp'/'val_labels.npy', val_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "tok_trn = np.load(CLAS_PATH/'tmp'/'tok_trn.npy')\n",
    "tok_val = np.load(CLAS_PATH/'tmp'/'tok_val.npy')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**NB:** We don't create a new `itos` vocabulary, we want to use the **same** as we used in the language model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60002"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "itos = pickle.load((LM_PATH/'tmp'/'itos.pkl').open('rb'))\n",
    "stoi = collections.defaultdict(lambda:0, {v:k for k,v in enumerate(itos)})\n",
    "len(itos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_clas = np.array([[stoi[o] for o in p] for p in tok_trn])\n",
    "val_clas = np.array([[stoi[o] for o in p] for p in tok_val])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(CLAS_PATH/'tmp'/'trn_ids.npy', trn_clas)\n",
    "np.save(CLAS_PATH/'tmp'/'val_ids.npy', val_clas)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets create the final model, a classifier as a custom linear head over the trained IMDB backbone. \n",
    "The steps to create the classifier model are similar to the ones for the LM."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_clas = np.load(CLAS_PATH/'tmp'/'trn_ids.npy')\n",
    "val_clas = np.load(CLAS_PATH/'tmp'/'val_ids.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_labels = np.squeeze(np.load(CLAS_PATH/'tmp'/'trn_labels.npy'))\n",
    "val_labels = np.squeeze(np.load(CLAS_PATH/'tmp'/'val_labels.npy'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "bptt,em_sz,nh,nl = 70,400,1150,3\n",
    "vs = len(itos)\n",
    "opt_fn = partial(optim.Adam, betas=(0.8, 0.99))\n",
    "bs = 20   # pick as big as possible given the memory available...  with 40 we use > 8GB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_lbl = trn_labels.min()\n",
    "trn_labels -= min_lbl\n",
    "val_labels -= min_lbl\n",
    "c=int(trn_labels.max())+1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the classifier, unlike LM, we read a movie review and learn to predict the sentiment as pos/neg. \n",
    "Now we do want to shuffle the documents, as each one is independent of the others.\n",
    "We do not deal with equal bptt size batches, so we have to pad the sequences to the same length in each batch. \n",
    "To create batches of similar sized movie reviews, we use a **sortish sampler method** invented by [@Smerity](https://twitter.com/Smerity) and [@jekbradbury](https://twitter.com/jekbradbury).\n",
    "In Pytorch this is very elegant to implement.\n",
    "The `sortishSampler` cuts down the overall number of padding tokens the classifier ends up seeing.\n",
    "We use it on the training set.  For the validation set just sort."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "trn_ds = TextDataset(trn_clas, trn_labels)\n",
    "val_ds = TextDataset(val_clas, val_labels)\n",
    "trn_samp = SortishSampler(trn_clas, key=lambda x: len(trn_clas[x]), bs=bs//2)\n",
    "val_samp = SortSampler(val_clas, key=lambda x: len(val_clas[x]))\n",
    "trn_dl = DataLoader(trn_ds, bs//2, transpose=True, num_workers=1, pad_idx=1, sampler=trn_samp)\n",
    "val_dl = DataLoader(val_ds, bs, transpose=True, num_workers=1, pad_idx=1, sampler=val_samp)\n",
    "md = ModelData(PATH, trn_dl, val_dl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below we create the datasets for the training and validation, then assign the sampler (sort and sortish), \n",
    "and invoke the DataLoader to get the data-loaders.<br>\n",
    "Notice that the `DataLoader` is provided by fastai, similar to torchtext but faster as it is multithreaded."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "# part 1\n",
    "dps = np.array([0.4, 0.5, 0.05, 0.3, 0.1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "dps = np.array([0.4,0.5,0.05,0.3,0.4])*0.5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can call `get_rnn_classifier()` to create the classifier, using similar parameters as before.\n",
    "But now we can do more things, for example, add more layers, with dropouts, etc. For example:\n",
    "```\n",
    "layers=[em_sz*3, 50, c]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = get_rnn_classifer(bptt, 20*70, c, vs, emb_sz=em_sz, n_hid=nh, n_layers=nl, pad_token=1,\n",
    "          layers=[em_sz*3, 50, c], drops=[dps[4], 0.1],\n",
    "          dropouti=dps[0], wdrop=dps[1], dropoute=dps[2], dropouth=dps[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt_fn = partial(optim.Adam, betas=(0.7, 0.99))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets use the RNN_Learner just as before."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn = RNN_Learner(md, TextModel(to_gpu(m)), opt_fn=opt_fn)\n",
    "learn.reg_fn = partial(seq2seq_reg, alpha=2, beta=1)\n",
    "learn.clip=25.\n",
    "learn.metrics = [accuracy]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets use `discriminative learning rates`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr=3e-3\n",
    "lrm = 2.6\n",
    "lrs = np.array([lr/(lrm**4), lr/(lrm**3), lr/(lrm**2), lr/lrm, lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "lrs=np.array([1e-4,1e-4,1e-4,1e-3,1e-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experiment with Weight Decay (`wd`)?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "wd = 1e-7\n",
    "wd = 0\n",
    "learn.load_encoder('lm1_enc')  # lm2_enc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "We start out by only training the last layer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze_to(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1b11fdbaa3904f83ac506c0654c0fabf",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 76%|  | 1264/1667 [07:39<02:26,  2.75it/s, loss=1.28] "
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4e20ef7550>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.lr_find(lrs/1000)\n",
    "learn.sched.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bc08aa044eb44480a6311e72f5df8284",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1667 [00:00<?, ?it/s]                      \n",
      "  0%|          | 1/1667 [00:00<07:42,  3.60it/s, loss=0.588]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-33:\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/german/anaconda3/lib/python3.6/threading.py\", line 916, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/home/german/anaconda3/lib/python3.6/site-packages/tqdm/_tqdm.py\", line 144, in run\n",
      "    for instance in self.tqdm_cls._instances:\n",
      "  File \"/home/german/anaconda3/lib/python3.6/_weakrefset.py\", line 60, in __iter__\n",
      "    for itemref in self.data:\n",
      "RuntimeError: Set changed size during iteration\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                      \n",
      "    0      0.293649   0.197152   0.926164  \n",
      "\n",
      "CPU times: user 10min 3s, sys: 1min 34s, total: 11min 37s\n",
      "Wall time: 11min 33s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.19715]), 0.926163704674685]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time learn.fit(lrs, 1, wds=wd, cycle_len=1, use_clr=(8,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('clas_0')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('clas_0')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we unfreeze one more layer and improve our accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.freeze_to(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "89f4333384b740bc8dfc13cc0b255100",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=1), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                      \n",
      "    0      0.246198   0.182977   0.933871  \n",
      "\n",
      "CPU times: user 10min 33s, sys: 1min 41s, total: 12min 15s\n",
      "Wall time: 12min 11s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([0.18298]), 0.9338706410266475]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time learn.fit(lrs, 1, wds=wd, cycle_len=1, use_clr=(8,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('clas_1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.load('clas_1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And now, lets fine tune the whole thing..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.unfreeze()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notice that after 3 epochs we are getting 94.8% accuracy, beating the state-of-the-art, which was $\\approx 94%$.\n",
    "[Learned in translation: Contextualized Word Vectors](https://arxiv.org/abs/1708.00107) used a translation model, but did not fine tune the whole thing. Just took the activations of the translation model.\n",
    "On IMDb they got $\\approx 91%$, which we reached in 1 epoch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "83cce16e556a4fe69b0df5a1f760ad5c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/html": [
       "<p>Failed to display Jupyter Widget of type <code>HBox</code>.</p>\n",
       "<p>\n",
       "  If you're reading this message in the Jupyter Notebook or JupyterLab Notebook, it may mean\n",
       "  that the widgets JavaScript is still loading. If this message persists, it\n",
       "  likely means that the widgets JavaScript library is either not installed or\n",
       "  not enabled. See the <a href=\"https://ipywidgets.readthedocs.io/en/stable/user_install.html\">Jupyter\n",
       "  Widgets Documentation</a> for setup instructions.\n",
       "</p>\n",
       "<p>\n",
       "  If you're reading this message in another frontend (for example, a static\n",
       "  rendering on GitHub or <a href=\"https://nbviewer.jupyter.org/\">NBViewer</a>),\n",
       "  it may mean that your frontend doesn't currently support widgets.\n",
       "</p>\n"
      ],
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=14), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  1%|          | 14/1667 [00:07<13:54,  1.98it/s, loss=0.287]\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "cuda runtime error (2) : out of memory at /opt/conda/conda-bld/pytorch_1512386481460/work/torch/lib/THC/generic/THCStorage.cu:58",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/DeepLearning/fastai/learner.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, lrs, n_cycle, wds, **kwargs)\u001b[0m\n\u001b[1;32m    285\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    286\u001b[0m         \u001b[0mlayer_opt\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer_opt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlrs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 287\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit_gen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlayer_opt\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_cycle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    288\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    289\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwarm_up\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mwds\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DeepLearning/fastai/learner.py\u001b[0m in \u001b[0;36mfit_gen\u001b[0;34m(self, model, data, layer_opt, n_cycle, cycle_len, cycle_mult, cycle_save_name, best_save_name, use_clr, use_clr_beta, metrics, callbacks, use_wd_sched, norm_wds, wds_sched_mult, use_swa, swa_start, swa_eval_freq, **kwargs)\u001b[0m\n\u001b[1;32m    232\u001b[0m             \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmetrics\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreg_fn\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreg_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclip\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfp16\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    233\u001b[0m             \u001b[0mswa_model\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mswa_model\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0muse_swa\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mswa_start\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mswa_start\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 234\u001b[0;31m             swa_eval_freq=swa_eval_freq, **kwargs)\n\u001b[0m\u001b[1;32m    235\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    236\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mget_layer_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_layer_groups\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DeepLearning/fastai/model.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(model, data, n_epochs, opt, crit, metrics, callbacks, stepper, swa_model, swa_start, swa_eval_freq, **kwargs)\u001b[0m\n\u001b[1;32m    127\u001b[0m             \u001b[0mbatch_num\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mcb\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mcb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m             \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_stepper\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m             \u001b[0mavg_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mavg_mom\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mavg_mom\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m             \u001b[0mdebias_loss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mavg_loss\u001b[0m \u001b[0;34m/\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mavg_mom\u001b[0m\u001b[0;34m**\u001b[0m\u001b[0mbatch_num\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/DeepLearning/fastai/model.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, xs, y, epoch)\u001b[0m\n\u001b[1;32m     53\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_scale\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;32massert\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m;\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_scale\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     54\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreg_fn\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mloss\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreg_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxtra\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mraw_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 55\u001b[0;31m         \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     56\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp16\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mupdate_fp32_grads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp32_params\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_scale\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/variable.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m    165\u001b[0m                 \u001b[0mVariable\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    166\u001b[0m         \"\"\"\n\u001b[0;32m--> 167\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_variables\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    168\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    169\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(variables, grad_variables, retain_graph, create_graph, retain_variables)\u001b[0m\n\u001b[1;32m     97\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     98\u001b[0m     Variable._execution_engine.run_backward(\n\u001b[0;32m---> 99\u001b[0;31m         variables, grad_variables, retain_graph)\n\u001b[0m\u001b[1;32m    100\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: cuda runtime error (2) : out of memory at /opt/conda/conda-bld/pytorch_1512386481460/work/torch/lib/THC/generic/THCStorage.cu:58"
     ]
    }
   ],
   "source": [
    "%time learn.fit(lrs, 1, wds=wd, cycle_len=14, use_clr=(32,10))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "An idea to improve is to use bi-direction: <br>\n",
    "Go to the start of the document, reverse the order of all of the documents, and do everything again. \n",
    "When we get to use the `fwd_wt103.h5` model, we replace it with `bwd_wt103.pt`, the backward model.  \n",
    "That is a backward language model that learns English backwards. \n",
    "Then we have 2 classifiers... We take the 2 predictions, average them and that is a bi-directional language model. This will exceed $95.4%$ accuracy, which is a $20%$ change in the state-of-the-art.\n",
    "Hence, transfer-learning is powerful, but every-field thinks they are special and they don't do it..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4e1494ccc0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.sched.plot_loss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JH worked on a paper w/Sebastian Ruder **[Universal Language Model Fine-tuning for Text Classification](https://arxiv.org/pdf/1801.06146),** which included the ablation studies, etc. \n",
    "Then formalized **`discriminative learning rates`** and **`Gradual unfreezing`.**  Also added some math. \n",
    "They also added the idea of `concat pooling`.\n",
    "\n",
    "They also used the newer idea of `cyclical Learning Rates` that was introduced by Leslie Smith's **[A Disciplined Approach to Neural Network Parameters: Part I - Learning Rate, Batch Size, Momentum, and Weight Decay](https://arxiv.org/abs/1803.09820),**.  This is a great paper to read and summarize...\n",
    "\n",
    "Used all the datasets that LeCun used (IMDb, TREC-6, AG, DBpedia, Yelp-bi, Yelp-full) on a recent paper and obtained better results, even against customized algorithms that were state of the art."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sebastian did the **ablation** studies which explain what are the contributions of the different ideas. (See ppt, will be in future paper?)\n",
    "This is done by removing each of the components and evaluating their contribution.\n",
    "\n",
    "The most interesting was, what is the validation error rate with fewer examples. \n",
    "With only 100 example it reached a much lower error rate than others reached with many more trainingexamples.\n",
    "So, this is most beneficial when there is little data.\n",
    "\n",
    "Valuable to use:\n",
    "```\n",
    "pip install -e .\n",
    "```\n",
    "creates a symlink into your ~/site-packages/  \n",
    "makes it simpler to keep track..\n",
    "But it may confuse conda..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Google tools for NLP\n",
    "\n",
    "[Google Fire library](https://github.com/google/python-fire) is great for ablation studies.\n",
    "JH put all the scripts under `dl2/imdb_scripts`. **TODO: review these scripts.**\n",
    "\n",
    "[SentencePiece](https://github.com/google/sentencepiece) is useful to tokenize in sub-word units, etc.\n",
    "JH got results nearly as good as word tokenization... suspect it could be better...\n",
    "But in any case, it is good because end up with vocabulary of sub-units which is very good...\n",
    "It is a bit difficult to install, bad error messages, etc.\n",
    "\n",
    "SentencePiece is an unsupervised text tokenizer and detokenizer mainly for Neural Network-based text generation systems where the vocabulary size is predetermined prior to the neural model training. SentencePiece implements subword units (e.g., byte-pair-encoding (BPE) [Sennrich et al.]) and unigram language model [Kudo.]) with the extension of direct training from raw sentences. Subword segmentation with unigram language model supports probabilistic subword sampling for subword regularization [Kudo.], a simple technique to improve the robustness of NMT model. SentencePiece allows us to make a purely end-to-end system that does not depend on language-specific pre/postprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "learn.save('clas_2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**BPT3C**. \n",
    "Language models are trained with backpropagation through time (BPTT) to enable gradient propagation for large input sequences.  \n",
    "The problem is that for classification, a document can be very long, eg 2000 words. The whole gradients would not fit on the GPU.\n",
    "In order to make fine-tuning a classifier for large documents feasible, we propose BPTT for Text Classification (BPT3C): \n",
    "We divide the document into fixed-length batches of size $b$. \n",
    "At the beginning of each batch, the model is initialized with the final state of the previous batch; \n",
    "we keep track of the hidden states for mean and max-pooling; \n",
    "gradients are back-propagated to the batches whose hidden states contributed to the classifier prediction \n",
    "at the end of the document. \n",
    "In practice, we use variable length backpropagation sequences (per Merity et al.)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('Sun May 13 18:15:15 2018', 35395.25425)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1 = time.clock()\n",
    "time.ctime(time.time()), (t1 - t0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYYAAAD8CAYAAABzTgP2AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAADsBJREFUeJzt23GonXd9x/H3x1xMUaFN2kRr0+xWWhjpBoqHFtkGnbVtOtAU7R/p/jBslfwx+8cUwUg3aqt/tN2kIrqNoEIQZusqYkBGia2FMUbtSduhmcZco9JrS42kFLpiS+Z3f9yn2/ldzu29uc+59+TW9wsO53l+v+95zveXA/nc53nOSVUhSdKr3jDtBiRJ5xaDQZLUMBgkSQ2DQZLUMBgkSQ2DQZLUMBgkSQ2DQZLUMBgkSY2ZaTewGhdddFHNzs5Ouw1J2lCOHj3666ratlzdhgyG2dlZhsPhtNuQpA0lyS9WUuelJElSw2CQJDUMBklSw2CQJDUMBklSw2CQJDUMBklSw2CQJDUMBklSw2CQJDUMBklSw2CQJDUMBklSw2CQJDUMBklSw2CQJDUMBklSw2CQJDUMBklSw2CQJDUMBklSw2CQJDUMBklSw2CQJDUmEgxJdic5nmQuyYEx85uTPNDNP5ZkdtH8ziQvJvnEJPqRJK1e72BIsgn4EnAjsAu4JcmuRWW3As9X1eXAfcA9i+bvA/61by+SpP4mccZwFTBXVSer6hXgfmDPopo9wKFu+0Hg2iQBSHITcBI4NoFeJEk9TSIYLgGeHtmf78bG1lTVGeAF4MIkbwY+Cdw5gT4kSRMwiWDImLFaYc2dwH1V9eKyb5LsTzJMMjx16tQq2pQkrcTMBI4xD1w6sr8DeGaJmvkkM8D5wGngauDmJPcCFwC/TfKbqvri4jepqoPAQYDBYLA4eCRJEzKJYHgcuCLJZcAvgb3Any+qOQzsA/4DuBl4pKoK+JNXC5J8GnhxXChIktZP72CoqjNJbgMeAjYBX62qY0nuAoZVdRj4CvC1JHMsnCns7fu+kqS1kYU/3DeWwWBQw+Fw2m1I0oaS5GhVDZar85fPkqSGwSBJahgMkqSGwSBJahgMkqSGwSBJahgMkqSGwSBJahgMkqSGwSBJahgMkqSGwSBJahgMkqSGwSBJahgMkqSGwSBJahgMkqSGwSBJahgMkqSGwSBJahgMkqSGwSBJahgMkqSGwSBJahgMkqSGwSBJahgMkqSGwSBJahgMkqSGwSBJahgMkqTGRIIhye4kx5PMJTkwZn5zkge6+ceSzHbj1yU5muQH3fN7J9GPJGn1egdDkk3Al4AbgV3ALUl2LSq7FXi+qi4H7gPu6cZ/Dby/qv4Q2Ad8rW8/kqR+JnHGcBUwV1Unq+oV4H5gz6KaPcChbvtB4Nokqaonq+qZbvwYcF6SzRPoSZK0SpMIhkuAp0f257uxsTVVdQZ4AbhwUc2HgCer6uUJ9CRJWqWZCRwjY8bqbGqSXMnC5aXrl3yTZD+wH2Dnzp1n36UkaUUmccYwD1w6sr8DeGapmiQzwPnA6W5/B/At4MNV9dOl3qSqDlbVoKoG27Ztm0DbkqRxJhEMjwNXJLksyRuBvcDhRTWHWbi5DHAz8EhVVZILgO8An6qqf59AL5KknnoHQ3fP4DbgIeBHwDeq6liSu5J8oCv7CnBhkjng48CrX2m9Dbgc+NskT3WP7X17kiStXqoW3w449w0GgxoOh9NuQ5I2lCRHq2qwXJ2/fJYkNQwGSVLDYJAkNQwGSVLDYJAkNQwGSVLDYJAkNQwGSVLDYJAkNQwGSVLDYJAkNQwGSVLDYJAkNQwGSVLDYJAkNQwGSVLDYJAkNQwGSVLDYJAkNQwGSVLDYJAkNQwGSVLDYJAkNQwGSVLDYJAkNQwGSVLDYJAkNQwGSVLDYJAkNQwGSVJjIsGQZHeS40nmkhwYM785yQPd/GNJZkfmPtWNH09ywyT6kSStXu9gSLIJ+BJwI7ALuCXJrkVltwLPV9XlwH3APd1rdwF7gSuB3cA/dMeTJE3JJM4YrgLmqupkVb0C3A/sWVSzBzjUbT8IXJsk3fj9VfVyVf0MmOuOJ0makkkEwyXA0yP7893Y2JqqOgO8AFy4wtdKktbRJIIhY8ZqhTUree3CAZL9SYZJhqdOnTrLFiVJKzWJYJgHLh3Z3wE8s1RNkhngfOD0Cl8LQFUdrKpBVQ22bds2gbYlSeNMIhgeB65IclmSN7JwM/nwoprDwL5u+2bgkaqqbnxv962ly4ArgO9PoCdJ0irN9D1AVZ1JchvwELAJ+GpVHUtyFzCsqsPAV4CvJZlj4Uxhb/faY0m+AfwXcAb4aFX9T9+eJEmrl4U/3DeWwWBQw+Fw2m1I0oaS5GhVDZar85fPkqSGwSBJahgMkqSGwSBJahgMkqSGwSBJahgMkqSGwSBJahgMkqSGwSBJahgMkqSGwSBJahgMkqSGwSBJahgMkqSGwSBJahgMkqSGwSBJahgMkqSGwSBJahgMkqSGwSBJahgMkqSGwSBJahgMkqSGwSBJahgMkqSGwSBJahgMkqSGwSBJahgMkqRGr2BIsjXJkSQnuuctS9Tt62pOJNnXjb0pyXeS/DjJsSR39+lFkjQZfc8YDgAPV9UVwMPdfiPJVuAO4GrgKuCOkQD5+6r6feBdwB8lubFnP5KknvoGwx7gULd9CLhpTM0NwJGqOl1VzwNHgN1V9VJVfQ+gql4BngB29OxHktRT32B4a1U9C9A9bx9Tcwnw9Mj+fDf2f5JcALyfhbMOSdIUzSxXkOS7wNvGTN2+wvfImLEaOf4M8HXgC1V18jX62A/sB9i5c+cK31qSdLaWDYaqet9Sc0meS3JxVT2b5GLgV2PK5oFrRvZ3AI+O7B8ETlTV55fp42BXy2AwqNeqlSStXt9LSYeBfd32PuDbY2oeAq5PsqW76Xx9N0aSzwLnA3/dsw9J0oT0DYa7geuSnACu6/ZJMkjyZYCqOg18Bni8e9xVVaeT7GDhctQu4IkkTyX5SM9+JEk9pWrjXZUZDAY1HA6n3YYkbShJjlbVYLk6f/ksSWoYDJKkhsEgSWoYDJKkhsEgSWoYDJKkhsEgSWoYDJKkhsEgSWoYDJKkhsEgSWoYDJKkhsEgSWoYDJKkhsEgSWoYDJKkhsEgSWoYDJKkhsEgSWoYDJKkhsEgSWoYDJKkhsEgSWoYDJKkhsEgSWoYDJKkhsEgSWoYDJKkhsEgSWoYDJKkRq9gSLI1yZEkJ7rnLUvU7etqTiTZN2b+cJIf9ulFkjQZfc8YDgAPV9UVwMPdfiPJVuAO4GrgKuCO0QBJ8kHgxZ59SJImpG8w7AEOdduHgJvG1NwAHKmq01X1PHAE2A2Q5C3Ax4HP9uxDkjQhfYPhrVX1LED3vH1MzSXA0yP7890YwGeAzwEv9exDkjQhM8sVJPku8LYxU7ev8D0yZqySvBO4vKo+lmR2BX3sB/YD7Ny5c4VvLUk6W8sGQ1W9b6m5JM8lubiqnk1yMfCrMWXzwDUj+zuAR4H3AO9O8vOuj+1JHq2qaxijqg4CBwEGg0Et17ckaXX6Xko6DLz6LaN9wLfH1DwEXJ9kS3fT+Xrgoar6x6p6e1XNAn8M/GSpUJAkrZ++wXA3cF2SE8B13T5JBkm+DFBVp1m4l/B497irG5MknYNStfGuygwGgxoOh9NuQ5I2lCRHq2qwXJ2/fJYkNQwGSVLDYJAkNQwGSVLDYJAkNQwGSVLDYJAkNQwGSVLDYJAkNQwGSVLDYJAkNQwGSVLDYJAkNQwGSVLDYJAkNQwGSVLDYJAkNQwGSVLDYJAkNQwGSVLDYJAkNQwGSVLDYJAkNQwGSVLDYJAkNVJV0+7hrCU5Bfxi2n2cpYuAX0+7iXXmmn83uOaN4/eqattyRRsyGDaiJMOqGky7j/Xkmn83uObXHy8lSZIaBoMkqWEwrJ+D025gClzz7wbX/DrjPQZJUsMzBklSw2CYoCRbkxxJcqJ73rJE3b6u5kSSfWPmDyf54dp33F+fNSd5U5LvJPlxkmNJ7l7f7s9Okt1JjieZS3JgzPzmJA90848lmR2Z+1Q3fjzJDevZdx+rXXOS65IcTfKD7vm96937avT5jLv5nUleTPKJ9ep5TVSVjwk9gHuBA932AeCeMTVbgZPd85Zue8vI/AeBfwZ+OO31rPWagTcBf9rVvBH4N+DGaa9piXVuAn4KvKPr9T+BXYtq/gr4p257L/BAt72rq98MXNYdZ9O017TGa34X8PZu+w+AX057PWu53pH5bwL/Anxi2uvp8/CMYbL2AIe67UPATWNqbgCOVNXpqnoeOALsBkjyFuDjwGfXoddJWfWaq+qlqvoeQFW9AjwB7FiHnlfjKmCuqk52vd7PwtpHjf5bPAhcmyTd+P1V9XJV/QyY6453rlv1mqvqyap6phs/BpyXZPO6dL16fT5jktzEwh89x9ap3zVjMEzWW6vqWYDuefuYmkuAp0f257sxgM8AnwNeWssmJ6zvmgFIcgHwfuDhNeqzr2XXMFpTVWeAF4ALV/jac1GfNY/6EPBkVb28Rn1OyqrXm+TNwCeBO9ehzzU3M+0GNpok3wXeNmbq9pUeYsxYJXkncHlVfWzxdctpW6s1jxx/Bvg68IWqOnn2Ha6L11zDMjUree25qM+aFyaTK4F7gOsn2Nda6bPeO4H7qurF7gRiQzMYzlJVvW+puSTPJbm4qp5NcjHwqzFl88A1I/s7gEeB9wDvTvJzFj6X7UkeraprmLI1XPOrDgInqurzE2h3rcwDl47s7wCeWaJmvgu784HTK3ztuajPmkmyA/gW8OGq+unat9tbn/VeDdyc5F7gAuC3SX5TVV9c+7bXwLRvcryeHsDf0d6IvXdMzVbgZyzcfN3SbW9dVDPLxrn53GvNLNxP+SbwhmmvZZl1zrBw/fgy/v/G5JWLaj5Ke2PyG932lbQ3n0+yMW4+91nzBV39h6a9jvVY76KaT7PBbz5PvYHX04OFa6sPAye651f/8xsAXx6p+0sWbkDOAX8x5jgbKRhWvWYW/iIr4EfAU93jI9Ne02us9c+An7DwzZXbu7G7gA902+ex8I2UOeD7wDtGXnt797rjnKPfvJrkmoG/Af575HN9Ctg+7fWs5Wc8cowNHwz+8lmS1PBbSZKkhsEgSWoYDJKkhsEgSWoYDJKkhsEgSWoYDJKkhsEgSWr8L4G+I6VKUcyzAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4d7485b780>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "learn.sched.plot_loss()"
   ]
  }
 ],
 "metadata": {
  "_draft": {
   "nbviewer_url": "https://gist.github.com/0dd0df21cf404cf2bb51d0148c8b7d8b"
  },
  "gist": {
   "data": {
    "description": "fastai.text imdb example",
    "public": true
   },
   "id": "0dd0df21cf404cf2bb51d0148c8b7d8b"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  },
  "toc": {
   "nav_menu": {
    "height": "86px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
