{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\" style=\"margin-top: 1em;\"><ul class=\"toc-item\"><li><span><a href=\"#CHEAT-SHEETS\" data-toc-modified-id=\"CHEAT-SHEETS-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>CHEAT SHEETS</a></span></li><li><span><a href=\"#Python-debugger\" data-toc-modified-id=\"Python-debugger-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Python debugger</a></span></li><li><span><a href=\"#Visual-Code\" data-toc-modified-id=\"Visual-Code-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Visual Code</a></span></li><li><span><a href=\"#pathlib\" data-toc-modified-id=\"pathlib-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>pathlib</a></span></li><li><span><a href=\"#OPENCV\" data-toc-modified-id=\"OPENCV-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>OPENCV</a></span></li><li><span><a href=\"#Matplotlib\" data-toc-modified-id=\"Matplotlib-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Matplotlib</a></span><ul class=\"toc-item\"><li><span><a href=\"#plt.subplots\" data-toc-modified-id=\"plt.subplots-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;</span>plt.subplots</a></span></li></ul></li><li><span><a href=\"#*-the-&quot;splat&quot;-operator\" data-toc-modified-id=\"*-the-&quot;splat&quot;-operator-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>* the \"splat\" operator</a></span></li><li><span><a href=\"#Questions:\" data-toc-modified-id=\"Questions:-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Questions:</a></span><ul class=\"toc-item\"><li><span><a href=\"#Question:-As-a-general-rule,-is-it-better-to-put-BatchNorm-before-or-after-ReLU-[18:02]?\" data-toc-modified-id=\"Question:-As-a-general-rule,-is-it-better-to-put-BatchNorm-before-or-after-ReLU-[18:02]?-8.1\"><span class=\"toc-item-num\">8.1&nbsp;&nbsp;</span>Question: As a general rule, is it better to put BatchNorm before or after ReLU [18:02]?</a></span></li><li><span><a href=\"#Question:-What-is-the-intuition-behind-using-dropout-after-a-BatchNorm?-Doesn’t-BatchNorm-already-do-a-good-job-of-regularizing-[19:12]?\" data-toc-modified-id=\"Question:-What-is-the-intuition-behind-using-dropout-after-a-BatchNorm?-Doesn’t-BatchNorm-already-do-a-good-job-of-regularizing-[19:12]?-8.2\"><span class=\"toc-item-num\">8.2&nbsp;&nbsp;</span>Question: What is the intuition behind using dropout after a BatchNorm? Doesn’t BatchNorm already do a good job of regularizing [19:12]?</a></span></li><li><span><a href=\"#Question:-When-you-are-incrementally-building-on-top-of-smaller-models,-do-you-reuse-them-as-pre-trained-weights?-or-do-you-toss-it-away-then-retrain-from-scratch-[27:11]?\" data-toc-modified-id=\"Question:-When-you-are-incrementally-building-on-top-of-smaller-models,-do-you-reuse-them-as-pre-trained-weights?-or-do-you-toss-it-away-then-retrain-from-scratch-[27:11]?-8.3\"><span class=\"toc-item-num\">8.3&nbsp;&nbsp;</span>Question: When you are incrementally building on top of smaller models, do you reuse them as pre-trained weights? or do you toss it away then retrain from scratch [27:11]?</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CHEAT SHEETS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Python debugger\n",
    "\n",
    "You can use the python debugger pdb to step through code.\n",
    "\n",
    "- pdb.set_trace() to set a breakpoint\n",
    "- %debug magic to trace an error (after the exception happened)\n",
    "\n",
    "Commands:\n",
    "\n",
    "- h (help)\n",
    "- s (step into)\n",
    "- n (next line / step over — you can also hit enter)\n",
    "- c (continue to the next breakpoint)\n",
    "- u (up the call stack)\n",
    "- d (down the call stack)\n",
    "- p (print) — force print when there is a single letter variable that’s also a command.\n",
    "- l (list) — show the line above and below it\n",
    "- q (quit) — very important"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visual Code\n",
    "You can use Visual Studio Code (vscode - open source editor that comes with recent versions of Anaconda, or can be installed separately), or most editors and IDEs, to find out all about the open_image function. vscode things to know:\n",
    "\n",
    "- Command palette (Ctrl-shift-p)\n",
    "- Select interpreter (for fastai env)\n",
    "- Select terminal shell\n",
    "- Go to symbol (Ctrl-t)\n",
    "- Find references (Shift-F12)\n",
    "- Go to definition (F12)\n",
    "- Go back (alt-left)\n",
    "- View documentation\n",
    "- Hide sidebar (Ctrl-b)\n",
    "- Zen mode (Ctrl-k,z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# pathlib\n",
    "We are now using the python3 standard library pathlib for our paths and file access. Note that it returns an OS-specific class (on Linux, PosixPath) so your output may look a little different. Most libraries that take paths as input can take a pathlib object. But some (like cv2) can't,then use str() to convert it to a string. [Pathlib Tutorial](https://pathlib.readthedocs.io/en/pep428/)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OPENCV\n",
    "**About open_image** open_image [1:10:52]\n",
    "Fastai uses `OpenCV`. TorchVision uses PyTorch tensors for data augmentations etc. Many people use [Pillow's]( http://python-pillow.org/) PIL. \n",
    "JH found OpenCV was 5 to 10 times faster than TorchVision. \n",
    "For the planet satellite image competition [1:11:55], TorchVision was so slow that they could only get 25% GPU utilization because they were doing a lot of data augmentation. Profiler showed that it was all in TorchVision.\n",
    "\n",
    "Pillow is faster but not as fast as OpenCV and also is not nearly as thread-safe [1:12:19]. \n",
    "Python has this thing called the **global interpreter lock (GIL)** which means that two threads can’t do pythonic things at the same time — which makes Python a crappy language for modern programming but we are stuck with it. **OpenCV releases the GIL.** The fast.ai library uses multiple threads (because it uses OpenCV) for data augmentations. In contrast, other libraries use multiple processors.  \n",
    "Unfortunately OpenCV has an inscrutable API and its documentations are somewhat obtuse. \n",
    "JH tried to make it so that no one using fast.ai needs to know that it’s using OpenCV. \n",
    "For example, You don’t need to know what flags to pass to open an image. \n",
    "You don’t need to know that if the reading fails, it doesn’t show an exception — it silently returns None."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Matplotlib  \n",
    "Matplotlib is so named because it was originally a clone of Matlab’s plotting library. Unfortunately, Matlab’s plotting library is not great, but at that time, it was what everybody knew. Eventually, they added an object-oriented API. Unfortunately, because nobody who originally learnt matplotlib learnt the OO API, they then taught the next generation of people the old Matlab style API. \n",
    "Now there are not many examples or tutorials that use the much better, easier to understand, and simpler OO API. Because plotting is so important in deep learning, one of the things we are going to learn in this class is how to use this API.\n",
    "\n",
    "## plt.subplots\n",
    "is a really useful wrapper for creating plots, regardless of whether you have more than one subplot. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# * the \"splat\" operator\n",
    "\"*\" is the \"splat\" operator: It takes a list as input, and expands it into actual positional arguments in the function call.\n",
    "\n",
    "So if uniqueCrossTabs was [ [ 1, 2 ], [ 3, 4 ] ], then itertools.chain(*uniqueCrossTabs) is the same as saying itertools.chain([ 1, 2 ], [ 3, 4 ])\n",
    "\n",
    "This is obviously different from passing in just uniqueCrossTabs. In your case, you have a list of lists that you wish to flatten; what itertools.chain() does is return an iterator over the concatenation of all the positional arguments you pass to it, where each positional argument is iterable in its own right.\n",
    "\n",
    "In other words, you want to pass each list in uniqueCrossTabs as an argument to chain(), which will chain them together, but you don't have the lists in separate variables, so you use the * operator to expand the list of lists into several list arguments.\n",
    "\n",
    "As Jochen Ritzel has pointed out in the comments, chain.from_iterable() is better-suited for this operation, as it assumes a single iterable of iterables to begin with. Your code then becomes simply:\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Questions:\n",
    "\n",
    "## Question: As a general rule, is it better to put BatchNorm before or after ReLU [18:02]? \n",
    "Jeremy would suggest to put it after a ReLU because BatchNorm is meant to move towards zero-mean one-standard deviation. So if you put ReLU right after it, you are truncating it at zero so there is no way to create negative numbers. But if you put ReLU then BatchNorm, it does have that ability and gives slightly better results. Having said that, it is not too big of a deal either way. \n",
    "Most of the time, Jeremy does ReLU then BatchNorm but sometimes does the opposite when he wants to be consistent with a paper."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question: What is the intuition behind using dropout after a BatchNorm? Doesn’t BatchNorm already do a good job of regularizing [19:12]?\n",
    "\n",
    "BatchNorm does an okay job of regularizing. \n",
    "It is one of a list of \"tools\" to avoid overfitting. Another is data augmentation. \n",
    "But it’s possible that you’ll still be overfitting. \n",
    "One nice thing about `dropout` is that you can tune it, ie to say how much to drop out. \n",
    "Parameters that decide how much to regularize let us build a nice big over parameterized model and then decide on how much to regularize it. \n",
    "Jeremy tends to always put in a drop out starting with p=0.\n",
    "Then as he adds regularization, he can just change the dropout parameter, without worrying about if he saved a model he wants to be able to load again, if he had or not dropout layers...\n",
    "If it does in one but not in another, it will not load anymore. \n",
    "So this way, it stays consistent."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question: When you are incrementally building on top of smaller models, do you reuse them as pre-trained weights? or do you toss it away then retrain from scratch [27:11]? \n",
    "When Jeremy is figuring stuff out as he goes like this, he would generally lean towards tossing away because reusing pre-trained weights introduces unnecessary complexities. However, if he is trying to get to a point where he can train on really big images, he will generally start on much smaller and often re-use these weights."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Defaultdict\n",
    "A `defaultdict` is useful any time you want to have a default dictionary entry for new keys. \n",
    "Below we create a dict from image IDs to a list of annotations (tuple of bounding box and class id).\n",
    "If we \"access\" a key that doesn’t exist, it \"magically\" makes itself exist and it sets itself equal to the return value of the function you specify (in this case lambda:[]).\n",
    "\n",
    "trn_anno = collections.defaultdict(lambda:[])\n",
    "for o in trn_j[ANNOTATIONS]:\n",
    "    if not o['ignore']:\n",
    "        bb = o[BBOX] # pull the box\n",
    "        bb = hw_bb(bb) # translate as above\n",
    "        trn_anno[o[IMG_ID]].append((bb,o[CAT_ID]))\n",
    "        \n",
    "len(trn_anno)   # number of entries in the dictionary for the trainning annotations."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  },
  "toc": {
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": true,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
