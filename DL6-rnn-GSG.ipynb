{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recurrent Neural Networks (RNN) \n",
    "edited by GSG based on [Lesson6-rnn](https://github.com/fastai/fastai/blob/master/courses/dl1/lesson6-rnn.ipynb).\n",
    "See [Lecture Notes](http://forums.fast.ai/t/deeplearning-lec7notes/8939)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%reload_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Setup for works of Nietzche by char"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Download the collected works of Nietzsche to use as our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[0m\u001b[01;34mmodels\u001b[0m/  nietzsche.txt  \u001b[01;34mtrn\u001b[0m/  \u001b[01;34mval\u001b[0m/\r\n"
     ]
    }
   ],
   "source": [
    "PATH='data/nietzsche/'\n",
    "TRN_PATH = 'trn/'\n",
    "VAL_PATH = 'val/'\n",
    "TRN = f'{PATH}{TRN_PATH}'\n",
    "VAL = f'{PATH}{VAL_PATH}'\n",
    "%ls {PATH}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.io import get_data # *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "corpus length: 600893\n"
     ]
    }
   ],
   "source": [
    "get_data(\"https://s3.amazonaws.com/text-datasets/nietzsche.txt\", f'{PATH}nietzsche.txt')\n",
    "text = open(f'{PATH}nietzsche.txt').read()\n",
    "print('corpus length:', len(text))  # number of characters in the whole text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PREFACE\\n\\n\\nSUPPOSING that Truth is a woman--what then? Is there not ground\\nfor suspecting that all philosophers, in so far as they have been\\ndogmatists, have failed to understand women--that the terrible\\nseriousness and clumsy importunity with which they have usually paid\\ntheir addresses to Truth, have been un'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text[:310]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validation set\n",
    "Make the first 80% of the text to be the training set, and the later 20% to be the validation set.\n",
    "No need to be a random sample, as it is more likely that a test set will come from a separate corpus.\n",
    "This is a more realistic validation test for the model is to have a separate set, ie a different part of Nietszche's corpus.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Scripts for validation sets.\n",
    "\n",
    "JH is more \"lazy than the students\" and fits the data to the existing API, in this case in `torchtext`, with trainning part, validation part, etc.  So he made copies into 2 paths and did a sed script to keep it like this.\n",
    "\n",
    "sed -n [1,7947p] nietzsche.txt > trn/trn.txt\n",
    "\n",
    "sed -n [7950,9935p] nietzsche.txt > val/val.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data/nietzsche/trn/:\r\n",
      "total 480\r\n",
      "-rw-rw-r-- 1 german german 490861 Jan 21 18:32 trn.txt\r\n",
      "\r\n",
      "data/nietzsche/val/:\r\n",
      "total 108\r\n",
      "-rw-rw-r-- 1 german german 109974 Jan 21 18:34 val.txt\r\n"
     ]
    }
   ],
   "source": [
    "%ls -l {TRN} {VAL}    # the training and validation sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Using torchtext data.Field\n",
    "A field is a description of how to pre-process the text, eg lowercase, and how to tokenize.\n",
    "Below we use Python's `list` as a tokenizer so we simply get the characters.\n",
    "So each minibatch gets a list of characters.\n",
    "\n",
    "`data.Field(sequential=True, use_vocab=True, init_token=None, eos_token=None, fix_length=None, tensor_type=<class 'torch.LongTensor'>, preprocessing=None, postprocessing=None, lower=False, tokenize=<function Field.<lambda> at 0x7f5cc269fea0>, include_lengths=False, batch_first=False, pad_token='<pad>', unk_token='<unk>', pad_first=False)`\n",
    "    \n",
    "Defines a datatype together with instructions for converting to Tensor.\n",
    "Field class models common text processing datatypes that can be represented\n",
    "by tensors.  It holds a Vocab object that defines the set of possible values\n",
    "for elements of the field and their corresponding numerical representations.\n",
    "The Field object also holds other parameters relating to how a datatype\n",
    "should be numericalized, such as a tokenization method and the kind of\n",
    "Tensor that should be produced.\n",
    "\n",
    "If a Field is shared between two columns in a dataset (e.g., question and\n",
    "answer in a QA dataset), then they will have a shared vocabulary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchtext import vocab, data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "TEXT = data.Field(lower=True, tokenize=list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create a small dictionary for the FILES. Since we don't have a separate test set we use the validation set again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "FILES = dict(train=TRN_PATH, validation=VAL_PATH, test=VAL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`set()` creates a list of the unique characters. Then we make them into a list and we sort them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "total chars: 85\n"
     ]
    }
   ],
   "source": [
    "chars = sorted(list(set(text)))  # chars is our vocabulary\n",
    "vocab_size = len(chars)+1\n",
    "print('total chars:', vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sometimes it's useful to have a zero value in the dataset, e.g. for padding."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n !\"\\'(),-.0123456789:;=?ABCDEFGHIJKLMNOPQRSTUVWXYZ[]_abcdefghijklmnopqrstuvwxy'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chars.insert(0, \"\\0\")\n",
    "''.join(chars[1:-6])  #show all characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Map from chars to indices and back again, creating 2 dictionaries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "char_indices = dict((c, i) for i, c in enumerate(chars))\n",
    "indices_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*idx* will be the data we use from now on - it has all the characters in the text by their index (based on the mapping above)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[40, 42, 29, 30, 25, 27, 29, 1, 1, 1]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'PREFACE\\n\\n\\n'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx = [char_indices[c] for c in text]\n",
    "\n",
    "print(idx[:10]); text[:10]   # these are the indeces for the first 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "confirm that indeed we got the mapping correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'PREFACE\\n\\n\\nSUPPOSING that Truth is a woman--what then? Is there not gro'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "''.join(indices_char[i] for i in idx[:70]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Three char model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a list of every 4th character, starting at the 0th, 1st, 2nd, then 3rd characters. `cs=3` skip over 3 at the time "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs=3\n",
    "c1_dat = [idx[i]   for i in range(0, len(idx)-1-cs, cs)]  # 0th character\n",
    "c2_dat = [idx[i+1] for i in range(0, len(idx)-1-cs, cs)]\n",
    "c3_dat = [idx[i+2] for i in range(0, len(idx)-1-cs, cs)]\n",
    "c4_dat = [idx[i+3] for i in range(0, len(idx)-1-cs, cs)]  # 3rd character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(200297,\n",
       " [40, 30, 29, 1, 40, 43],\n",
       " [42, 25, 1, 43, 40, 33],\n",
       " [29, 27, 1, 45, 39, 38],\n",
       " [30, 29, 1, 40, 43, 31])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(c1_dat), c1_dat[:6], c2_dat[:6], c3_dat[:6], c4_dat[:6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our inputs converted to np using `np.asarray`. JH was using `np.stack`, \" np.stack is going to be different for when axis!=0. I used ‘stack’ here because I think this is a better semantic match for what we’re doing.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "x1 = np.asarray(c1_dat[:-2])  # 0 character\n",
    "x2 = np.asarray(c2_dat[:-2])  # 1 character\n",
    "x3 = np.asarray(c3_dat[:-2])  # 2 character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(numpy.ndarray, array([40, 30, 29, ..., 67, 68, 72]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(x1), x1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.asarray(c4_dat[:-2])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first 4 inputs and corresponding outputs (in following line)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([40, 30, 29,  1]), array([42, 25,  1, 43]), array([29, 27,  1, 45]))"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1[:4], x2[:4], x3[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([30, 29,  1, 40])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((200295,), (200295,))"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x1.shape, y.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and train model\n",
    "Now using pytorch nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pick a size for our hidden state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_hidden = 256   # Activations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of latent factors to create (i.e. the size of the embedding matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fac = 42   # about half the number of characters we have (experimental)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Below` Char3model` is standard fully connected model... \n",
    "Each character will go thru an embedding, linear and relu.\n",
    "\n",
    "`nn.Embedding(num_embeddings, embedding_dim, padding_idx=None, max_norm=None, norm_type=2, scale_grad_by_freq=False, sparse=False)`    \n",
    "A simple lookup table that stores embeddings of a fixed dictionary and size.\n",
    "\n",
    "`nn.Linear(in_features, out_features, bias=True)`   \n",
    "Applies a linear transformation to the incoming data: :math:`y = Ax + b`\n",
    "\n",
    "`F.relu(input, inplace=False)`\n",
    "relu(input, threshold, value, inplace=False) -> Variable\n",
    "Applies the rectified linear unit function element-wise.\n",
    "\n",
    "`F.log_softmax(input, dim=None, _stacklevel=3)`\n",
    "Applies a softmax followed by a logarithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Char3Model(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac):\n",
    "        super().__init__()    # access the __init__ class of nn.Module \n",
    "        self.e = nn.Embedding(vocab_size, n_fac)  #one embedding\n",
    "\n",
    "        # The 'green arrow' from our diagram - the layer operation from input to hidden\n",
    "        self.l_in = nn.Linear(n_fac, n_hidden)\n",
    "\n",
    "        # The 'orange arrow' from our diagram - the layer operation from hidden to hidden\n",
    "        self.l_hidden = nn.Linear(n_hidden, n_hidden)   #This is a squared Matrix. \"the trick\"\n",
    "        \n",
    "        # The 'blue arrow' from our diagram - the layer operation from hidden to output\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        \n",
    "    def forward(self, c1, c2, c3):\n",
    "        in1 = F.relu(self.l_in(self.e(c1)))\n",
    "        in2 = F.relu(self.l_in(self.e(c2)))\n",
    "        in3 = F.relu(self.l_in(self.e(c3)))\n",
    "        \n",
    "        #now activations\n",
    "        h = V(torch.zeros(in1.size()).cuda())  #this is to make the following 3 lines identical so later loop\n",
    "        h = F.tanh(self.l_hidden(h+in1))\n",
    "        h = F.tanh(self.l_hidden(h+in2))\n",
    "        h = F.tanh(self.l_hidden(h+in3))\n",
    "        \n",
    "        return F.log_softmax(self.l_out(h))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.column_data import ColumnarModelData # *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`ColumnarModelData.from_arrays(path, val_idxs, xs, y, is_reg=True, is_multi=False, bs=64, test_xs=None, shuffle=True)`\n",
    "\n",
    "fastai used to create the data object for training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = ColumnarModelData.from_arrays('.', [-1], np.stack([x1,x2,x3], axis=1), y, bs=512)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = Char3Model(vocab_size, n_fac).cuda()  #this is a standard pytorch model (not fastai) so we need to add cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.conv_learner import V, F   # *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(md.trn_dl) #grab the iterator to iterate thru the training set\n",
    "*xs,yt = next(it)   #grab a minibatch of size bs=512, returns all the xs and ys tensors\n",
    "t = m(*V(xs))  #invoke the model as a function passing the tensor as Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, torch.cuda.LongTensor, 3, 512)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(xs), type(xs[0]), len(xs), len(xs[0]) # xs is a list of 3 tensors of size bs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([512]), \n",
       "  61\n",
       "  72\n",
       "  73\n",
       "  65\n",
       "  56\n",
       "  72\n",
       "  67\n",
       "  69\n",
       "  73\n",
       "  72\n",
       "   2\n",
       "  68\n",
       "  65\n",
       "  73\n",
       "  67\n",
       "   2\n",
       "   2\n",
       "  29\n",
       "  62\n",
       "  74\n",
       "  58\n",
       "  67\n",
       "  38\n",
       "  10\n",
       "  62\n",
       "  73\n",
       "  67\n",
       "  73\n",
       "  61\n",
       "  58\n",
       "   2\n",
       "  55\n",
       "  62\n",
       "   2\n",
       "   2\n",
       "   2\n",
       "  58\n",
       "   2\n",
       "  72\n",
       "   8\n",
       "  58\n",
       "  55\n",
       "  58\n",
       "   2\n",
       "  22\n",
       "  57\n",
       "  72\n",
       "   4\n",
       "  73\n",
       "   2\n",
       "  72\n",
       "  74\n",
       "  73\n",
       "  57\n",
       "  58\n",
       "  67\n",
       "  74\n",
       "  73\n",
       "  58\n",
       "  78\n",
       "  56\n",
       "  68\n",
       "  73\n",
       "  77\n",
       "  61\n",
       "  67\n",
       "   2\n",
       "  65\n",
       "   2\n",
       "  74\n",
       "  24\n",
       "  72\n",
       "  10\n",
       "  10\n",
       "  76\n",
       "  67\n",
       "  73\n",
       "  73\n",
       "  20\n",
       "  56\n",
       "  73\n",
       "  59\n",
       "  10\n",
       "   2\n",
       "  61\n",
       "  67\n",
       "   2\n",
       "  57\n",
       "  69\n",
       "  60\n",
       "  68\n",
       "  33\n",
       "   2\n",
       "  73\n",
       "  73\n",
       "  75\n",
       "  39\n",
       "  58\n",
       "   2\n",
       "  54\n",
       "  58\n",
       "   2\n",
       "   2\n",
       "  74\n",
       "  56\n",
       "  58\n",
       "  55\n",
       "  56\n",
       "  62\n",
       "  77\n",
       "  73\n",
       "  69\n",
       "  69\n",
       "   2\n",
       "   2\n",
       "  67\n",
       "  73\n",
       "  71\n",
       "  67\n",
       "   2\n",
       "  56\n",
       "   1\n",
       "  73\n",
       "  58\n",
       "   8\n",
       "  54\n",
       "  68\n",
       "  62\n",
       "  58\n",
       "  62\n",
       "   8\n",
       "  58\n",
       "  45\n",
       "  73\n",
       "  32\n",
       "  61\n",
       "  73\n",
       "  61\n",
       "  68\n",
       "   2\n",
       "  62\n",
       "  71\n",
       "  72\n",
       "  55\n",
       "   2\n",
       "  58\n",
       "   2\n",
       "  61\n",
       "   2\n",
       "  71\n",
       "  55\n",
       "  73\n",
       "  72\n",
       "  71\n",
       "  73\n",
       "  62\n",
       "  60\n",
       "  74\n",
       "  67\n",
       "  73\n",
       "  74\n",
       "  72\n",
       "  60\n",
       "  62\n",
       "  65\n",
       "  68\n",
       "  67\n",
       "  57\n",
       "  62\n",
       "  66\n",
       "   2\n",
       "  73\n",
       "   2\n",
       "  67\n",
       "  72\n",
       "  72\n",
       "  58\n",
       "  72\n",
       "  65\n",
       "  74\n",
       "  72\n",
       "   2\n",
       "  73\n",
       "  73\n",
       "   2\n",
       "  59\n",
       "   1\n",
       "  62\n",
       "  56\n",
       "  67\n",
       "  71\n",
       "  58\n",
       "  67\n",
       "  62\n",
       "   2\n",
       "  72\n",
       "  58\n",
       "   8\n",
       "  73\n",
       "  67\n",
       "   2\n",
       "  74\n",
       "  56\n",
       "   1\n",
       "  71\n",
       "  58\n",
       "  58\n",
       "  60\n",
       "  78\n",
       "   2\n",
       "  54\n",
       "  65\n",
       "  68\n",
       "  73\n",
       "   9\n",
       "   3\n",
       "  73\n",
       "  73\n",
       "   2\n",
       "  68\n",
       "  73\n",
       "  57\n",
       "  56\n",
       "  72\n",
       "  68\n",
       "  69\n",
       "  64\n",
       "  72\n",
       "  77\n",
       "  61\n",
       "  69\n",
       "   2\n",
       "  54\n",
       "  61\n",
       "   2\n",
       "  73\n",
       "  71\n",
       "   2\n",
       "   9\n",
       "   2\n",
       "  73\n",
       "  67\n",
       "   2\n",
       "  73\n",
       "  62\n",
       "  67\n",
       "  54\n",
       "   2\n",
       "  56\n",
       "  73\n",
       "  58\n",
       "   2\n",
       "  58\n",
       "  75\n",
       "  69\n",
       "  72\n",
       "  72\n",
       "  58\n",
       "  58\n",
       "   2\n",
       "  62\n",
       "  71\n",
       "   2\n",
       "  54\n",
       "  71\n",
       "  72\n",
       "  72\n",
       "  61\n",
       "  73\n",
       "   8\n",
       "  68\n",
       "  58\n",
       "  68\n",
       "   8\n",
       "  61\n",
       "  58\n",
       "   2\n",
       "   2\n",
       "  58\n",
       "  71\n",
       "  66\n",
       "   1\n",
       "  73\n",
       "  73\n",
       "  61\n",
       "  58\n",
       "   2\n",
       "  72\n",
       "  69\n",
       "  56\n",
       "  71\n",
       "  57\n",
       "  61\n",
       "  59\n",
       "  68\n",
       "  55\n",
       "  73\n",
       "  54\n",
       "   2\n",
       "   2\n",
       "  39\n",
       "   1\n",
       "  54\n",
       "  73\n",
       "  67\n",
       "  54\n",
       "  72\n",
       "  71\n",
       "   2\n",
       "  59\n",
       "  69\n",
       "  54\n",
       "  62\n",
       "  68\n",
       "  68\n",
       "  66\n",
       "  58\n",
       "  78\n",
       "  78\n",
       "   2\n",
       "  62\n",
       "  67\n",
       "  71\n",
       "  73\n",
       "  67\n",
       "  67\n",
       "  58\n",
       "  57\n",
       "  74\n",
       "  65\n",
       "  68\n",
       "  73\n",
       "  68\n",
       "  62\n",
       "   1\n",
       "  58\n",
       "   8\n",
       "  60\n",
       "  71\n",
       "  71\n",
       "  62\n",
       "   2\n",
       "  72\n",
       "   2\n",
       "  73\n",
       "  21\n",
       "   8\n",
       "  73\n",
       "  54\n",
       "  58\n",
       "  58\n",
       "  73\n",
       "  54\n",
       "   2\n",
       "  58\n",
       "  60\n",
       "   2\n",
       "  58\n",
       "  58\n",
       "  68\n",
       "  78\n",
       "  62\n",
       "  67\n",
       "  59\n",
       "  61\n",
       "  78\n",
       "  73\n",
       "   2\n",
       "  71\n",
       "  72\n",
       "  76\n",
       "  68\n",
       "  62\n",
       "  58\n",
       "   8\n",
       "  73\n",
       "  72\n",
       "  62\n",
       "   2\n",
       "   2\n",
       "  73\n",
       "  58\n",
       "  72\n",
       "  61\n",
       "  72\n",
       "   2\n",
       "  67\n",
       "  72\n",
       "  78\n",
       "  71\n",
       "  62\n",
       "  58\n",
       "   8\n",
       "  62\n",
       "  57\n",
       "   9\n",
       "  67\n",
       "  65\n",
       "  68\n",
       "   8\n",
       "  54\n",
       "  67\n",
       "  72\n",
       "   1\n",
       "  68\n",
       "   2\n",
       "  68\n",
       "  69\n",
       "  67\n",
       "   2\n",
       "   2\n",
       "  54\n",
       "  58\n",
       "   2\n",
       "  62\n",
       "  71\n",
       "  58\n",
       "  62\n",
       "  60\n",
       "  74\n",
       "  62\n",
       "  71\n",
       "  66\n",
       "  54\n",
       "  68\n",
       "   2\n",
       "  58\n",
       "  75\n",
       "  68\n",
       "  65\n",
       "  58\n",
       "  67\n",
       "  59\n",
       "  55\n",
       "  54\n",
       "  73\n",
       "   2\n",
       "   2\n",
       "  62\n",
       "  71\n",
       "  58\n",
       "  27\n",
       "  74\n",
       "  73\n",
       "   2\n",
       "   2\n",
       "  36\n",
       "  76\n",
       "   2\n",
       "  54\n",
       "  58\n",
       "   2\n",
       "   2\n",
       "  67\n",
       "  76\n",
       "  68\n",
       "  55\n",
       "  63\n",
       "  22\n",
       "   2\n",
       "  73\n",
       "  60\n",
       "   2\n",
       "   2\n",
       "   2\n",
       "  71\n",
       "  67\n",
       "  73\n",
       "   2\n",
       "  74\n",
       "  60\n",
       "  58\n",
       "  67\n",
       "   2\n",
       "  57\n",
       "  58\n",
       "   2\n",
       "  58\n",
       "   2\n",
       "  72\n",
       "  58\n",
       "  58\n",
       "  59\n",
       "  73\n",
       "  72\n",
       "  62\n",
       "  57\n",
       "   2\n",
       "   2\n",
       "   2\n",
       "  72\n",
       "  71\n",
       "   2\n",
       "  54\n",
       "  67\n",
       "   2\n",
       "  73\n",
       "  71\n",
       "   1\n",
       "  62\n",
       "  62\n",
       "  61\n",
       "   1\n",
       "  60\n",
       "  62\n",
       "   2\n",
       "  54\n",
       "   2\n",
       "  72\n",
       "  61\n",
       "  72\n",
       "  72\n",
       " [torch.cuda.LongTensor of size 512 (GPU 0)])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs[0].size(), xs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each one below are the (log) probabilities of the characters (a minibatch of 512 out of the 85 in the vocabulary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Variable containing:\n",
       "-4.6422 -4.5425 -4.4591  ...  -4.6062 -4.2883 -4.3331\n",
       "-4.3910 -4.5908 -4.4742  ...  -4.3545 -4.2008 -4.5668\n",
       "-4.4441 -4.5255 -4.3257  ...  -4.5036 -4.3068 -4.5682\n",
       "          ...             ⋱             ...          \n",
       "-4.4045 -4.7033 -4.5676  ...  -4.3706 -4.1562 -4.4312\n",
       "-4.1991 -4.8139 -4.5314  ...  -4.4237 -4.4263 -4.6011\n",
       "-4.5181 -4.4486 -4.5114  ...  -4.5055 -4.4911 -4.3749\n",
       "[torch.cuda.FloatTensor of size 512x85 (GPU 0)]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`optim.Adam(params, lr=0.001, betas=(0.9, 0.999), eps=1e-08, weight_decay=0)`  \n",
    "See [Adam: A Method for Stochastic Optimization](https://arxiv.org/abs/1412.6980)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the pytorch optimizer, pass a list of things to optimize, which are the parameters of the model (m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "opt = optim.Adam(m.parameters(), lr=1e-2)    #pytorch optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.learner import fit"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`fit(model, data, epochs, opt, crit, metrics=None, callbacks=None, stepper=<class 'fastai.model.Stepper'>, **kwargs)`\n",
    "Now returns the val_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c677701f9bf94f61ab9ef84f4067de0c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      2.061463   4.895084  \n",
      "\n",
      "CPU times: user 8.72 s, sys: 397 ms, total: 9.11 s\n",
      "Wall time: 4.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([ 4.89508])]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time fit(m, md, 1, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.layer_optimizer import set_lrs\n",
    "set_lrs(opt, 0.001)   # fastai set the lr for the optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e236bc86cfda4243baefe8818fb296e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      1.820131   5.26033   \n",
      "\n",
      "CPU times: user 8.86 s, sys: 450 ms, total: 9.31 s\n",
      "Wall time: 4.71 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([ 5.26033])]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time fit(m, md, 1, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5dc6c2159c1848eabd2ae06bb78c478d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      1.778682   5.130069  \n",
      "\n",
      "CPU times: user 8.94 s, sys: 396 ms, total: 9.33 s\n",
      "Wall time: 4.68 s\n"
     ]
    }
   ],
   "source": [
    "%time vl = fit(m, md, 1, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 5.13007])]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vl"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`get_next(inp)` will return the next (predicted) character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.core import T, VV, to_np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next(inp):\n",
    "    idxs = T(np.array([char_indices[c] for c in inp]))  # T converts to Tensor\n",
    "    p = m(*VV(idxs))  # convert to variables and pass to model\n",
    "    i = np.argmax(to_np(p)) # grab the character number, converting it first to np\n",
    "    return chars[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'T'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('y. ')  #pass it 3 characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('i', 'e', ' ')"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('ppl'), get_next(' th'), get_next('and')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Our first RNN!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create inputs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the size of our unrolled RNN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "cs=8    # 8 characters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of 0 through 7, create a list of every 8th character with that starting point. These will be the 8 inputs to the model.  j will go from 0 to len(idx)-cs-1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_in_dat = [[idx[i+j] for i in range(cs)] for j in range(len(idx)-cs-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[40, 42, 29, 30, 25, 27, 29, 1],\n",
       " [42, 29, 30, 25, 27, 29, 1, 1],\n",
       " [29, 30, 25, 27, 29, 1, 1, 1],\n",
       " [30, 25, 27, 29, 1, 1, 1, 43],\n",
       " [25, 27, 29, 1, 1, 1, 43, 45],\n",
       " [27, 29, 1, 1, 1, 43, 45, 40],\n",
       " [29, 1, 1, 1, 43, 45, 40, 40],\n",
       " [1, 1, 1, 43, 45, 40, 40, 39],\n",
       " [1, 1, 43, 45, 40, 40, 39, 43],\n",
       " [1, 43, 45, 40, 40, 39, 43, 33]]"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_in_dat[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then create a list of the next (+cs) character in each of these series. \n",
    "This list will have the labels for the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_out_dat = [idx[j+cs] for j in range(len(idx)-cs-1)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 1, 43, 45, 40, 40, 39, 43, 33, 38]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_out_dat[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "JS had the slower xs = np.stack(c_in_dat, axis=0)   # could be xs = np.asarray(c_in_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "xs = np.asarray(c_in_dat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(600884, 8)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[40, 42, 29, 30, 25, 27, 29,  1],\n",
       "       [42, 29, 30, 25, 27, 29,  1,  1],\n",
       "       [29, 30, 25, 27, 29,  1,  1,  1],\n",
       "       [30, 25, 27, 29,  1,  1,  1, 43],\n",
       "       [25, 27, 29,  1,  1,  1, 43, 45],\n",
       "       [27, 29,  1,  1,  1, 43, 45, 40],\n",
       "       [29,  1,  1,  1, 43, 45, 40, 40],\n",
       "       [ 1,  1,  1, 43, 45, 40, 40, 39],\n",
       "       [ 1,  1, 43, 45, 40, 40, 39, 43],\n",
       "       [ 1, 43, 45, 40, 40, 39, 43, 33]])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.asarray(c_out_dat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So each column below is one series of 8 characters from the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[40, 42, 29, 30, 25, 27, 29,  1],\n",
       "       [42, 29, 30, 25, 27, 29,  1,  1],\n",
       "       [29, 30, 25, 27, 29,  1,  1,  1],\n",
       "       [30, 25, 27, 29,  1,  1,  1, 43],\n",
       "       [25, 27, 29,  1,  1,  1, 43, 45],\n",
       "       [27, 29,  1,  1,  1, 43, 45, 40],\n",
       "       [29,  1,  1,  1, 43, 45, 40, 40],\n",
       "       [ 1,  1,  1, 43, 45, 40, 40, 39]])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs[:cs,:cs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "...and this is the next character after each sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 1,  1, 43, 45, 40, 40, 39, 43])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y[:cs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and train model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`get_cv_idxs(n, cv_idx=0, val_pct=0.2, seed=42)` from fastai\n",
    "\n",
    "Get a list of index values for Validation set from a dataset\n",
    "\n",
    "Arguments:\n",
    "    n : int, Total number of elements in the data set.\n",
    "    cv_idx : int, starting index [idx_start = cv_idx*int(val_pct*n)] \n",
    "    val_pct : (int, float), validation set percentage \n",
    "    seed : seed value for RandomState\n",
    "   \n",
    "Returns:\n",
    "    list of indexes "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.dataset import get_cv_idxs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_idx = get_cv_idxs(len(idx)-cs-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(120176, array([480310, 419017, 232803, ..., 134355, 389158, 330599]))"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(val_idx), val_idx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = ColumnarModelData.from_arrays('.', val_idx, xs, y, bs=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`CharLoopModel(nn.Module)` is an RNN!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharLoopModel(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac):\n",
    "        super().__init__()\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)    #Embedding Layer\n",
    "        self.l_in = nn.Linear(n_fac, n_hidden)      #in linear\n",
    "        self.l_hidden = nn.Linear(n_hidden, n_hidden) #hidden\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size) # out\n",
    "        \n",
    "    def forward(self, *cs):\n",
    "        bs = cs[0].size(0)\n",
    "        h = V(torch.zeros(bs, n_hidden).cuda())\n",
    "        for c in cs:   #here is the loop\n",
    "            inp = F.relu(self.l_in(self.e(c)))\n",
    "            h = F.tanh(self.l_hidden(h+inp))\n",
    "        \n",
    "        return F.log_softmax(self.l_out(h), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = CharLoopModel(vocab_size, n_fac).cuda() \n",
    "opt = optim.Adam(m.parameters(), 1e-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "fd0c09fc7cbb4db9b2ac30d01133045a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      2.015361   1.984964  \n",
      "\n",
      "CPU times: user 33.6 s, sys: 1.61 s, total: 35.2 s\n",
      "Wall time: 22.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([ 1.98496])]"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time fit(m, md, 1, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_lrs(opt, 0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0afa712e324544c5a372d64bfb67e3f8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      1.72084    1.719567  \n",
      "\n",
      "CPU times: user 33.1 s, sys: 1.27 s, total: 34.4 s\n",
      "Wall time: 21.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([ 1.71957])]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time fit(m, md, 1, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Adding things together may loose information... so lets use concatenation which is better in those cases...\n",
    "Notice  we pass `n_fac+n_hidden` to the first Linear layer, to get the right dimensions in the input layer.\n",
    "When we have information, even if it is of the same dimension, concatenating preserves more informtion than adding.\n",
    "And then use `torch.cat((h, self.e(c)), 1)` in the forward loop."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharLoopConcatModel(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac):\n",
    "        super().__init__()\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "        self.l_in = nn.Linear(n_fac+n_hidden, n_hidden) # concatenation\n",
    "        self.l_hidden = nn.Linear(n_hidden, n_hidden)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        \n",
    "    def forward(self, *cs):\n",
    "        bs = cs[0].size(0)\n",
    "        h = V(torch.zeros(bs, n_hidden).cuda())\n",
    "        for c in cs:\n",
    "            inp = torch.cat((h, self.e(c)), 1)   #now concatenate instead of adding\n",
    "            inp = F.relu(self.l_in(inp))\n",
    "            h = F.tanh(self.l_hidden(inp))\n",
    "        \n",
    "        return F.log_softmax(self.l_out(h), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = CharLoopConcatModel(vocab_size, n_fac).cuda()\n",
    "opt = optim.Adam(m.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(md.trn_dl)\n",
    "*xs,yt = next(it)\n",
    "t = m(*V(xs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c6b3254d832346868cd6f5167fe39e53",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      1.814632   1.793261  \n",
      "\n",
      "CPU times: user 34.1 s, sys: 1.35 s, total: 35.4 s\n",
      "Wall time: 22.4 s\n"
     ]
    }
   ],
   "source": [
    "%time vl1 = fit(m, md, 1, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_lrs(opt, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d3cd7fbbfb0140bd9cc13076c2a8074a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      1.699837   1.707809  \n",
      "\n",
      "CPU times: user 34.2 s, sys: 1.43 s, total: 35.7 s\n",
      "Wall time: 22.7 s\n"
     ]
    }
   ],
   "source": [
    "%time vls2 = fit(m, md, 1, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Improved from {{vl1}}  to {{vls2}}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('e', 'e', ' ')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('ppl'), get_next(' th'), get_next('and')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "# RNN with pytorch\n",
    "Now lets use Pytorch to do for us the writing of the loop in the forward (with a starting point) and create the input linear layers.\n",
    "For this we use the `nn.RNN`.\n",
    "Pytorch appends a hidden state, so it returns all of them. \n",
    "But we care only for the last one, we use outp[-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problem is that in the forward below we keep throwing away the hidden $h$.\n",
    "So we will fix this in the next part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharRnn(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac):\n",
    "        super().__init__()\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "        self.rnn = nn.RNN(n_fac, n_hidden)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        \n",
    "    def forward(self, *cs):\n",
    "        bs = cs[0].size(0)\n",
    "        h = V(torch.zeros(1, bs, n_hidden))\n",
    "        inp = self.e(torch.stack(cs))\n",
    "        outp,h = self.rnn(inp, h)    #Pytorch returns all the hidden states in h\n",
    "        \n",
    "        return F.log_softmax(self.l_out(outp[-1]), dim=-1)   #outp[-1] because we only care for the last one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = CharRnn(vocab_size, n_fac).cuda()\n",
    "opt = optim.Adam(m.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(md.trn_dl)\n",
    "*xs,yt = next(it)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([8, 512, 42])"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = m.e(V(torch.stack(xs)))\n",
    "t.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([8, 512, 256]), torch.Size([1, 512, 256]))"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ht = V(torch.zeros(1, 512,n_hidden))\n",
    "outp, hn = m.rnn(t, ht)\n",
    "outp.size(), hn.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([512, 85])"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t = m(*V(xs)); t.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b995f20b4ad64185b63ecb781bf1924a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      1.881316   1.85602   \n",
      "    1      1.677138   1.67785                               \n",
      "    2      1.590103   1.598457                              \n",
      "    3      1.539169   1.551392                              \n",
      "\n",
      "CPU times: user 2min 3s, sys: 6.66 s, total: 2min 9s\n",
      "Wall time: 1min 19s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([ 1.55139])]"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time fit(m, md, 4, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_lrs(opt, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "142ffcae9135410ca2424b784d710168",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      1.465953   1.512221  \n",
      "    1      1.456044   1.506954                              \n",
      "\n",
      "CPU times: user 1min 1s, sys: 3.27 s, total: 1min 5s\n",
      "Wall time: 39.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([ 1.50695])]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time fit(m, md, 2, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('e', 't', 'n')"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('for thos'), get_next('part of '), get_next('queens a')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get_next_n() used to look forward multiple chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_n(inp, n):\n",
    "    res = inp\n",
    "    for i in range(n):\n",
    "        c = get_next(inp)\n",
    "        res += c\n",
    "        inp = inp[1:]+c\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('for those stand the same the same the same the s',\n",
       " 'part of the same the same the same the same the ',\n",
       " 'queens and the same the same the same the same t')"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next_n('for thos', 40), get_next_n('part of ', 40), get_next_n('queens a', 40)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Multi-output model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's take non-overlapping sets of characters this time. Recall the overlapping was done by\n",
    "`c_in_dat = [[idx[i+j] for i in range(cs)] for j in range(len(idx)-cs-1)]`\n",
    "\n",
    "using `range(start, stop[, step])`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_in_dat = [[idx[i+j] for i in range(cs)] for j in range(0, len(idx)-cs-1, cs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[40, 42, 29, 30, 25, 27, 29, 1],\n",
       " [1, 1, 43, 45, 40, 40, 39, 43],\n",
       " [33, 38, 31, 2, 73, 61, 54, 73],\n",
       " [2, 44, 71, 74, 73, 61, 2, 62],\n",
       " [72, 2, 54, 2, 76, 68, 66, 54],\n",
       " [67, 9, 9, 76, 61, 54, 73, 2],\n",
       " [73, 61, 58, 67, 24, 2, 33, 72],\n",
       " [2, 73, 61, 58, 71, 58, 2, 67],\n",
       " [68, 73, 2, 60, 71, 68, 74, 67],\n",
       " [57, 1, 59, 68, 71, 2, 72, 74]]"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c_in_dat[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then create the exact same thing, offset by 1, as our labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_out_dat = [[idx[i+j] for i in range(cs)] for j in range(1, len(idx)-cs, cs)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75111, 8)"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs = np.stack(c_in_dat)\n",
    "xs.shape  # shape is now 600884/8, as we are looking at 8 non-overlapping characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(75111, 8)"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys = np.stack(c_out_dat)\n",
    "ys.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[40, 42, 29, 30, 25, 27, 29,  1],\n",
       "       [ 1,  1, 43, 45, 40, 40, 39, 43],\n",
       "       [33, 38, 31,  2, 73, 61, 54, 73],\n",
       "       [ 2, 44, 71, 74, 73, 61,  2, 62],\n",
       "       [72,  2, 54,  2, 76, 68, 66, 54],\n",
       "       [67,  9,  9, 76, 61, 54, 73,  2],\n",
       "       [73, 61, 58, 67, 24,  2, 33, 72],\n",
       "       [ 2, 73, 61, 58, 71, 58,  2, 67]])"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xs[:cs,:cs]   # using non-overlapping characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[42, 29, 30, 25, 27, 29,  1,  1],\n",
       "       [ 1, 43, 45, 40, 40, 39, 43, 33],\n",
       "       [38, 31,  2, 73, 61, 54, 73,  2],\n",
       "       [44, 71, 74, 73, 61,  2, 62, 72],\n",
       "       [ 2, 54,  2, 76, 68, 66, 54, 67],\n",
       "       [ 9,  9, 76, 61, 54, 73,  2, 73],\n",
       "       [61, 58, 67, 24,  2, 33, 72,  2],\n",
       "       [73, 61, 58, 71, 58,  2, 67, 68]])"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ys[:cs,:cs]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create and train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_idx = get_cv_idxs(len(xs)-cs-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "md = ColumnarModelData.from_arrays('.', val_idx, xs, ys, bs=512)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the earlier `CharRNN` the softmax used outp[-1], because we only cared for the last one.\n",
    "This time we would use the full outp so we get them all...."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharSeqRnn(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac):\n",
    "        super().__init__()\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "        self.rnn = nn.RNN(n_fac, n_hidden)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        \n",
    "    def forward(self, *cs):\n",
    "        bs = cs[0].size(0)\n",
    "        h = V(torch.zeros(1, bs, n_hidden))\n",
    "        inp = self.e(torch.stack(cs))\n",
    "        outp,h = self.rnn(inp, h)\n",
    "        return F.log_softmax(self.l_out(outp), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = CharSeqRnn(vocab_size, n_fac).cuda()   # cuda(1) to use the 2nd GPU \n",
    "opt = optim.Adam(m.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "it = iter(md.trn_dl)\n",
    "*xst,yt = next(it)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a rank 3 tensor (8x84x512), since we have 8 characters (time steps) for each of them we have 84 probabilities for every character, and that for each of the 512 items in the minibatch.\n",
    "The pytorch loss function expects rank 2 tensors.. (bad design)\n",
    "So we now write our own custom loss function for sequences, `nll_loss_seq(inp, targ)`\n",
    "We need to flatten our input (using .size to pull them)and flatten our targets.\n",
    "We also need to transpose the axises.\n",
    "In pytorch the axises are:\n",
    "- sl is the sequence length (eg 8)\n",
    "- bs is batch size (eg 512)\n",
    "- nh is hidden state (eg 256, n_hidden)\n",
    "\n",
    "Because of an issue with Pytorch we need to invoke `contiguos` and invoke `.view` which is like reshape to flatten the input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "def nll_loss_seq(inp, targ):\n",
    "    sl,bs,nh = inp.size() # need to transpose the first 2 axis to be sl, bs, number hidden 8, 512, 256\n",
    "    targ = targ.transpose(0,1).contiguous().view(-1)  \n",
    "    #contiguos to avoid a pytorch error message, -1 == as long as needs to be\n",
    "    return F.nll_loss(inp.view(-1,nh), targ)  # invoke the pytorch nll loss function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So now we can pass the custom loss function `nll_loss_seq` to `fit`.\n",
    "Recall that in `fit()` the parameters are all standard pytorch, except for the first 2 parameters, `m`, and `md`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3eb08b6df3ec4a1ab13e444abc878deb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      2.602346   2.415453  \n",
      "    1      2.294791   2.203934                              \n",
      "    2      2.144559   2.090983                              \n",
      "    3      2.050911   2.014842                              \n",
      "\n",
      "CPU times: user 15.2 s, sys: 853 ms, total: 16 s\n",
      "Wall time: 9.72 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([ 2.01484])]"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time fit(m, md, 4, opt, nll_loss_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_lrs(opt, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "6127830487ba4626bd8aa2fe6c799363",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                             \n",
      "    0      1.999156   1.999102  \n",
      "\n",
      "CPU times: user 3.85 s, sys: 244 ms, total: 4.09 s\n",
      "Wall time: 2.45 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([ 1.9991])]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time fit(m, md, 1, opt, nll_loss_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identity init!\n",
    "One problem is that we could get gradient explosion... To avoid it, lets use an initialization (instead of random), based on G. Hinton paper [A Simple Way to Initialize Recurrent Networks of Rectified Linear Units](https://arxiv.org/abs/1504.00941)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = CharSeqRnn(vocab_size, n_fac).cuda()\n",
    "opt = optim.Adam(m.parameters(), 1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "By G. Hinton, lets use the Identity Matrix to initialize.\n",
    "See `m.rnn` to see the attributes that are learneable.\n",
    "Specificaly, `weight_hh_l[k] : the learnable hidden-hidden weights of the k-th layer`.\n",
    "This initialization improves our results significantly.            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "#??m.rnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\n",
       "    1     0     0  ...      0     0     0\n",
       "    0     1     0  ...      0     0     0\n",
       "    0     0     1  ...      0     0     0\n",
       "       ...          ⋱          ...       \n",
       "    0     0     0  ...      1     0     0\n",
       "    0     0     0  ...      0     1     0\n",
       "    0     0     0  ...      0     0     1\n",
       "[torch.cuda.FloatTensor of size 256x256 (GPU 0)]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.rnn.weight_hh_l0.data.copy_(torch.eye(n_hidden))   #eye is the identity matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8adab1eb6c944939bdbfdbb630bd85fa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      2.49338    2.309519  \n",
      "    1      2.193046   2.125766                              \n",
      "    2      2.06573    2.029975                              \n",
      "    3      1.994678   1.980016                              \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([ 1.98002])]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(m, md, 4, opt, nll_loss_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_lrs(opt, 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2287559e27fa4afabde3d4b55f951d37",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      1.90354    1.912661  \n",
      "    1      1.892017   1.904126                              \n",
      "    2      1.883681   1.898293                              \n",
      "    3      1.877339   1.894527                              \n",
      "\n",
      "CPU times: user 15.3 s, sys: 893 ms, total: 16.2 s\n",
      "Wall time: 9.86 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([ 1.89453])]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time fit(m, md, 4, opt, nll_loss_seq)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stateful RNN model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.nlp import LanguageModelData #*\n",
    "from fastai.lm_rnn import repackage_var  #*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that at the beginning we did:\n",
    "\n",
    "TEXT = data.Field(lower=True, tokenize=list)\n",
    "\n",
    "FILES = dict(train=TRN_PATH, validation=VAL_PATH, test=VAL_PATH)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters for the model:\n",
    "- bs = batch size\n",
    "- bptt = backprop thru time\n",
    "- n_fac size of embedding\n",
    "- n_hidden: size of the hidden \"circles\" "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " minibatchlength= 942 number of tokens= 55\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1, 482908)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bs=64; bptt=8; n_fac=42; n_hidden=256\n",
    "\n",
    "md = LanguageModelData.from_text_files(PATH, TEXT, **FILES, bs=bs, bptt=bptt, min_freq=3)\n",
    "print(\" minibatchlength=\", len(md.trn_dl), \"number of tokens=\", md.nt)\n",
    "len(md.trn_ds), len(md.trn_ds[0].text)   # definitions?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<fastai.nlp.ConcatTextDataset at 0x7f84b0935780>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "md.trn_ds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that after the model is created, the TEXT object also contains many additional fields, eg, vocab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TEXT.vocab"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pytorch \"randomizes\" the size of bptt for each minibatch. Sometimes a little smaller, etc."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BPTT\n",
    "Wrinkle #1, we can get into a back-prop thru too many layers...\n",
    "The difference below is that we invoke `init_hidden()` as part of the constructor.\n",
    "If we did not use repackage_var there would be too many layers, which will be very memory intensive.\n",
    "to avoid that, from time to time we want to forget the history. \n",
    "We still remember the state, but forget most of how we got there.\n",
    "\n",
    "**Solution: Forget some of your history**\n",
    "We want to remember the current state, but not all the history on how we got there.\n",
    "\n",
    "self.h = repackage_var(h) - will get the tensor (activations) out of the variable, and make a new variable out of that. (but no history of operations).\n",
    "It will backpropogate through 8 layers, but throw away the history of operations, this is also called Backprop through time = bptt\n",
    "Another reason not to backprop all the way back is because of exploding gradients; more layers, more chances the gradients will go through the roof.\n",
    "\n",
    "\n",
    "That is provided by `repackage_var()`. It just takes the last (current) value of the Variable (.data) and throws away the history of operations and start afresh.\n",
    "This approach is called `Back-Prop Thru time (BPTT)`.\n",
    "Another reason to use this is that the larger number of layers, the harder it is to train... \n",
    "A larger value of the BPTT parameter indicates how many layers to back-prop thru, \n",
    "which implies more memory, which keeps more memory.\n",
    "\n",
    "`repackage_var(h):` Wraps h in new Variables, to detach them from their history\n",
    "    return Variable(h.data) if type(h) == Variable else tuple(repackage_var(v) for v in h)\n",
    "\n",
    "File:      ~/fastai/courses/dl1/fastai/lm_rnn.py"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to split the data (chunks) into batches\n",
    "Wrinkle #2, we need to properly split the chunks. First we split the (large) text into $n$, e.g., $n=64$ chunks. \n",
    "Then we look at subsets of size `bptt` in parallel.\n",
    "See [Lesson 6](https://www.youtube.com/watch?v=H3g26EVADgY&t=1195s)\n",
    "00:17:50 Creating mini-batches, “split in 64 equal size chunks” not “split in chunks of size 64”, questions on data augmentation and choosing a BPTT size, PyTorch QRNN.\n",
    "The chunks are of size `BPTT * BS`. And this size should fit into the memory of the GPU. \n",
    "If performance is too slow, lowering the BPTT may expedite it."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will use torchtext again....  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The class is similar to before, but now we invoke `init_hidden()` in __init__, so **h** is now an attribute,\n",
    "which starts as a Variable set as zeros.  \n",
    "\n",
    "00:35:43 Dealing with PyTorch not accepting a “Rank 3 Tensor”, only Rank 2 or 4, ‘F.log_softmax()’\n",
    "Also, pytorch loss functions are not \"happy\" receiving Tensors of rank 3.  JH: not good reason for this...\n",
    "it expects a rank 2 (or rank 4) tensor.  \n",
    "so we need to use `.view()` to flatten out the input. The number of columns will be the `vocab_size`, while the number of rows is \"-1\", ie whatever is needed (ie bs * bptt).\n",
    "For the traget, `torchtext` automatically changes the target to be flatten."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharSeqStatefulRnn(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac, bs):\n",
    "        self.vocab_size = vocab_size\n",
    "        super().__init__()\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "        self.rnn = nn.RNN(n_fac, n_hidden)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        self.init_hidden(bs)\n",
    "        \n",
    "    def forward(self, cs):\n",
    "        bs = cs[0].size(0)\n",
    "        #check for the last batch, as for each epoch we need to reinitialize, for end of each epoch start of each epoch problem \n",
    "        if self.h.size(1) != bs: self.init_hidden(bs)\n",
    "        outp,h = self.rnn(self.e(cs), self.h)   # now it takes self.h as input\n",
    "        self.h = repackage_var(h)    # now store it throwing away history of operations\n",
    "        return F.log_softmax(self.l_out(outp), dim=-1).view(-1, self.vocab_size)\n",
    "    \n",
    "    def init_hidden(self, bs): self.h = V(torch.zeros(1, bs, n_hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = CharSeqStatefulRnn(md.nt, n_fac, 512).cuda()\n",
    "opt = optim.Adam(m.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Careful, pytorch 0.3 requires that we tell it over which axis to sum over. Here we passed the last axis (-1) which is the probability per latter of the vocabulary. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "0e62ddd3a238423881d761d513653832",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                               \n",
      "    0      1.885003   1.855492  \n",
      "    1      1.71443    1.711497                               \n",
      "    2      1.639589   1.646649                               \n",
      "    3      1.577061   1.602231                               \n",
      "\n",
      "CPU times: user 25.2 s, sys: 3.6 s, total: 28.8 s\n",
      "Wall time: 24.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([ 1.60223])]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time fit(m, md, 4, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ff2b7639457b4e5caf6d2d90e140bb70",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                               \n",
      "    0      1.498694   1.559651  \n",
      "    1      1.503777   1.55453                                \n",
      "    2      1.500938   1.548958                               \n",
      "    3      1.499807   1.545453                               \n",
      "\n",
      "CPU times: user 25.2 s, sys: 3.45 s, total: 28.7 s\n",
      "Wall time: 24.3 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([ 1.54545])]"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_lrs(opt, 1e-4)\n",
    "\n",
    "%time fit(m, md, 4, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RNN loop"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the pytorch source, just for reference, no need to execute it.\n",
    "Notice that they do not concatenate....\n",
    "But in practice, nobody uses this because of gradient explosions, so we need to use very small values of lr and bptt.\n",
    "Instead of it we use GRU cell (see later)\n",
    "\n",
    "def RNNCell(input, hidden, w_ih, w_hh, b_ih, b_hh):\n",
    "\n",
    "    return F.tanh(F.linear(input, w_ih, b_ih) + F.linear(hidden, w_hh, b_hh))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharSeqStatefulRnn2(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac, bs):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "        self.rnn = nn.RNNCell(n_fac, n_hidden)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        self.init_hidden(bs)\n",
    "        \n",
    "    def forward(self, cs):\n",
    "        bs = cs[0].size(0)\n",
    "        if self.h.size(1) != bs: self.init_hidden(bs)\n",
    "        outp = []\n",
    "        o = self.h\n",
    "        for c in cs: \n",
    "            o = self.rnn(self.e(c), o)\n",
    "            outp.append(o)\n",
    "        outp = self.l_out(torch.stack(outp))\n",
    "        self.h = repackage_var(o)\n",
    "        return F.log_softmax(outp, dim=-1).view(-1, self.vocab_size)\n",
    "    \n",
    "    def init_hidden(self, bs): self.h = V(torch.zeros(1, bs, n_hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = CharSeqStatefulRnn2(md.nt, n_fac, 512).cuda()\n",
    "opt = optim.Adam(m.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "02a2c83870174f819893e2f3adb80844",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      1.891111   1.857432  \n",
      "    1      1.715802   1.704021                              \n",
      "    2      1.631887   1.637275                              \n",
      "    3      1.578639   1.603177                              \n",
      "\n",
      "CPU times: user 46.4 s, sys: 3.45 s, total: 49.8 s\n",
      "Wall time: 44.6 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([ 1.60318])]"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time fit(m, md, 4, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### GRU (Gated Recurrent Unit) Cell\n",
    " A gating mechanism in RNNs, introduced in [Learning Phrase Representations using RNN Encoder-Decoder for Statistical Machine Translation](https://arxiv.org/abs/1406.1078). Their performance on polyphonic music modeling and speech signal modeling was found to be similar to that of long short-term memory. However, GRUs have been shown to exhibit better performance on smaller datasets.\n",
    "\n",
    "See below http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-var-GRU.png![image.png](attachment:image.png)\n",
    "\n",
    "Uses a mini-neural-net to decide when to throw away information. For example, when it sees a \".\".\n",
    "Also has an outtake gate, decides when to update and by how much the hidden state."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<img src=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-var-GRU.png\"/>"
      ],
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Image\n",
    "Image(url='http://colah.github.io/posts/2015-08-Understanding-LSTMs/img/LSTM3-var-GRU.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharSeqStatefulGRU(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac, bs):\n",
    "        super().__init__()\n",
    "        self.vocab_size = vocab_size\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "        self.rnn = nn.GRU(n_fac, n_hidden)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        self.init_hidden(bs)\n",
    "        \n",
    "    def forward(self, cs):\n",
    "        bs = cs[0].size(0)\n",
    "        if self.h.size(1) != bs: self.init_hidden(bs)\n",
    "        outp,h = self.rnn(self.e(cs), self.h)\n",
    "        self.h = repackage_var(h)\n",
    "        return F.log_softmax(self.l_out(outp), dim=-1).view(-1, self.vocab_size)\n",
    "    \n",
    "    def init_hidden(self, bs): self.h = V(torch.zeros(1, bs, n_hidden))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "# From the pytorch source code - for reference\n",
    "\n",
    "def GRUCell(input, hidden, w_ih, w_hh, b_ih, b_hh):\n",
    "    gi = F.linear(input, w_ih, b_ih)\n",
    "    gh = F.linear(hidden, w_hh, b_hh)\n",
    "    i_r, i_i, i_n = gi.chunk(3, 1)\n",
    "    h_r, h_i, h_n = gh.chunk(3, 1)\n",
    "\n",
    "    resetgate = F.sigmoid(i_r + h_r)\n",
    "    inputgate = F.sigmoid(i_i + h_i)\n",
    "    newgate = F.tanh(i_n + resetgate * h_n)\n",
    "    return newgate + inputgate * (hidden - newgate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = CharSeqStatefulGRU(md.nt, n_fac, 512).cuda()\n",
    "\n",
    "opt = optim.Adam(m.parameters(), 1e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ebe08882115d430fa5df43254bb8dbf1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                               \n",
      "    0      1.775305   1.740946  \n",
      "    1      1.594406   1.591478                               \n",
      "    2      1.50108    1.529803                               \n",
      "    3      1.448508   1.49697                                \n",
      "    4      1.405877   1.478582                               \n",
      "    5      1.374997   1.463661                               \n",
      "\n",
      "CPU times: user 39.3 s, sys: 5.16 s, total: 44.4 s\n",
      "Wall time: 37.9 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([ 1.46366])]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time fit(m, md, 6, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "set_lrs(opt, 1e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7c75d7323d64927be47d61bc5958a16",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                               \n",
      "    0      1.291673   1.430188  \n",
      "    1      1.297437   1.426499                               \n",
      "    2      1.299452   1.424684                               \n",
      "\n",
      "CPU times: user 20.3 s, sys: 2.57 s, total: 22.9 s\n",
      "Wall time: 19.4 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([ 1.42468])]"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time fit(m, md, 3, opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Putting it all together: LSTM\n",
    "See [Understanding LSTM Networks by Colah](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)\n",
    "\n",
    "Now for an LSTM cell, instead of GRU.\n",
    "LSTM has the cell state in addition to the hidden, so we return a tuple of matrices.\n",
    "Added dropout (after each time step) and doubled the size of the hidden layer.j"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import sgdr\n",
    "n_hidden=512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "class CharSeqStatefulLSTM(nn.Module):\n",
    "    def __init__(self, vocab_size, n_fac, bs, nl):\n",
    "        super().__init__()\n",
    "        self.vocab_size,self.nl = vocab_size,nl\n",
    "        self.e = nn.Embedding(vocab_size, n_fac)\n",
    "        self.rnn = nn.LSTM(n_fac, n_hidden, nl, dropout=0.5)\n",
    "        self.l_out = nn.Linear(n_hidden, vocab_size)\n",
    "        self.init_hidden(bs)\n",
    "        \n",
    "    def forward(self, cs):\n",
    "        bs = cs[0].size(0)\n",
    "        if self.h[0].size(1) != bs: self.init_hidden(bs)\n",
    "        outp,h = self.rnn(self.e(cs), self.h)\n",
    "        self.h = repackage_var(h)\n",
    "        return F.log_softmax(self.l_out(outp), dim=-1).view(-1, self.vocab_size)\n",
    "    \n",
    "    def init_hidden(self, bs):\n",
    "        self.h = (V(torch.zeros(self.nl, bs, n_hidden)),\n",
    "                  V(torch.zeros(self.nl, bs, n_hidden)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "m = CharSeqStatefulLSTM(md.nt, n_fac, 512, 2).cuda()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But now, instead of using the pytorch optimizer, we use the fastai \n",
    "`LayerOptimizer(opt_fn, layer_groups, lrs, wds=None)` from \n",
    "File:           ~/fastai/courses/dl1/fastai/layer_optimizer.py\n",
    "which add learning rate and weight decay."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.layer_optimizer import LayerOptimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "lo = LayerOptimizer(optim.Adam, m, 1e-2, 1e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.optim.adam.Adam at 0x7f846bb5f438>"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lo.opt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(f'{PATH}models', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4334f8a7184d4c5cae7985f203fa1c06",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      1.816026   1.732448  \n",
      "    1      1.718293   1.652915                              \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([ 1.65292])]"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fit(m, md, 2, lo.opt, F.nll_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But now we can pass a function as a a callback to `fit` to dynamically change the learning rate.\n",
    "Below we pass the `CosAnneal(layer_opt, nb, on_cycle_end=None, cycle_mult=1)` from fastai.sgdr, \n",
    "which will update the learning rates when we call fit.\n",
    "`layer_opt` is the optimizer object, \n",
    "`nb` is the length of an epoch, eg `len(md.trn_dl)`, how many minibatches in an epoch (needed to know how often to reset).\n",
    "Then automatically save the model (passing another callbck, on_end, which uses fastai `save_model`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.sgdr import CosAnneal\n",
    "from fastai.torch_imports import save_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "on_end = lambda sched, cycle: save_model(m, f'{PATH}models/cyc_{cycle}')\n",
    "cb = [CosAnneal(lo, len(md.trn_dl), cycle_mult=2, on_cycle_end=on_end)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e5d49fea13924379b2c8cd1e031a83f7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                               \n",
      "    0      1.54353    1.487647  \n",
      "    1      1.594493   1.526807                              \n",
      "    2      1.472359   1.437603                              \n",
      "    3      1.615485   1.543589                               \n",
      "    4      1.540682   1.487883                               \n",
      "    5      1.454911   1.428852                              \n",
      "    6      1.390208   1.39055                               \n",
      "    7      1.589738   1.532587                              \n",
      "    8      1.549987   1.509889                              \n",
      "    9      1.525921   1.485307                              \n",
      "    10     1.479244   1.455329                               \n",
      "    11     1.437987   1.428274                              \n",
      "    12     1.387103   1.398252                              \n",
      "    13     1.347644   1.370574                              \n",
      "    14     1.320503   1.35871                               \n",
      "\n",
      "CPU times: user 2min 35s, sys: 15.4 s, total: 2min 51s\n",
      "Wall time: 2min 32s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([ 1.35871])]"
      ]
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time fit(m, md, 2**4-1, lo.opt, F.nll_loss, callbacks=cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit again starting with a smaller lr.   Wall time: 10min 22s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "80b36efc309e4de0ba7a316bd0db2836",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "A Jupyter Widget"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss                              \n",
      "    0      1.542346   1.494945  \n",
      "    1      1.498697   1.468537                               \n",
      "    2      1.475329   1.461309                              \n",
      "    3      1.448708   1.431154                              \n",
      "    4      1.401603   1.405935                              \n",
      "    5      1.35829    1.37964                               \n",
      "    6      1.316973   1.358165                              \n",
      "    7      1.292795   1.349112                              \n",
      "    8      1.523479   1.492144                               \n",
      "    9      1.49655    1.486515                               \n",
      "    10     1.48825    1.47728                               \n",
      "    11     1.479888   1.475037                              \n",
      "    12     1.469291   1.4608                                \n",
      "    13     1.451007   1.450497                              \n",
      "    14     1.43606    1.429036                              \n",
      "    15     1.41056    1.418746                              \n",
      "    16     1.396541   1.410116                               \n",
      "    17     1.3763     1.391736                              \n",
      "    18     1.349578   1.381181                              \n",
      "    19     1.318932   1.367243                               \n",
      "    20     1.298812   1.357498                              \n",
      "    21     1.276675   1.349226                              \n",
      "    22     1.253129   1.341339                               \n",
      "    23     1.236464   1.336367                               \n",
      "    24     1.234511   1.335783                              \n",
      "    25     1.473742   1.465081                              \n",
      "    26     1.467596   1.467623                              \n",
      "    27     1.459101   1.460363                              \n",
      "    28     1.459307   1.454681                              \n",
      "    29     1.458969   1.460206                              \n",
      "    30     1.465206   1.45441                                \n",
      "    31     1.460942   1.45692                               \n",
      "    32     1.458345   1.444125                              \n",
      "    33     1.447614   1.447827                              \n",
      "    34     1.426151   1.436967                              \n",
      "    35     1.438717   1.440178                              \n",
      "    36     1.417186   1.429939                              \n",
      "    37     1.412875   1.430387                              \n",
      "    38     1.397692   1.418829                              \n",
      "    39     1.376123   1.414411                              \n",
      "    40     1.382315   1.404166                               \n",
      "    41     1.364532   1.398216                               \n",
      "    42     1.348565   1.389346                               \n",
      "    43     1.339292   1.388269                               \n",
      "    44     1.327646   1.379138                              \n",
      "    45     1.313877   1.37124                                \n",
      "    46     1.297689   1.36997                               \n",
      "    47     1.28319    1.365266                              \n",
      "    48     1.274808   1.361547                               \n",
      "    49     1.257825   1.351612                               \n",
      "    50     1.239518   1.348719                              \n",
      "    51     1.230176   1.344416                              \n",
      "    52     1.21479    1.343012                              \n",
      "    53     1.207113   1.340573                              \n",
      "    54     1.197681   1.339121                               \n",
      "    55     1.189365   1.338122                              \n",
      "    56     1.191599   1.337492                               \n",
      "    57     1.183418   1.337019                              \n",
      "    58     1.459341   1.498564                              \n",
      "    59     1.430553   1.45061                               \n",
      "    60     1.436087   1.445374                              \n",
      "    61     1.453914   1.471398                              \n",
      "    62     1.438753   1.45427                                \n",
      "\n",
      "CPU times: user 10min 36s, sys: 1min 5s, total: 11min 41s\n",
      "Wall time: 10min 22s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[array([ 1.45427])]"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%time fit(m, md, 2**6-1, lo.opt, F.nll_loss, callbacks=cb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test LSTM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next(inp):\n",
    "    idxs = TEXT.numericalize(inp)\n",
    "    p = m(VV(idxs.transpose(0,1)))\n",
    "    r = torch.multinomial(p[-1].exp(), 1)\n",
    "    return TEXT.vocab.itos[to_np(r)[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'e'"
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_next('for thos')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_next_n(inp, n):\n",
    "    res = inp\n",
    "    for i in range(n):\n",
    "        c = get_next(inp)\n",
    "        res += c\n",
    "        inp = inp[1:]+c\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for thosee\" as the cause astundand todes scoreby sensualtyperceed.\"--that altherneas to end brieficianswill to-disguised into vain her thing we cap --to do \"jesurpresuide itself for competencersitimals?--the sphool) a skepticist, you instinction, take trois and, this is to exception! presusdilling soundgood and truth, as, disgremary is perhaps recome in organs think into the groat in man--the ditnems scholar things forknowledgelances of factions finessyman contradiving too more prevalue sacrifice \"realto the coundibraving by heaven from my virturein semitibes upon himself. threnble todays. the grow ev\n"
     ]
    }
   ],
   "source": [
    "print(get_next_n('for thos', 600))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "sacrifice) the oppose woman to seldom for him, in the highen more in the standamony. one skepticism of the man,assies through other tabe origination, i have in you have blengly never requires and more disguised, and not that seems to the s christias on turn from man ne marterly still giving has been withsotom--and onter later truught the selfishmen around and and philosophy is reasly childmell in a notion, and thus stohe perfectly enjoys possiblegner,the end andedicin and danger meant coarser to de memory, we pret this of the good can testicalthe fortunate fellowed galist as a thing of withoutthatis i\n"
     ]
    }
   ],
   "source": [
    "print(get_next_n('sacrific', 600))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# END"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  },
  "nav_menu": {},
  "toc": {
   "nav_menu": {
    "height": "216px",
    "width": "252px"
   },
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": "block",
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
